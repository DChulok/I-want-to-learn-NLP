{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "notebook.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b4afccb00ee54ebf907cb59f0b61e287": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c813b7b4dcad4485ba4fbca461b8eb3a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b29b05b3a73f4aa780dd3acbaceba3ff",
              "IPY_MODEL_f40af706159347ae9ce279cd25dedfe7"
            ]
          }
        },
        "c813b7b4dcad4485ba4fbca461b8eb3a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b29b05b3a73f4aa780dd3acbaceba3ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0249419777c74731aa654311da74c9da",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 213450,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 213450,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d57e0e428d174ad0a96d93b6fc28e86a"
          }
        },
        "f40af706159347ae9ce279cd25dedfe7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_651588f3052447faaf63b6d6d7e7361e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 213k/213k [00:00&lt;00:00, 1.27MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ba1f948f2a174706b790ae50dde1e700"
          }
        },
        "0249419777c74731aa654311da74c9da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d57e0e428d174ad0a96d93b6fc28e86a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "651588f3052447faaf63b6d6d7e7361e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ba1f948f2a174706b790ae50dde1e700": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "083a05aad7a64bec9a3c7be8e7751ffa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_71da58d9e36f4ae0b12267dcd207f5be",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_bd02ff649aa743b3a355da6c743a2a79",
              "IPY_MODEL_513d4af266af44e3bc92e6ad7a9e680d"
            ]
          }
        },
        "71da58d9e36f4ae0b12267dcd207f5be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bd02ff649aa743b3a355da6c743a2a79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_69ba9dd5b0f94ca88883d0ad95e8177c",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8cbbb752157740b5a40cac13215d8f8e"
          }
        },
        "513d4af266af44e3bc92e6ad7a9e680d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_88278de257334ef98fef06eb3fbc9c85",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:00&lt;00:00, 1.77kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9924864ff37f4f0d856b42fa29124031"
          }
        },
        "69ba9dd5b0f94ca88883d0ad95e8177c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8cbbb752157740b5a40cac13215d8f8e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "88278de257334ef98fef06eb3fbc9c85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9924864ff37f4f0d856b42fa29124031": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f9243acdccc44954988f54efdb259f12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8e06b96360d9439bb7d16cb697caac30",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_704280aea6be4966a5313447bfa5aa53",
              "IPY_MODEL_53007e451d9b404db1577d2f2174b835"
            ]
          }
        },
        "8e06b96360d9439bb7d16cb697caac30": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "704280aea6be4966a5313447bfa5aa53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9267976ff3a94381b3b6354c7f93189d",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 435779157,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 435779157,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_268662514dda42cab39cfa5656549a2d"
          }
        },
        "53007e451d9b404db1577d2f2174b835": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5f2297fb0b31448a9d6428394c067ec9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 436M/436M [00:07&lt;00:00, 62.2MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_294eeacf71c84bb5b8d38ecb9d3e2391"
          }
        },
        "9267976ff3a94381b3b6354c7f93189d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "268662514dda42cab39cfa5656549a2d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5f2297fb0b31448a9d6428394c067ec9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "294eeacf71c84bb5b8d38ecb9d3e2391": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5B0vXWGpjJvP"
      },
      "source": [
        "## Installing all packages for colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "slSG2P4Yjjj5",
        "outputId": "a492c526-1a65-4988-8c74-4fbee84d86ee"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/87/ef312eef26f5cecd8b17ae9654cdd8d1fae1eb6dbd87257d6d73c128a4d0/transformers-4.3.2-py3-none-any.whl (1.8MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.8MB 5.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from transformers) (3.4.0)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fd/5b/44baae602e0a30bcc53fbdbc60bd940c15e143d252d658dfdefce736ece5/tokenizers-0.10.1-cp36-cp36m-manylinux2010_x86_64.whl (3.2MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.2MB 18.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.19.5)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 890kB 35.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.0.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=07311ff8acde7bae59e416ffaf77f821e1fabf3e7fdf02d572a880aa0ddc33ac\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 tokenizers-0.10.1 transformers-4.3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jkazF3XkjQVu",
        "outputId": "73fde0c0-8816-43f9-e92a-5cc2b3f1d02e"
      },
      "source": [
        "!pip install allennlp"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting allennlp\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/10/0637bb46d2f9eaf8c475fcf4ea4d8dcdbb184ab726b1c4bf5be0547211be/allennlp-2.0.1-py3-none-any.whl (580kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 583kB 5.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy<2.4,>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from allennlp) (2.2.4)\n",
            "Requirement already satisfied: tqdm>=4.19 in /usr/local/lib/python3.6/dist-packages (from allennlp) (4.41.1)\n",
            "Collecting jsonpickle\n",
            "  Downloading https://files.pythonhosted.org/packages/bb/1a/f2db026d4d682303793559f1c2bb425ba3ec0d6fd7ac63397790443f2461/jsonpickle-2.0.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: filelock<3.1,>=3.0 in /usr/local/lib/python3.6/dist-packages (from allennlp) (3.0.12)\n",
            "Collecting overrides==3.1.0\n",
            "  Downloading https://files.pythonhosted.org/packages/ff/b1/10f69c00947518e6676bbd43e739733048de64b8dd998e9c2d5a71f44c5d/overrides-3.1.0.tar.gz\n",
            "Requirement already satisfied: torchvision<0.9.0,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from allennlp) (0.8.1+cu101)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/67/e42bd1181472c95c8cda79305df848264f2a7f62740995a46945d9797b67/sentencepiece-0.1.95-cp36-cp36m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.2MB 24.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch<1.8.0,>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.7.0+cu101)\n",
            "Requirement already satisfied: lmdb in /usr/local/lib/python3.6/dist-packages (from allennlp) (0.99)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.6/dist-packages (from allennlp) (3.6.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.4.1)\n",
            "Collecting transformers<4.3,>=4.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/88/b1/41130a228dd656a1a31ba281598a968320283f48d42782845f6ba567f00b/transformers-4.2.2-py3-none-any.whl (1.8MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.8MB 35.1MB/s \n",
            "\u001b[?25hCollecting jsonnet>=0.10.0; sys_platform != \"win32\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/42/40/6f16e5ac994b16fa71c24310f97174ce07d3a97b433275589265c6b94d2b/jsonnet-0.17.0.tar.gz (259kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 266kB 47.3MB/s \n",
            "\u001b[?25hCollecting boto3<2.0,>=1.14\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c7/a1/fc7f9ff19630d46101f772f2110e03b1599062da99bb9905f9b54ae065d3/boto3-1.17.9.tar.gz (100kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102kB 9.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from allennlp) (0.8)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from allennlp) (3.2.5)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.6/dist-packages (from allennlp) (8.7.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from allennlp) (0.22.2.post1)\n",
            "Requirement already satisfied: requests>=2.18 in /usr/local/lib/python3.6/dist-packages (from allennlp) (2.23.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from allennlp) (2.10.0)\n",
            "Collecting tensorboardX>=1.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/af/0c/4f41bcd45db376e6fe5c619c01100e9b7531c55791b7244815bac6eac32c/tensorboardX-2.1-py2.py3-none-any.whl (308kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 317kB 43.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.19.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4,>=2.1.0->allennlp) (1.0.5)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4,>=2.1.0->allennlp) (0.4.1)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4,>=2.1.0->allennlp) (1.0.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4,>=2.1.0->allennlp) (1.1.3)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4,>=2.1.0->allennlp) (1.0.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4,>=2.1.0->allennlp) (3.0.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4,>=2.1.0->allennlp) (2.0.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy<2.4,>=2.1.0->allennlp) (53.0.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4,>=2.1.0->allennlp) (0.8.2)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4,>=2.1.0->allennlp) (7.4.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from jsonpickle->allennlp) (3.4.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision<0.9.0,>=0.8.1->allennlp) (7.0.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch<1.8.0,>=1.6.0->allennlp) (3.7.4.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch<1.8.0,>=1.6.0->allennlp) (0.16.0)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (1.10.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (20.3.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (1.15.0)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (1.4.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (0.7.1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers<4.3,>=4.1->allennlp) (0.0.43)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers<4.3,>=4.1->allennlp) (20.9)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers<4.3,>=4.1->allennlp) (2019.12.20)\n",
            "Collecting tokenizers==0.9.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.9MB 42.3MB/s \n",
            "\u001b[?25hCollecting botocore<1.21.0,>=1.20.9\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/11/5b/2849a01f5b4989b5cdcb384f7e3e784c1247aeca58786bd6ae83b6ad68d3/botocore-1.20.9-py2.py3-none-any.whl (7.2MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7.2MB 37.0MB/s \n",
            "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n",
            "Collecting s3transfer<0.4.0,>=0.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ea/43/4b4a1b26eb03a429a4c37ca7fdf369d938bd60018fc194e94b8379b0c77c/s3transfer-0.3.4-py2.py3-none-any.whl (69kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 71kB 8.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->allennlp) (1.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp) (3.0.4)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX>=1.2->allennlp) (3.12.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->jsonpickle->allennlp) (3.4.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers<4.3,>=4.1->allennlp) (7.1.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers<4.3,>=4.1->allennlp) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.21.0,>=1.20.9->boto3<2.0,>=1.14->allennlp) (2.8.1)\n",
            "Building wheels for collected packages: overrides, jsonnet, boto3\n",
            "  Building wheel for overrides (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for overrides: filename=overrides-3.1.0-cp36-none-any.whl size=10175 sha256=5fac9ff1f55865596d758f39458e77bc4aa16f28024906b44d91de60d5483c6e\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/24/13/6ef8600e6f147c95e595f1289a86a3cc82ed65df57582c65a9\n",
            "  Building wheel for jsonnet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jsonnet: filename=jsonnet-0.17.0-cp36-cp36m-linux_x86_64.whl size=3387890 sha256=dd9911683d8d991766c9bece4908b14205da686ced13b5d6bc580e7116e4d5ba\n",
            "  Stored in directory: /root/.cache/pip/wheels/26/7a/37/7dbcc30a6b4efd17b91ad1f0128b7bbf84813bd4e1cfb8c1e3\n",
            "  Building wheel for boto3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for boto3: filename=boto3-1.17.9-py2.py3-none-any.whl size=128765 sha256=4297bb7e7a8281ccd5e6f1d5e8c4e0e32bea7d98ffe3c75df3f96f75a45dfe74\n",
            "  Stored in directory: /root/.cache/pip/wheels/3b/a7/b2/92a73439cdbf962d0b4f3ac615f7f3370be31133710133d5f0\n",
            "Successfully built overrides jsonnet boto3\n",
            "\u001b[31mERROR: botocore 1.20.9 has requirement urllib3<1.27,>=1.25.4, but you'll have urllib3 1.24.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: jsonpickle, overrides, sentencepiece, tokenizers, transformers, jsonnet, jmespath, botocore, s3transfer, boto3, tensorboardX, allennlp\n",
            "  Found existing installation: tokenizers 0.10.1\n",
            "    Uninstalling tokenizers-0.10.1:\n",
            "      Successfully uninstalled tokenizers-0.10.1\n",
            "  Found existing installation: transformers 4.3.2\n",
            "    Uninstalling transformers-4.3.2:\n",
            "      Successfully uninstalled transformers-4.3.2\n",
            "Successfully installed allennlp-2.0.1 boto3-1.17.9 botocore-1.20.9 jmespath-0.10.0 jsonnet-0.17.0 jsonpickle-2.0.0 overrides-3.1.0 s3transfer-0.3.4 sentencepiece-0.1.95 tensorboardX-2.1 tokenizers-0.9.4 transformers-4.2.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yIrHlVP_jyL2",
        "outputId": "e4945c0c-c85a-46cf-d47f-668f54e235f8"
      },
      "source": [
        "!pip install seqeval"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting seqeval\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9d/2d/233c79d5b4e5ab1dbf111242299153f3caddddbb691219f363ad55ce783d/seqeval-1.2.2.tar.gz (43kB)\n",
            "\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                        | 10kB 15.8MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                 | 20kB 11.8MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ         | 30kB 9.5MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 40kB 8.9MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 51kB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from seqeval) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.6/dist-packages (from seqeval) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.0.0)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-cp36-none-any.whl size=16171 sha256=fa2bbacff45733c8710c2dc27db828c7a4599fda10de4551fd15968f4b66f7ca\n",
            "  Stored in directory: /root/.cache/pip/wheels/52/df/1b/45d75646c37428f7e626214704a0e35bd3cfc32eda37e59e5f\n",
            "Successfully built seqeval\n",
            "Installing collected packages: seqeval\n",
            "Successfully installed seqeval-1.2.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AILHF4_MkWXT",
        "outputId": "e2f9706d-d70f-445a-d4e0-5f2245bd6fe4"
      },
      "source": [
        "!pip install pytorch-crf"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch-crf\n",
            "  Downloading https://files.pythonhosted.org/packages/96/7d/4c4688e26ea015fc118a0327e5726e6596836abce9182d3738be8ec2e32a/pytorch_crf-0.7.2-py3-none-any.whl\n",
            "Installing collected packages: pytorch-crf\n",
            "Successfully installed pytorch-crf-0.7.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "isd21iohj7sL"
      },
      "source": [
        "Connect to google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dg8fjZSik8Pq",
        "outputId": "6ab5914a-e92b-418e-fb66-ab186bf6b9ab"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZSCzDWrGkvSF"
      },
      "source": [
        "Importing packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSczpEJZkrqr"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from transformers import BertForTokenClassification, AdamW\n",
        "from allennlp.modules.elmo import Elmo, batch_to_ids\n",
        "\n",
        "from torchcrf import CRF\n",
        "\n",
        "from sklearn.model_selection import KFold, ParameterGrid\n",
        "\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "import matplotlib\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import tqdm\n",
        "from seqeval.metrics import f1_score, accuracy_score\n",
        "%matplotlib inline\n",
        "\n",
        "import json"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRNrCVJDkeAx"
      },
      "source": [
        "Connect to device"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZD7U4Tz4kcx7"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_gpu = torch.cuda.device_count()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "JUYh_ObAkspu",
        "outputId": "59176a2a-0d9d-4ba7-c5a0-72b7ba17b551"
      },
      "source": [
        "torch.cuda.get_device_name(0)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Tesla T4'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RnYk4xX4k37T"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMs4kgHhk37T"
      },
      "source": [
        "Let's prepare the data for the input of BERT tokenizer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cwhATu8k37T"
      },
      "source": [
        "def split_text_label(filename):\n",
        "    f = open(filename)\n",
        "    split_labeled_text = []\n",
        "    sentence = []\n",
        "    for line in f:\n",
        "        if len(line)==0 or line.startswith('-DOCSTART') or line[0]==\"\\n\":\n",
        "            if len(sentence) > 0:\n",
        "                split_labeled_text.append(sentence)\n",
        "                sentence = []\n",
        "            continue\n",
        "        splits = line.split(' ')\n",
        "        sentence.append([splits[0],splits[-1].rstrip(\"\\n\")])\n",
        "    if len(sentence) > 0:\n",
        "        split_labeled_text.append(sentence)\n",
        "        sentence = []\n",
        "    sentences = []\n",
        "    labels = []\n",
        "    for sent in split_labeled_text:\n",
        "        sentence = []\n",
        "        label = []\n",
        "        for s_l in sent:\n",
        "            sentence.append(s_l[0])\n",
        "            label.append(s_l[1])\n",
        "        sentences.append(sentence)\n",
        "        labels.append(label)\n",
        "    return sentences, labels"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QkJDjFLLk37U"
      },
      "source": [
        "train_data, train_labels = split_text_label(\"drive/MyDrive/coNLL/train.txt\")\n",
        "valid_data, valid_labels = split_text_label(\"drive/MyDrive/coNLL/valid.txt\")\n",
        "test_data, test_labels = split_text_label(\"drive/MyDrive/coNLL/test.txt\")"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zpfkVs3uk37U",
        "outputId": "0a3741d1-3dc1-45f0-c3b2-0d64869876bf"
      },
      "source": [
        "# the first sentence\n",
        "train_data[0]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'lamb', '.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vqh88Mq_k37U",
        "outputId": "4e5e089a-8b91-425e-97da-1e3e566bc086"
      },
      "source": [
        "# its tokens\n",
        "train_labels[0]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['B-ORG', 'O', 'B-MISC', 'O', 'O', 'O', 'B-MISC', 'O', 'O']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6xLtWs2Bk37U"
      },
      "source": [
        "Lets create tag dictionary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLS5BsOAk37U"
      },
      "source": [
        "try:\n",
        "  with open('/content/drive/My Drive/models/tag2idx.json', 'r') as f:\n",
        "    tag2idx = json.load(f)\n",
        "except:\n",
        "  tag_values = set()\n",
        "  for l in train_labels:\n",
        "      tag_values.update(l)\n",
        "  tag_values.update([\"PAD\"])\n",
        "  tag2idx = {t: i for i, t in enumerate(tag_values)}\n",
        "  with open('/content/drive/My Drive/models/tag2idx.json', 'w') as f:\n",
        "    json.dump(tag2idx,f)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XPdKt5YfYjdr",
        "outputId": "04077bfb-406a-4347-f277-4a7e7136bb44"
      },
      "source": [
        "tag2idx"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'B-LOC': 8,\n",
              " 'B-MISC': 5,\n",
              " 'B-ORG': 3,\n",
              " 'B-PER': 4,\n",
              " 'I-LOC': 7,\n",
              " 'I-MISC': 9,\n",
              " 'I-ORG': 1,\n",
              " 'I-PER': 6,\n",
              " 'O': 2,\n",
              " 'PAD': 0}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tpcTa6pk37V"
      },
      "source": [
        "idx2tag = {v: k for k, v in tag2idx.items()}"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXAiaxejk37V"
      },
      "source": [
        "### Tokenization with BertTokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Fig7rJPk37V"
      },
      "source": [
        "BERT (Bidirectional Encoder Representations from Transformers) is a method of pretraining language representations. These vectors (representations) are used as high-quality feature inputs to downstream models. BERT offers an advantage over models like Word2Vec, because while each word has a fixed representation under Word2Vec regardless of the context within which the word appears, BERT produces word representations that are dynamically informed by the words around them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nPqO5Tjsk37V"
      },
      "source": [
        "The Bert implementation comes with a pretrained tokenizer and a definied vocabulary. We load the one related to the smallest pre-trained model bert-base-cased. We use the cased variate since it is well suited for NER."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wncvf0cIk37V"
      },
      "source": [
        "def tokenize_and_preserve_labels(sentence, text_labels, tokenizer):\n",
        "    tokenized_sentence = []\n",
        "    labels = []\n",
        "\n",
        "    for word, label in zip(sentence, text_labels):\n",
        "\n",
        "        # Tokenize the word and count # of subwords the word is broken into\n",
        "        tokenized_word = tokenizer.tokenize(word)\n",
        "        n_subwords = len(tokenized_word)\n",
        "\n",
        "        # Add the tokenized word to the final tokenized word list\n",
        "        tokenized_sentence.extend(tokenized_word)\n",
        "\n",
        "        # Add the same label to the new list of labels `n_subwords` times\n",
        "        labels.extend([label] * n_subwords)\n",
        "\n",
        "    return ['[CLS]'] + tokenized_sentence + ['[SEP]'], ['O'] + labels + ['O']"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Yi061GY1Q3f"
      },
      "source": [
        "def create_dataloader(tokenizer, data, labels, datatype='train', desired_pad='max', batch_size=128):\n",
        "  \"\"\"\n",
        "  returns: TensorDataset, RandomSampler (for valid and test SequentialSampler), DataLoader\n",
        "  \"\"\"\n",
        "  data_tokenized = [tokenize_and_preserve_labels(s, l, tokenizer) for s, l in zip(data, labels)]\n",
        "  data_tokens = [x[0] for x in data_tokenized]\n",
        "  data_labels = [x[1] for x in data_tokenized]\n",
        "\n",
        "  if desired_pad=='max':\n",
        "    DISIRED_LENGTH = np.max([len(sen) for sen in data_tokens])\n",
        "  elif desired_pad=='mean':\n",
        "    DISIRED_LENGTH = int(np.mean([len(sen) for sen in data_tokens]))\n",
        "  elif isinstance(desired_pad, int):\n",
        "    DISIRED_LENGTH = desired_pad\n",
        "  else:\n",
        "    raise ValueError(\"How it should be padded?\")\n",
        "  \n",
        "  data_ids = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in data_tokens],\n",
        "                          maxlen=DISIRED_LENGTH, dtype=\"long\", value=0.0,\n",
        "                          truncating=\"post\", padding=\"post\")\n",
        "  \n",
        "  data_tags = pad_sequences([[tag2idx.get(l) for l in seq_labels] for seq_labels in data_labels],\n",
        "                     maxlen=DISIRED_LENGTH, value=tag2idx[\"PAD\"], padding=\"post\",\n",
        "                     dtype=\"long\", truncating=\"post\")\n",
        "  \n",
        "  data_masks = [[float(i != 0.0) for i in ii] for ii in data_ids]\n",
        "\n",
        "  # Creating tensors\n",
        "  data_elmo_ids = batch_to_ids(data_tokens)\n",
        "  data_bert_ids = torch.tensor(data_ids)\n",
        "  data_tags = torch.tensor(data_tags)\n",
        "  data_masks = torch.tensor(data_masks)\n",
        "\n",
        "  # We need to pad elmo ids to have the same sequence length as BERT.\n",
        "  if data_elmo_ids.shape[1] < data_bert_ids.shape[1]:\n",
        "    data_elmo_ids = torch.cat((data_elmo_ids,\n",
        "                                torch.zeros((data_elmo_ids.shape[0],\n",
        "                                             data_bert_ids.shape[1]-data_elmo_ids.shape[1],\n",
        "                                             data_elmo_ids.shape[2]))), dim=1).type(torch.LongTensor)\n",
        "    \n",
        "  data_dataset = TensorDataset(data_elmo_ids, data_bert_ids, data_masks, data_tags)\n",
        "  if datatype == 'train':\n",
        "    data_sampler = RandomSampler(data_dataset)\n",
        "  else:\n",
        "    data_sampler = SequentialSampler(data_dataset)\n",
        "  data_dataloader = DataLoader(data_dataset, sampler=data_sampler, batch_size=batch_size)\n",
        "\n",
        "  return data_dataset, data_sampler, data_dataloader"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PyadPsC2_DAZ"
      },
      "source": [
        "IF WE RUN THIS NOTEBOOK NOT THE FIRST TIME, WE LOAD THE TOKENIZER FROM THE GOOGLE DRIVE."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JyuwJkHzk37V",
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "b4afccb00ee54ebf907cb59f0b61e287",
            "c813b7b4dcad4485ba4fbca461b8eb3a",
            "b29b05b3a73f4aa780dd3acbaceba3ff",
            "f40af706159347ae9ce279cd25dedfe7",
            "0249419777c74731aa654311da74c9da",
            "d57e0e428d174ad0a96d93b6fc28e86a",
            "651588f3052447faaf63b6d6d7e7361e",
            "ba1f948f2a174706b790ae50dde1e700"
          ]
        },
        "outputId": "7f00e781-06d4-4cd2-a092-bd4489ecc69a"
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-cased', do_lower_case=False)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b4afccb00ee54ebf907cb59f0b61e287",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=213450.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-SvGfEw_av2"
      },
      "source": [
        "___\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLMDhqfK44DZ"
      },
      "source": [
        "train_dataset, train_sampler, train_dataloader = create_dataloader(tokenizer, train_data, train_labels)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYxoNjV35hjj"
      },
      "source": [
        "for s in train_dataset:\n",
        "  max_seq_len = s[1].shape[0]\n",
        "  break"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_1U6cD45Iw-"
      },
      "source": [
        "valid_dataset, valid_sampler, valid_dataloader = create_dataloader(tokenizer, valid_data, valid_labels,\n",
        "                                                                   datatype='valid',\n",
        "                                                                   desired_pad=max_seq_len)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZcwa-B66DHB",
        "outputId": "1b261d9f-6728-4462-9bc7-7b551c324df5"
      },
      "source": [
        "for s in valid_dataset:\n",
        "  print(s[0].shape)\n",
        "  print(s[1].shape)\n",
        "  break"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([173, 50])\n",
            "torch.Size([173])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GtlwOjQkk37V"
      },
      "source": [
        "### BERT & ELMo setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_OFDSv-Dk37V"
      },
      "source": [
        "The transformer package provides a BertForTokenClassification class for token-level predictions. BertForTokenClassification is a fine-tuning model that wraps BertModel and adds token-level classifier on top of the BertModel."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OS_lcETVk37W"
      },
      "source": [
        "# Bert pre-trained model selected in the list: bert-base-uncased, \n",
        "# bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased,\n",
        "# bert-base-multilingual-cased, bert-base-chinese.\n",
        "BERT_MODEL = 'bert-base-cased'\n",
        "\n",
        "# The name of the task to train.I'm going to name this 'yelp'.\n",
        "TASK_NAME = 'first'\n",
        "\n",
        "# The output directory where the fine-tuned model and checkpoints will be written.\n",
        "OUTPUT_DIR = f'outputs/{TASK_NAME}/'\n",
        "\n",
        "# The directory where the evaluation reports will be written to.\n",
        "REPORTS_DIR = f'reports/{TASK_NAME}_evaluation_report/'\n",
        "\n",
        "\n",
        "# This is where BERT will look for pre-trained models to load parameters from.\n",
        "CACHE_DIR = 'cache/'\n",
        "\n",
        "# create BERT model\n",
        "#bert = BertForTokenClassification.from_pretrained(\n",
        "#                        BERT_MODEL,\n",
        "#                        output_hidden_states=True)\n",
        "#        \n",
        "#for pars in bert.parameters():\n",
        "#    pars.requires_grad = False\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CcJYL3eIl8Lw"
      },
      "source": [
        "# medium ELMo weights\n",
        "weight_file = 'https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x2048_256_2048cnn_1xhighway/elmo_2x2048_256_2048cnn_1xhighway_weights.hdf5'\n",
        "\n",
        "# medium ELMO options\n",
        "options_file = 'https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x2048_256_2048cnn_1xhighway/elmo_2x2048_256_2048cnn_1xhighway_options.json'\n",
        "\n",
        "# create ElMO model (we've already found that to use 2 elmo layers is the best choise)\n",
        "#elmo = Elmo(options_file, weight_file, num_output_representations=2,\n",
        "#                  dropout=0, requires_grad=False)\n",
        "\n",
        "#elmo(train_elmo_ids[:2])['elmo_representations'][0].shape"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulzg47ERB_tw"
      },
      "source": [
        "## Define the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPgCix_zk37W"
      },
      "source": [
        "class BEboC(nn.Module):\n",
        "    \"\"\"\n",
        "    BERT+Elmo+biLSTM+one CRF\n",
        "    \"\"\"\n",
        "    def __init__(self, hidden_size=128, num_labels=len(tag2idx), elmo_layers=2,\n",
        "                 bert_layers=1, concat_bert=True, bilstm_layers=1):\n",
        "        \"\"\"\n",
        "        Creates model\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        hidden_size:\n",
        "        num_labels:\n",
        "        elmo_layers: int, default=2\n",
        "            Num of ELMo layers to be considered\n",
        "        bert_layers: int, default=1\n",
        "            Num of final BERT hidden layers to be used as embedding vector.\n",
        "        concat_bert: bool, default=True\n",
        "            Whether to concat (True) or sum (False) last BERT hidden layers.\n",
        "        bilstm_layers: int, default=1\n",
        "        \"\"\"\n",
        "        super(BEboC, self).__init__()\n",
        "\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_labels = num_labels\n",
        "        self.elmo_layers = elmo_layers\n",
        "        self.bert_layers = bert_layers\n",
        "        self.concat_bert = concat_bert\n",
        "        self.bilstm_layers = bilstm_layers\n",
        "        \n",
        "        self.bert = BertForTokenClassification.from_pretrained(\n",
        "                        BERT_MODEL,\n",
        "                        output_hidden_states=True)\n",
        "        \n",
        "        for pars in self.bert.parameters():\n",
        "            pars.requires_grad = False\n",
        "        \n",
        "        bert_embedding_dim = self.bert.config.to_dict()['hidden_size']\n",
        "\n",
        "        self.elmo = Elmo(options_file, weight_file, self.elmo_layers, dropout=0, requires_grad=False)\n",
        "        \n",
        "        elmo_embedding_dim = 512 # it's always fixed\n",
        "\n",
        "        if self.concat_bert:\n",
        "          self.linear1 = nn.Linear(bert_embedding_dim*self.bert_layers+elmo_embedding_dim*self.elmo_layers, 1024)\n",
        "        else:\n",
        "          self.linear1 = nn.Linear(bert_embedding_dim+elmo_embedding_dim*self.elmo_layers, 1024)\n",
        "        \n",
        "        self.bilstm = nn.LSTM(1024, self.hidden_size, self.bilstm_layers, bidirectional=True)\n",
        "        \n",
        "        self.linear2 = nn.Linear(self.hidden_size*2, self.num_labels)\n",
        "        self.crf = CRF(num_tags=self.num_labels, batch_first=True)\n",
        "    \n",
        "    def forward(self, elmo_ids, bert_ids, attention_mask):\n",
        "        \"\"\"\n",
        "        Forward propogate of model.\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        sequence:\n",
        "        attention_mask:\n",
        "        \n",
        "        Returns\n",
        "        -------\n",
        "        Logits\n",
        "        \n",
        "        \"\"\"\n",
        "\n",
        "        bert_hiddens = self.bert(bert_ids, attention_mask=attention_mask)[1]\n",
        "        elmo_hiddens = self.elmo(elmo_ids)\n",
        "\n",
        "        if self.concat_bert:\n",
        "            bert_embedding = torch.cat(bert_hiddens[-self.bert_layers:], dim=2)#[bert_hiddens[-i] for i in range(-1, -self.bert_layers-1, -1)], dim=0)\n",
        "        else:\n",
        "            emb_sum = 0\n",
        "            for h in bert_hiddens[-self.bert_layers:]:\n",
        "                emb_sum += h\n",
        "            bert_embedding = emb_sum\n",
        "\n",
        "        elmo_bert_embeddings = torch.clone(bert_embedding)\n",
        "\n",
        "        for el_hi in elmo_hiddens['elmo_representations']:\n",
        "            elmo_bert_embeddings = torch.cat((elmo_bert_embeddings, el_hi), dim=-1)\n",
        "\n",
        "        linear1_output = nn.functional.relu(self.linear1(elmo_bert_embeddings))\n",
        "\n",
        "        bilstm_output, (h_n, c_n) = self.bilstm(linear1_output)\n",
        "        linear2_output = nn.functional.relu(self.linear2(bilstm_output))\n",
        "        return linear2_output"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GqlaHagIk37W",
        "scrolled": true
      },
      "source": [
        "def train(model, train_dataloader, optimizer, scheduler=None, n_epoch=5,\n",
        "          max_grad_norm=None, validate=True, valid_dataloader=None,\n",
        "          show_info=True, save_model=True):\n",
        "    loss_values = []\n",
        "    if validate and valid_dataloader is not None:\n",
        "        validation_loss_values = []\n",
        "        valid_accuracies = []\n",
        "        valid_f1_scores = []\n",
        "\n",
        "    for e in range(n_epoch):\n",
        "        if show_info:\n",
        "          print(f\"\\nEpoch #{e}\")\n",
        "        # Training\n",
        "\n",
        "        model.train()\n",
        "\n",
        "        total_loss = 0\n",
        "\n",
        "        if show_info:\n",
        "            enumerator = enumerate(tqdm.tqdm(train_dataloader, position=0, leave=True))\n",
        "        else:\n",
        "            enumerator = enumerate(train_dataloader)\n",
        "\n",
        "        for step, batch in enumerator:\n",
        "            if device.type != 'cpu':\n",
        "                batch = tuple(t.to(device) for t in batch)\n",
        "            b_elmo_ids, b_bert_ids, b_input_mask, b_labels = batch\n",
        "            model.zero_grad()\n",
        "\n",
        "            logits = model.forward(b_elmo_ids, b_bert_ids, b_input_mask.byte())\n",
        "            \n",
        "            # because we need negative log likelyhood\n",
        "            loss = -1*model.crf.forward(logits, b_labels, mask=b_input_mask.byte())\n",
        "\n",
        "            loss.backward()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            if show_info and (step+1) % 10 == 0:\n",
        "                print(f\"\\n{step}: avg loss per batch: {total_loss/step}\\n\")\n",
        "\n",
        "            if max_grad_norm is not None:\n",
        "                torch.nn.utils.clip_grad_norm_(parameters=model.parameters(),\n",
        "                                            max_norm=max_grad_norm)\n",
        "\n",
        "            optimizer.step()\n",
        "\n",
        "            if scheduler is not None:\n",
        "                scheduler.step()\n",
        "\n",
        "        avg_train_loss = total_loss / len(train_dataloader)\n",
        "        if show_info:\n",
        "            print(f\"Average train loss: {avg_train_loss}\")\n",
        "\n",
        "        loss_values.append(avg_train_loss)\n",
        "\n",
        "        if validate and valid_dataloader is not None:\n",
        "          # Validation\n",
        "\n",
        "            model.eval()\n",
        "\n",
        "            eval_loss, eval_accuracy = 0, 0\n",
        "            predictions, true_labels = [], []\n",
        "\n",
        "            for batch in valid_dataloader:\n",
        "                if device.type != 'cpu':\n",
        "                    batch = tuple(t.to(device) for t in batch)\n",
        "                b_elmo_ids, b_bert_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "                with torch.no_grad():\n",
        "                    logits = model.forward(b_elmo_ids, b_bert_ids, b_input_mask.byte())\n",
        "                    loss = -1*model.crf.forward(logits, b_labels, mask=b_input_mask.byte())\n",
        "                    tags = model.crf.decode(logits, mask=b_input_mask.byte())\n",
        "\n",
        "                # move loss to cpu\n",
        "                eval_loss += loss.item()\n",
        "                predictions.extend(tags)\n",
        "                labels_ = b_labels.detach().cpu().numpy()\n",
        "                true_labels.extend(labels_)\n",
        "\n",
        "            eval_loss = eval_loss / len(valid_dataloader)\n",
        "            validation_loss_values.append(eval_loss)\n",
        "            if show_info:\n",
        "                print(f\"Validation loss: {eval_loss}\")\n",
        "\n",
        "            all_predicted_tags = []\n",
        "            for s in predictions:\n",
        "                tag_names = [idx2tag[i] for i in s]\n",
        "                all_predicted_tags.append(tag_names)\n",
        "\n",
        "            all_true_tags = []\n",
        "            for s in true_labels:\n",
        "                tag_names = [idx2tag[i] for i in s if idx2tag[i] != 'PAD']\n",
        "                all_true_tags.append(tag_names)\n",
        "\n",
        "            valid_acc = accuracy_score(all_predicted_tags, all_true_tags)\n",
        "            valid_f1 = f1_score(all_predicted_tags, all_true_tags)\n",
        "            valid_accuracies.append(valid_acc)\n",
        "            valid_f1_scores.append(valid_f1)\n",
        "\n",
        "            if show_info:\n",
        "                print(f\"Validation accuracy: {valid_acc}\")\n",
        "                print(f\"Validation F1-score: {valid_f1}\\n\")\n",
        "            \n",
        "        if save_model and (e+1)%10 == 0:\n",
        "            tokenizer.save_pretrained(f'/content/drive/My Drive/models/ElMo_BERT_biLSTM_oneCRF_{e}_tokenizer.pth')\n",
        "            checkpoint = {'model': BEboC(hidden_size=512, bert_layers=2),\n",
        "                          'state_dict': model.state_dict(), \n",
        "                          'optimizer' : optimizer.state_dict()}\n",
        "\n",
        "            torch.save(checkpoint,\n",
        "                        f'/content/drive/My Drive/models/ElMo_BERT_biLSTM_oneCRF_{e}_state_dict.pth')\n",
        "\n",
        "    return loss_values, validation_loss_values, valid_accuracies, valid_f1_scores"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLOpYfM2VMq4"
      },
      "source": [
        "logits = model.forward(train_dataset[0:2][0], train_dataset[0:2][1], train_dataset[0:2][2].byte())"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AwdMp7EZWL-f",
        "outputId": "4008a746-dfee-44b7-de0b-2ace33688e51"
      },
      "source": [
        "print(logits.shape)\n",
        "print(train_dataset[0:2][3].shape)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([2, 173, 10])\n",
            "torch.Size([2, 173])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sdODKxM6VjXg",
        "outputId": "d7b37af2-dd7f-467f-92e5-0191f1e7f661"
      },
      "source": [
        "model.crf.forward(logits, train_dataset[0:2][3], train_dataset[0:2][2].byte())"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-36.3391, grad_fn=<SumBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBeYV1uDDOvk"
      },
      "source": [
        "### Cross-validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ByjTJrC8P2K"
      },
      "source": [
        "Fix some train parameters\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AnXnYO3H8GDs"
      },
      "source": [
        "RANDOM_SEED = 42\n",
        "\n",
        "N_FOLDS = 3\n",
        "\n",
        "N_EPOCHS = 5"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rl13L8v75q0t"
      },
      "source": [
        "kf = KFold(n_splits=N_FOLDS, shuffle=True, random_state=RANDOM_SEED)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_7d6NpZOZ4w"
      },
      "source": [
        "# model = BEboc(batch_size=BATCH_SIZE, hidden_size=128, num_labels=len(tag2idx),\n",
        "#                     bert_layers=2, concat=False)\n",
        "# model.to(device)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJR2I5SCOi_E"
      },
      "source": [
        "# opt = AdamW(params=model.parameters(),lr=1e-3)\n",
        "# train(model, train_dataloader, opt)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "BYCHQ6sboU8R",
        "outputId": "cc13e749-d5e1-494f-baef-4df279f8f019"
      },
      "source": [
        "%time\n",
        "param_grid = {\n",
        "    'opt': ['AdamW'],\n",
        "    'lr': [3e-4, 7e-4, 1e-3],\n",
        "    'bert_layers': [2,3],\n",
        "    'concat': [True, False],\n",
        "    'max_grad_norm': [None]#[1., None]\n",
        "}\n",
        "\n",
        "param_grid = {\n",
        "    'opt': ['AdamW'],\n",
        "    'lr': [1e-3],\n",
        "    'bert_layers': [2],\n",
        "    'concat': [False],\n",
        "    'max_grad_norm': [None]\n",
        "}\n",
        "\n",
        "grid = ParameterGrid(param_grid)\n",
        "\n",
        "params_results = {}\n",
        "\n",
        "for m, ps in enumerate(grid):\n",
        "  print(f\"Model #{m} of {len(grid)}\")\n",
        "  _p_r = {'params': ps}\n",
        "  \n",
        "  mean_train_losses = 0\n",
        "  mean_valid_losses = 0\n",
        "  mean_valid_accs = 0\n",
        "  mean_valid_f1s = 0\n",
        "\n",
        "  for i, (train_index, valid_index) in enumerate(kf.split(train_data)):\n",
        "    train_fold = torch.utils.data.Subset(train_data, train_index)\n",
        "    valid_fold = torch.utils.data.Subset(train_data, valid_index)\n",
        "    train_dataloader = DataLoader(train_fold, batch_size=BATCH_SIZE)\n",
        "    valid_dataloader = DataLoader(valid_fold, batch_size=BATCH_SIZE)\n",
        "\n",
        "    model = BEboc(batch_size=BATCH_SIZE, hidden_size=128, num_labels=len(tag2idx),\n",
        "                    bert_layers=ps['bert_layers'], concat=ps['concat'])\n",
        "    model.to(device)\n",
        "\n",
        "    if ps['opt'] == 'Adam':\n",
        "      optimizer = torch.optim.Adam(params=model.parameters(),lr=ps['lr'])\n",
        "    else:\n",
        "      optimizer = AdamW(params=model.parameters(),lr=ps['lr'])\n",
        "\n",
        "    train_losses, valid_losses, valid_accs, valid_f1s = train(model,\n",
        "                                            train_dataloader,\n",
        "                                            optimizer,\n",
        "                                            n_epoch=N_EPOCHS,\n",
        "                                            max_grad_norm=ps['max_grad_norm'],\n",
        "                                            valid_dataloader=valid_dataloader,\n",
        "                                            show_info=False)\n",
        "    \n",
        "    mean_train_losses += np.array(train_losses)\n",
        "    mean_valid_losses += np.array(valid_losses)\n",
        "    mean_valid_accs += np.array(valid_accs)\n",
        "    mean_valid_f1s += np.array(valid_f1s)\n",
        "  \n",
        "  mean_train_losses /= N_FOLDS\n",
        "  mean_valid_losses /= N_FOLDS\n",
        "  mean_valid_accs /= N_FOLDS\n",
        "  mean_valid_f1s /= N_FOLDS\n",
        "  _p_r['mean_train_losses'] = list(mean_train_losses)\n",
        "  _p_r['mean_valid_losses'] = list(mean_valid_losses)\n",
        "  _p_r['mean_valid_accs'] = list(mean_valid_accs)\n",
        "  _p_r['mean_valid_f1s'] = list(mean_valid_f1s)\n",
        "  params_results[m] = _p_r \n",
        "\n",
        "with open(\"/content/drive/My Drive/params_results.json\", \"w\") as w:\n",
        "  json.dump(params_results, w)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1e+03 ns, sys: 1e+03 ns, total: 2 Âµs\n",
            "Wall time: 4.29 Âµs\n",
            "Model #0 of 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-578de80884cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mtrain_fold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSubset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mvalid_fold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSubset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mtrain_dataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_fold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0mvalid_dataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_fold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'BATCH_SIZE' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPS7K3gVw3KU"
      },
      "source": [
        "with open(\"/content/drive/My Drive/params_results.json\", \"w\") as w:\n",
        "  json.dump(params_results, w)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_xcMVxJlxsn"
      },
      "source": [
        "After train on 1 epoch on small dataset the best result gave the model that concatenates two last bert layers and has learning rate 3e-4, so let's train such model on all train data. Also, let's increase LSTM hidden size to be 512 and use now linear scheduler."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMWe0ewXDUm0"
      },
      "source": [
        "### Final model train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVfn5z8DMXOd"
      },
      "source": [
        "N_EPOCHS = 20"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UrTQbk8byXP_"
      },
      "source": [
        "total_steps = len(train_dataloader) *  N_EPOCHS"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288,
          "referenced_widgets": [
            "083a05aad7a64bec9a3c7be8e7751ffa",
            "71da58d9e36f4ae0b12267dcd207f5be",
            "bd02ff649aa743b3a355da6c743a2a79",
            "513d4af266af44e3bc92e6ad7a9e680d",
            "69ba9dd5b0f94ca88883d0ad95e8177c",
            "8cbbb752157740b5a40cac13215d8f8e",
            "88278de257334ef98fef06eb3fbc9c85",
            "9924864ff37f4f0d856b42fa29124031",
            "f9243acdccc44954988f54efdb259f12",
            "8e06b96360d9439bb7d16cb697caac30",
            "704280aea6be4966a5313447bfa5aa53",
            "53007e451d9b404db1577d2f2174b835",
            "9267976ff3a94381b3b6354c7f93189d",
            "268662514dda42cab39cfa5656549a2d",
            "5f2297fb0b31448a9d6428394c067ec9",
            "294eeacf71c84bb5b8d38ecb9d3e2391"
          ]
        },
        "id": "r3hRyRjLMNvJ",
        "outputId": "0dbc8cab-4ef3-4737-b053-3b0cb9dc6173"
      },
      "source": [
        "model = BEboC(hidden_size=512, bert_layers=2)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "083a05aad7a64bec9a3c7be8e7751ffa",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f9243acdccc44954988f54efdb259f12",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=435779157.0, style=ProgressStyle(descriâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "downloading: 100%|##########| 336/336 [00:00<00:00, 201499.31B/s]\n",
            "downloading: 100%|##########| 112140184/112140184 [00:03<00:00, 32678180.30B/s]\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py:434: UserWarning: Setting attributes on ParameterList is not supported.\n",
            "  warnings.warn(\"Setting attributes on ParameterList is not supported.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "noc7jM-228Jf"
      },
      "source": [
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZtAb2SH5MPr_"
      },
      "source": [
        "optimizer = AdamW(params=model.parameters(),lr=3e-4)\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=total_steps\n",
        ")\n",
        "\n",
        "if device.type != 'cpu':\n",
        "    model.to(device)\n",
        "\n",
        "#train_losses, valid_losses, valid_accs, valid_f1s\n",
        "results = train(model, train_dataloader, optimizer, scheduler, n_epoch=N_EPOCHS,\n",
        "     validate=True, valid_dataloader=valid_dataloader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4tqWLr8kihG4"
      },
      "source": [
        "If we want to train model for more time"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_WyjXJoifw1"
      },
      "source": [
        "N_EPOCHS = 5\n",
        "total_steps = len(train_dataloader) *  N_EPOCHS\n",
        "\n",
        "optimizer = AdamW(params=model.parameters(),lr=1e-4)\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=total_steps\n",
        ")\n",
        "\n",
        "if device.type != 'cpu':\n",
        "    model.to(device)\n",
        "  \n",
        "model.train()\n",
        "\n",
        "#train_losses, valid_losses, valid_accs, valid_f1s\n",
        "results_1 = train(model, train_dataloader, optimizer, scheduler, n_epoch=N_EPOCHS,\n",
        "     validate=True, valid_dataloader=valid_dataloader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-0_1ZMOAvS0"
      },
      "source": [
        "If we want to plot the reults of learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L20ydosUhaCI"
      },
      "source": [
        "plt.figure(figsize=(8,6))\n",
        "plt.plot(results[0], label='train')\n",
        "plt.plot(results[1], label='valid', c='g')\n",
        "plt.ylabel(\"loss\")\n",
        "plt.xlabel(\"#epoch\")\n",
        "plt.xticks(np.arange(0,20,2))\n",
        "plt.grid()\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_55aneQlAzpC"
      },
      "source": [
        "If we want to evaluate model on the test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0bd-fXwgE0J"
      },
      "source": [
        "test_dataset, test_sampler, test_dataloader = create_dataloader(tokenizer, test_data, test_labels,\n",
        "                                                                   datatype='test',\n",
        "                                                                   desired_pad=max_seq_len)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ho1fi5rCMTJN"
      },
      "source": [
        "model.eval()\n",
        "test_losses = []\n",
        "true_labels = []\n",
        "pred_labels = []\n",
        "for step, batch in enumerate(test_dataloader):\n",
        "    # add batch to gpu\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    b_elmo_ids, b_bert_ids, b_input_mask, b_labels = batch\n",
        "    batch_true_labels = b_labels\n",
        "    for bl in batch_true_labels.detach().cpu().tolist():\n",
        "      tag_names = [idx2tag[i] for i in bl if idx2tag[i] != 'PAD']\n",
        "      true_labels.append(tag_names)\n",
        "    \n",
        "    # Always clear any previously calculated gradients before performing a backward pass.\n",
        "    # forward pass\n",
        "    # This will return the loss (rather than the model output)\n",
        "    # because we have provided the `labels`.\n",
        "    with torch.no_grad():\n",
        "        logits = model.forward(b_elmo_ids, b_bert_ids, b_input_mask.byte())\n",
        "        loss = model.crf.forward(logits, b_labels, b_input_mask.byte())\n",
        "        test_losses.append(loss.item())\n",
        "        tags = model.crf.decode(logits, b_input_mask.byte())\n",
        "    for t in tags:\n",
        "      tag_names = [idx2tag[i] for i in t]\n",
        "      pred_labels.append(tag_names)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWsV2OM_11Qy"
      },
      "source": [
        "f1_score(true_labels, pred_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97x4ZM_bBLE9"
      },
      "source": [
        "___"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Ab-dH8uikuU"
      },
      "source": [
        "torch.save(model, '/content/drive/My Drive/models/Elmo_BERT_biLSTM_oneCRF_final.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7wd1cGUgLIu"
      },
      "source": [
        "torch.save(model.state_dict(), '/content/drive/My Drive/models/ELmo_BERT_biLSTM_oneCRF_final_state_dict.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4iZbz4pAgg9"
      },
      "source": [
        "##Load the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlJ5NZwVi5iQ"
      },
      "source": [
        "model = torch.load('/content/drive/My Drive/models/BERT_biLSTM_oneCRF.pth',\n",
        "                   map_location=torch.device('cpu'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4LdgKkJXCdHU"
      },
      "source": [
        "model = torch.load('/content/drive/My Drive/models/Elmo_BERT_biLSTM_oneCRF.pth',\n",
        "                   map_location=torch.device('cpu'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l72fDasHEj_2"
      },
      "source": [
        "def load_checkpoint(tokenizer_path, checkpoint_path):\n",
        "    \"\"\"Loads both tokenizer and our pretrained model\"\"\"\n",
        "    tokenizer = tokenizer = BertTokenizer.from_pretrained(tokenizer_path)\n",
        "    checkpoint = torch.load(checkpoint_path)\n",
        "    model = checkpoint['model']\n",
        "    model.load_state_dict(checkpoint['state_dict'])\n",
        "    #for parameter in model.parameters():\n",
        "    #    parameter.requires_grad = False\n",
        "\n",
        "    model.eval()\n",
        "    return tokenizer, model"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36G1_emY6nIF",
        "outputId": "94ce8141-ec1f-43ef-bd93-98bf72bbd5b1"
      },
      "source": [
        "tokenizer, model = load_checkpoint('/content/drive/My Drive/models/ElMo_BERT_biLSTM_oneCRF_19_tokenizer.pth',\n",
        "                                     '/content/drive/My Drive/models/ElMo_BERT_biLSTM_oneCRF_19_state_dict.pth')"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py:434: UserWarning: Setting attributes on ParameterList is not supported.\n",
            "  warnings.warn(\"Setting attributes on ParameterList is not supported.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "beoXMar6EssL"
      },
      "source": [
        "train_dataset, train_sampler, train_dataloader = create_dataloader(tokenizer, train_data, train_labels)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lAhyHC69E8qd"
      },
      "source": [
        "for s in train_dataset:\n",
        "  max_seq_len = s[1].shape[0]\n",
        "  break"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3PnWw3uSEptE"
      },
      "source": [
        "test_dataset, test_sampler, test_dataloader = create_dataloader(tokenizer, test_data, test_labels,\n",
        "                                                                   datatype='test',\n",
        "                                                                   desired_pad=max_seq_len)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J3j0QLosgsvL",
        "outputId": "55ac4c06-2dd8-4031-a0dd-4c3e63f68696"
      },
      "source": [
        "model.to(device)\n",
        "model.eval()\n",
        "test_losses = []\n",
        "true_labels = []\n",
        "pred_labels = []\n",
        "for step, batch in enumerate(test_dataloader):\n",
        "    # add batch to gpu\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    b_elmo_ids, b_bert_ids, b_input_mask, b_labels = batch\n",
        "    batch_true_labels = b_labels\n",
        "    for bl in batch_true_labels.detach().cpu().tolist():\n",
        "      tag_names = [idx2tag[i] for i in bl if idx2tag[i] != 'PAD']\n",
        "      true_labels.append(tag_names)\n",
        "    \n",
        "    # Always clear any previously calculated gradients before performing a backward pass.\n",
        "    # forward pass\n",
        "    # This will return the loss (rather than the model output)\n",
        "    # because we have provided the `labels`.\n",
        "    with torch.no_grad():\n",
        "        logits = model.forward(b_elmo_ids, b_bert_ids, b_input_mask.byte())\n",
        "        loss = model.crf.forward(logits, b_labels, b_input_mask.byte())\n",
        "        test_losses.append(loss.item())\n",
        "        tags = model.crf.decode(logits, b_input_mask.byte())\n",
        "    for t in tags:\n",
        "      tag_names = [idx2tag[i] for i in t]\n",
        "      pred_labels.append(tag_names)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py:434: UserWarning: Setting attributes on ParameterList is not supported.\n",
            "  warnings.warn(\"Setting attributes on ParameterList is not supported.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wfdmdhpghyar",
        "outputId": "64c845c4-3c93-4dcc-f28f-4d1bba83deae"
      },
      "source": [
        "f1_score(true_labels, pred_labels)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8405783838198957"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZNZ2mHjaE0Vp"
      },
      "source": [
        "## FINETUNE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eB8HDqLBE4EP"
      },
      "source": [
        "class BEbiC(nn.Module):\n",
        "    \"\"\"\n",
        "    BERT+Elmo+biLSTM+CRFs\n",
        "    \"\"\"\n",
        "    def __init__(self, hidden_size=128, num_labels=len(tag2idx), num_heads=1,\n",
        "                 elmo_layers=2, bert_layers=1, concat_bert=True, bilstm_layers=1):\n",
        "        \"\"\"\n",
        "        Creates model\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        hidden_size:\n",
        "          LSTM parameter\n",
        "        num_labels:\n",
        "          The number of CRF labels\n",
        "        num_heads:\n",
        "          The number of CRF heads\n",
        "        elmo_layers: int, default=2\n",
        "          Num of ELMo layers to be considered\n",
        "        bert_layers: int, default=1\n",
        "          Num of final BERT hidden layers to be used as embedding vector.\n",
        "        concat_bert: bool, default=True\n",
        "          Whether to concat (True) or sum (False) last BERT hidden layers.\n",
        "        bilstm_layers: int, default=1\n",
        "        \"\"\"\n",
        "        super(BEbiC, self).__init__()\n",
        "\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_labels = num_labels\n",
        "        self.num_heads = num_heads\n",
        "        self.elmo_layers = elmo_layers\n",
        "        self.bert_layers = bert_layers\n",
        "        self.concat_bert = concat_bert\n",
        "        self.bilstm_layers = bilstm_layers\n",
        "        \n",
        "        self.bert = BertForTokenClassification.from_pretrained(\n",
        "                        BERT_MODEL,\n",
        "                        output_hidden_states=True)\n",
        "        \n",
        "        for pars in self.bert.parameters():\n",
        "            pars.requires_grad = False\n",
        "        \n",
        "        bert_embedding_dim = self.bert.config.to_dict()['hidden_size']\n",
        "\n",
        "        self.elmo = Elmo(options_file, weight_file, self.elmo_layers, dropout=0, requires_grad=False)\n",
        "        \n",
        "        elmo_embedding_dim = 512 # it's always fixed\n",
        "\n",
        "        if self.concat_bert:\n",
        "          self.linear1 = nn.Linear(bert_embedding_dim*self.bert_layers+elmo_embedding_dim*self.elmo_layers, 1024)\n",
        "        else:\n",
        "          self.linear1 = nn.Linear(bert_embedding_dim+elmo_embedding_dim*self.elmo_layers, 1024)\n",
        "        \n",
        "        self.bilstm = nn.LSTM(1024, self.hidden_size, self.bilstm_layers, bidirectional=True)\n",
        "        \n",
        "        # multiple heads\n",
        "        self.linears2 = []\n",
        "        self.crfs = []\n",
        "\n",
        "        for _ in range(self.num_heads):\n",
        "          self.linears2.append(nn.Linear(self.hidden_size*2, self.num_labels))\n",
        "          self.crfs.append(CRF(num_tags=self.num_labels, batch_first=True))\n",
        "    \n",
        "    def forward(self, elmo_ids, bert_ids, attention_mask):\n",
        "        \"\"\"\n",
        "        Forward propogate of model.\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        elmo_ids:\n",
        "        bert_ids:\n",
        "        \n",
        "        Returns\n",
        "        -------\n",
        "        Logits or list of logits if number of heads > 1\n",
        "        \n",
        "        \"\"\"\n",
        "\n",
        "        bert_hiddens = self.bert(bert_ids, attention_mask=attention_mask)[1]\n",
        "        elmo_hiddens = self.elmo(elmo_ids)\n",
        "\n",
        "        if self.concat_bert:\n",
        "            bert_embedding = torch.cat(bert_hiddens[-self.bert_layers:], dim=2)#[bert_hiddens[-i] for i in range(-1, -self.bert_layers-1, -1)], dim=0)\n",
        "        else:\n",
        "            emb_sum = 0\n",
        "            for h in bert_hiddens[-self.bert_layers:]:\n",
        "                emb_sum += h\n",
        "            bert_embedding = emb_sum\n",
        "\n",
        "        elmo_bert_embeddings = torch.clone(bert_embedding)\n",
        "\n",
        "        for el_hi in elmo_hiddens['elmo_representations']:\n",
        "            elmo_bert_embeddings = torch.cat((elmo_bert_embeddings, el_hi), dim=-1)\n",
        "\n",
        "        linear1_output = nn.functional.relu(self.linear1(elmo_bert_embeddings))\n",
        "\n",
        "        bilstm_output, (h_n, c_n) = self.bilstm(linear1_output)\n",
        "\n",
        "        linears2_outputs = []\n",
        "        for i in range(self.num_heads):\n",
        "          linears2_output.append(nn.functional.relu(self.linears2[i](bilstm_output)))\n",
        "\n",
        "        # returning logits\n",
        "        return linears2_outputs[0] if self.num_heads==1 else linears2_outputs"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHEObiFiPwih"
      },
      "source": [
        "def new_train(model, train_dataloaders, optimizer, scheduler=None, n_epoch=5,\n",
        "          max_grad_norm=None, validate=True, valid_dataloaders=None,\n",
        "          show_info=True, save_model=True):\n",
        "\n",
        "    loss_values = []\n",
        "    if validate and valid_dataloaders is not None:\n",
        "        validation_loss_values = []\n",
        "        valid_accuracies = []\n",
        "        valid_f1_scores = []\n",
        "    \n",
        "    if isinstance(train_dataloaders, list):\n",
        "      n_heads = len(train_dataloaders)\n",
        "    else:\n",
        "      n_heads = 1\n",
        "      train_dataloader = train_dataloaders\n",
        "\n",
        "    for e in range(n_epoch):\n",
        "        if show_info:\n",
        "          print(f\"\\nEpoch #{e}\")\n",
        "        # Training\n",
        "\n",
        "        model.train()\n",
        "\n",
        "        total_loss = 0\n",
        "\n",
        "        if show_info:\n",
        "            _loader = train_dataloader if n_heads == 1 else train_dataloader[0]\n",
        "            enumerator = enumerate(tqdm.tqdm(_loader, position=0, leave=True))\n",
        "        else:\n",
        "            enumerator = enumerate(train_dataloader)\n",
        "\n",
        "        for step, batch in enumerator:\n",
        "            if device.type != 'cpu':\n",
        "                batch = tuple(t.to(device) for t in batch)\n",
        "            b_elmo_ids, b_bert_ids, b_input_mask, b_labels = batch\n",
        "            model.zero_grad()\n",
        "\n",
        "            logits = model.forward(b_elmo_ids, b_bert_ids, b_input_mask.byte())\n",
        "            \n",
        "            # because we need negative log likelyhood\n",
        "            loss = -1*model.crf.forward(logits, b_labels, mask=b_input_mask.byte())\n",
        "\n",
        "            loss.backward()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            if show_info and (step+1) % 10 == 0:\n",
        "                print(f\"\\n{step}: avg loss per batch: {total_loss/step}\\n\")\n",
        "\n",
        "            if max_grad_norm is not None:\n",
        "                torch.nn.utils.clip_grad_norm_(parameters=model.parameters(),\n",
        "                                            max_norm=max_grad_norm)\n",
        "\n",
        "            optimizer.step()\n",
        "\n",
        "            if scheduler is not None:\n",
        "                scheduler.step()\n",
        "\n",
        "        avg_train_loss = total_loss / len(train_dataloader)\n",
        "        if show_info:\n",
        "            print(f\"Average train loss: {avg_train_loss}\")\n",
        "\n",
        "        loss_values.append(avg_train_loss)\n",
        "\n",
        "        if validate and valid_dataloader is not None:\n",
        "          # Validation\n",
        "\n",
        "            model.eval()\n",
        "\n",
        "            eval_loss, eval_accuracy = 0, 0\n",
        "            predictions, true_labels = [], []\n",
        "\n",
        "            for batch in valid_dataloader:\n",
        "                if device.type != 'cpu':\n",
        "                    batch = tuple(t.to(device) for t in batch)\n",
        "                b_elmo_ids, b_bert_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "                with torch.no_grad():\n",
        "                    logits = model.forward(b_elmo_ids, b_bert_ids, b_input_mask.byte())\n",
        "                    loss = -1*model.crf.forward(logits, b_labels, mask=b_input_mask.byte())\n",
        "                    tags = model.crf.decode(logits, mask=b_input_mask.byte())\n",
        "\n",
        "                # move loss to cpu\n",
        "                eval_loss += loss.item()\n",
        "                predictions.extend(tags)\n",
        "                labels_ = b_labels.detach().cpu().numpy()\n",
        "                true_labels.extend(labels_)\n",
        "\n",
        "            eval_loss = eval_loss / len(valid_dataloader)\n",
        "            validation_loss_values.append(eval_loss)\n",
        "            if show_info:\n",
        "                print(f\"Validation loss: {eval_loss}\")\n",
        "\n",
        "            all_predicted_tags = []\n",
        "            for s in predictions:\n",
        "                tag_names = [idx2tag[i] for i in s]\n",
        "                all_predicted_tags.append(tag_names)\n",
        "\n",
        "            all_true_tags = []\n",
        "            for s in true_labels:\n",
        "                tag_names = [idx2tag[i] for i in s if idx2tag[i] != 'PAD']\n",
        "                all_true_tags.append(tag_names)\n",
        "\n",
        "            valid_acc = accuracy_score(all_predicted_tags, all_true_tags)\n",
        "            valid_f1 = f1_score(all_predicted_tags, all_true_tags)\n",
        "            valid_accuracies.append(valid_acc)\n",
        "            valid_f1_scores.append(valid_f1)\n",
        "\n",
        "            if show_info:\n",
        "                print(f\"Validation accuracy: {valid_acc}\")\n",
        "                print(f\"Validation F1-score: {valid_f1}\\n\")\n",
        "            \n",
        "        if save_model and (e+1)%10 == 0:\n",
        "            tokenizer.save_pretrained(f'/content/drive/My Drive/models/ElMo_BERT_biLSTM_oneCRF_{e}_tokenizer.pth')\n",
        "            checkpoint = {'model': BEboC(hidden_size=512, bert_layers=2),\n",
        "                          'state_dict': model.state_dict(), \n",
        "                          'optimizer' : optimizer.state_dict()}\n",
        "\n",
        "            torch.save(checkpoint,\n",
        "                        f'/content/drive/My Drive/models/ElMo_BERT_biLSTM_oneCRF_{e}_state_dict.pth')\n",
        "\n",
        "    return loss_values, validation_loss_values, valid_accuracies, valid_f1_scores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rO4veiB8Qe08"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}