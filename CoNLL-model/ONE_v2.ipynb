{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Копия notebook.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "5B0vXWGpjJvP",
        "Rc7JfSK1Hs8Q",
        "LFu_4fMKPCjv",
        "RBeYV1uDDOvk",
        "dB8TmGLD29DC",
        "W4iZbz4pAgg9",
        "lEjtb2Ft2Yqb"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "dcba835f5daf4a259414e78325612127": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9804c2530f574607ba0145d11b34021a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4730f7c53e934eed9746e7411aeb6f0a",
              "IPY_MODEL_b85d384d3a694a63ae7ae3122a5c3c8e"
            ]
          }
        },
        "9804c2530f574607ba0145d11b34021a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4730f7c53e934eed9746e7411aeb6f0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1d25b797f742400992fddbf4d5e20c55",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 213450,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 213450,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9c6eaaf4edeb439db234767a9693c8fe"
          }
        },
        "b85d384d3a694a63ae7ae3122a5c3c8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_309646a6259a462e8e1301c63e37bf37",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 213k/213k [00:00&lt;00:00, 2.78MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6c3c3a5f945c444ebe1e28c6d765db7d"
          }
        },
        "1d25b797f742400992fddbf4d5e20c55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9c6eaaf4edeb439db234767a9693c8fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "309646a6259a462e8e1301c63e37bf37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6c3c3a5f945c444ebe1e28c6d765db7d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f06d4f3f09e44d7281575f8ee9b8b8eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a710f50332c04a2a8b4e65c7c3d1dc30",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9a2e456c1e864e098a5eff059e3920ae",
              "IPY_MODEL_28631b66e20046ad8dc16a9a576160fc"
            ]
          }
        },
        "a710f50332c04a2a8b4e65c7c3d1dc30": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9a2e456c1e864e098a5eff059e3920ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4089fd51dead419189a1c9d0856e992f",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9b29bc675ea7456ba9724c44986d3b43"
          }
        },
        "28631b66e20046ad8dc16a9a576160fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2c71105966934923afb6d0d923884af4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:08&lt;00:00, 48.9B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f7932c6432954d01b73b3a856116991c"
          }
        },
        "4089fd51dead419189a1c9d0856e992f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9b29bc675ea7456ba9724c44986d3b43": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2c71105966934923afb6d0d923884af4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f7932c6432954d01b73b3a856116991c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ade080fbbbfb4bb080edbf58da5ad5fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f5b9ac612c064b949099708ccd020f08",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7bd992fe00dd44a6a686325e71f23cad",
              "IPY_MODEL_8dde2b3b744e48abb7c67df105a09e68"
            ]
          }
        },
        "f5b9ac612c064b949099708ccd020f08": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7bd992fe00dd44a6a686325e71f23cad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1af0a6b1f7654da0b54ebbe8cf7ea5ce",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 435779157,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 435779157,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ca2c3838700b481198277fbb72a7f6c6"
          }
        },
        "8dde2b3b744e48abb7c67df105a09e68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c85299002a1941259f2c6343016bd7a6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 436M/436M [00:08&lt;00:00, 51.8MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_12df2642d803487fa9575e80c738012d"
          }
        },
        "1af0a6b1f7654da0b54ebbe8cf7ea5ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ca2c3838700b481198277fbb72a7f6c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c85299002a1941259f2c6343016bd7a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "12df2642d803487fa9575e80c738012d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dg8fjZSik8Pq",
        "outputId": "b1cd977e-c6fd-42f7-f50e-0292adaa31aa"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7hQb7BQj3qD"
      },
      "source": [
        "PATH_TO_PROJECT = '/content/drive/My Drive/Serious/'\n",
        "# path to conll class as well as to conll data\n",
        "PATH_TO_CONLL = PATH_TO_PROJECT + 'coNLL/'\n",
        "PATH_TO_TAG2IDX = PATH_TO_CONLL + 'tag2idx.json'\n",
        "PATH_TO_ONE_TAG2IDX = PATH_TO_CONLL + 'one_tag2idx.json'\n",
        "PATH_TO_CHECKPOINT = PATH_TO_PROJECT + 'Models_results/'"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5B0vXWGpjJvP"
      },
      "source": [
        "### Installing all packages for colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X1EcfRFCkM0P",
        "outputId": "e34288cc-4bc6-4089-d918-9f9ab9562e83"
      },
      "source": [
        "!pip install -r '/content/drive/My Drive/Serious/requirements.txt'"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers==4.3.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f9/54/5ca07ec9569d2f232f3166de5457b63943882f7950ddfcc887732fc7fb23/transformers-4.3.3-py3-none-any.whl (1.9MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9MB 20.3MB/s \n",
            "\u001b[?25hCollecting allennlp~=2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/12/76/6aac1f03aa96f7d4f6fcb593b3632156747b25ef2f3348e6d7474b1b8aab/allennlp-2.3.0-py3-none-any.whl (598kB)\n",
            "\u001b[K     |████████████████████████████████| 604kB 51.3MB/s \n",
            "\u001b[?25hCollecting seqeval~=1.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9d/2d/233c79d5b4e5ab1dbf111242299153f3caddddbb691219f363ad55ce783d/seqeval-1.2.2.tar.gz (43kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 7.7MB/s \n",
            "\u001b[?25hCollecting pytorch-crf~=0.7\n",
            "  Downloading https://files.pythonhosted.org/packages/96/7d/4c4688e26ea015fc118a0327e5726e6596836abce9182d3738be8ec2e32a/pytorch_crf-0.7.2-py3-none-any.whl\n",
            "Collecting torch~=1.7.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/90/5d/095ddddc91c8a769a68c791c019c5793f9c4456a688ddd235d6670924ecb/torch-1.7.1-cp37-cp37m-manylinux1_x86_64.whl (776.8MB)\n",
            "\u001b[K     |████████████████████████████████| 776.8MB 22kB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.3->-r /content/drive/My Drive/Serious/requirements.txt (line 1)) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.3->-r /content/drive/My Drive/Serious/requirements.txt (line 1)) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.3->-r /content/drive/My Drive/Serious/requirements.txt (line 1)) (3.10.1)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/08/cd/342e584ee544d044fb573ae697404ce22ede086c9e87ce5960772084cad0/sacremoses-0.0.44.tar.gz (862kB)\n",
            "\u001b[K     |████████████████████████████████| 870kB 51.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.3->-r /content/drive/My Drive/Serious/requirements.txt (line 1)) (3.0.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.3->-r /content/drive/My Drive/Serious/requirements.txt (line 1)) (20.9)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.3->-r /content/drive/My Drive/Serious/requirements.txt (line 1)) (4.41.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.3->-r /content/drive/My Drive/Serious/requirements.txt (line 1)) (1.19.5)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/04/5b870f26a858552025a62f1649c20d29d2672c02ff3c3fb4c688ca46467a/tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 42.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from allennlp~=2.0->-r /content/drive/My Drive/Serious/requirements.txt (line 2)) (3.2.5)\n",
            "Requirement already satisfied: torchvision<0.10.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from allennlp~=2.0->-r /content/drive/My Drive/Serious/requirements.txt (line 2)) (0.9.1+cu101)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.7/dist-packages (from allennlp~=2.0->-r /content/drive/My Drive/Serious/requirements.txt (line 2)) (8.7.0)\n",
            "Collecting boto3<2.0,>=1.14\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/b3/8c889dd3d5ae47a9c4468cc20ef980adc4a16f06f0937ab33f78b58b5eda/boto3-1.17.53-py2.py3-none-any.whl (131kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 61.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy<3.1,>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from allennlp~=2.0->-r /content/drive/My Drive/Serious/requirements.txt (line 2)) (2.2.4)\n",
            "Collecting jsonnet>=0.10.0; sys_platform != \"win32\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/42/40/6f16e5ac994b16fa71c24310f97174ce07d3a97b433275589265c6b94d2b/jsonnet-0.17.0.tar.gz (259kB)\n",
            "\u001b[K     |████████████████████████████████| 266kB 59.7MB/s \n",
            "\u001b[?25hCollecting wandb<0.11.0,>=0.10.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d5/5d/20ab24504de2669c9a76a50c9bdaeb44a440b0e5e4b92be881ed323857b1/wandb-0.10.26-py2.py3-none-any.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 41.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from allennlp~=2.0->-r /content/drive/My Drive/Serious/requirements.txt (line 2)) (1.4.1)\n",
            "Requirement already satisfied: lmdb in /usr/local/lib/python3.7/dist-packages (from allennlp~=2.0->-r /content/drive/My Drive/Serious/requirements.txt (line 2)) (0.99)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 46.5MB/s \n",
            "\u001b[?25hCollecting tensorboardX>=1.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/84/46421bd3e0e89a92682b1a38b40efc22dafb6d8e3d947e4ceefd4a5fabc7/tensorboardX-2.2-py2.py3-none-any.whl (120kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 60.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytest in /usr/local/lib/python3.7/dist-packages (from allennlp~=2.0->-r /content/drive/My Drive/Serious/requirements.txt (line 2)) (3.6.4)\n",
            "Collecting overrides==3.1.0\n",
            "  Downloading https://files.pythonhosted.org/packages/ff/b1/10f69c00947518e6676bbd43e739733048de64b8dd998e9c2d5a71f44c5d/overrides-3.1.0.tar.gz\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from allennlp~=2.0->-r /content/drive/My Drive/Serious/requirements.txt (line 2)) (2.10.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from allennlp~=2.0->-r /content/drive/My Drive/Serious/requirements.txt (line 2)) (0.22.2.post1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch~=1.7.1->-r /content/drive/My Drive/Serious/requirements.txt (line 5)) (3.7.4.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.3.3->-r /content/drive/My Drive/Serious/requirements.txt (line 1)) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.3.3->-r /content/drive/My Drive/Serious/requirements.txt (line 1)) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.3.3->-r /content/drive/My Drive/Serious/requirements.txt (line 1)) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.3.3->-r /content/drive/My Drive/Serious/requirements.txt (line 1)) (2020.12.5)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers==4.3.3->-r /content/drive/My Drive/Serious/requirements.txt (line 1)) (3.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.3.3->-r /content/drive/My Drive/Serious/requirements.txt (line 1)) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.3.3->-r /content/drive/My Drive/Serious/requirements.txt (line 1)) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.3.3->-r /content/drive/My Drive/Serious/requirements.txt (line 1)) (1.0.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.3.3->-r /content/drive/My Drive/Serious/requirements.txt (line 1)) (2.4.7)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision<0.10.0,>=0.8.1->allennlp~=2.0->-r /content/drive/My Drive/Serious/requirements.txt (line 2)) (7.1.2)\n",
            "Collecting botocore<1.21.0,>=1.20.53\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/4e/232e261b739534e216f28d935a06c44840221c3476ebcdb411cd0fc2bf16/botocore-1.20.53-py2.py3-none-any.whl (7.4MB)\n",
            "\u001b[K     |████████████████████████████████| 7.4MB 40.8MB/s \n",
            "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n",
            "Collecting s3transfer<0.4.0,>=0.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/00/89/0cb4e92c239e6425b9b0035227b8cdf9d3d098a5c9e95632c3815df63a09/s3transfer-0.3.7-py2.py3-none-any.whl (73kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 12.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1,>=2.1.0->allennlp~=2.0->-r /content/drive/My Drive/Serious/requirements.txt (line 2)) (7.4.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1,>=2.1.0->allennlp~=2.0->-r /content/drive/My Drive/Serious/requirements.txt (line 2)) (1.0.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1,>=2.1.0->allennlp~=2.0->-r /content/drive/My Drive/Serious/requirements.txt (line 2)) (0.8.2)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1,>=2.1.0->allennlp~=2.0->-r /content/drive/My Drive/Serious/requirements.txt (line 2)) (3.0.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1,>=2.1.0->allennlp~=2.0->-r /content/drive/My Drive/Serious/requirements.txt (line 2)) (1.1.3)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1,>=2.1.0->allennlp~=2.0->-r /content/drive/My Drive/Serious/requirements.txt (line 2)) (1.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.1,>=2.1.0->allennlp~=2.0->-r /content/drive/My Drive/Serious/requirements.txt (line 2)) (54.2.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1,>=2.1.0->allennlp~=2.0->-r /content/drive/My Drive/Serious/requirements.txt (line 2)) (1.0.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1,>=2.1.0->allennlp~=2.0->-r /content/drive/My Drive/Serious/requirements.txt (line 2)) (2.0.5)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1,>=2.1.0->allennlp~=2.0->-r /content/drive/My Drive/Serious/requirements.txt (line 2)) (0.4.1)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb<0.11.0,>=0.10.0->allennlp~=2.0->-r /content/drive/My Drive/Serious/requirements.txt (line 2)) (2.3)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb<0.11.0,>=0.10.0->allennlp~=2.0->-r /content/drive/My Drive/Serious/requirements.txt (line 2)) (3.12.4)\n",
            "Collecting pathtools\n",
            "  Downloading https://files.pythonhosted.org/packages/e7/7f/470d6fcdf23f9f3518f6b0b76be9df16dcc8630ad409947f8be2eb0ed13a/pathtools-0.1.2.tar.gz\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading https://files.pythonhosted.org/packages/f5/e8/f6bd1eee09314e7e6dee49cbe2c5e22314ccdb38db16c9fc72d2fa80d054/docker_pycreds-0.4.0-py2.py3-none-any.whl\n",
            "Collecting GitPython>=1.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/99/98019716955ba243657daedd1de8f3a88ca1f5b75057c38e959db22fb87b/GitPython-3.1.14-py3-none-any.whl (159kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 58.3MB/s \n",
            "\u001b[?25hCollecting shortuuid>=0.5.0\n",
            "  Downloading https://files.pythonhosted.org/packages/25/a6/2ecc1daa6a304e7f1b216f0896b26156b78e7c38e1211e9b798b4716c53d/shortuuid-1.0.1-py3-none-any.whl\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb<0.11.0,>=0.10.0->allennlp~=2.0->-r /content/drive/My Drive/Serious/requirements.txt (line 2)) (5.4.8)\n",
            "Collecting sentry-sdk>=0.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f3/92/5a33be64990ba815364a8f2dd9e6f51de60d23dfddafb4f1fc5577d4dc64/sentry_sdk-1.0.0-py2.py3-none-any.whl (131kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 60.9MB/s \n",
            "\u001b[?25hCollecting subprocess32>=3.5.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/c8/564be4d12629b912ea431f1a50eb8b3b9d00f1a0b1ceff17f266be190007/subprocess32-3.5.4.tar.gz (97kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 13.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb<0.11.0,>=0.10.0->allennlp~=2.0->-r /content/drive/My Drive/Serious/requirements.txt (line 2)) (2.8.1)\n",
            "Collecting configparser>=3.8.1\n",
            "  Downloading https://files.pythonhosted.org/packages/fd/01/ff260a18caaf4457eb028c96eeb405c4a230ca06c8ec9c1379f813caa52e/configparser-5.0.2-py3-none-any.whl\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb<0.11.0,>=0.10.0->allennlp~=2.0->-r /content/drive/My Drive/Serious/requirements.txt (line 2)) (3.13)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp~=2.0->-r /content/drive/My Drive/Serious/requirements.txt (line 2)) (0.7.1)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp~=2.0->-r /content/drive/My Drive/Serious/requirements.txt (line 2)) (1.4.0)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp~=2.0->-r /content/drive/My Drive/Serious/requirements.txt (line 2)) (1.10.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp~=2.0->-r /content/drive/My Drive/Serious/requirements.txt (line 2)) (20.3.0)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ea/e8/f414d1a4f0bbc668ed441f74f44c116d9816833a48bf81d22b697090dba8/gitdb-4.0.7-py3-none-any.whl (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 9.5MB/s \n",
            "\u001b[?25hCollecting smmap<5,>=3.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/68/ee/d540eb5e5996eb81c26ceffac6ee49041d473bc5125f2aa995cf51ec1cf1/smmap-4.0.0-py2.py3-none-any.whl\n",
            "Building wheels for collected packages: seqeval, sacremoses, jsonnet, overrides, pathtools, subprocess32\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-cp37-none-any.whl size=16172 sha256=67af9fadb19b700f78d076e5b9206b3027376307cc51ce6bbcb60b1e264bc3ea\n",
            "  Stored in directory: /root/.cache/pip/wheels/52/df/1b/45d75646c37428f7e626214704a0e35bd3cfc32eda37e59e5f\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.44-cp37-none-any.whl size=886084 sha256=8c9357c4ee89b8f07365cefa1b81c4c89ba8eb1af9bb524f4fcd8324553a2aec\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/fb/c0/13ab4d63d537658f448366744654323077c4d90069b6512f3c\n",
            "  Building wheel for jsonnet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jsonnet: filename=jsonnet-0.17.0-cp37-cp37m-linux_x86_64.whl size=3388735 sha256=76ee5b4a4c80dca69bebcfe4a58ec95f6c6895d261e35bb1fc38fed8f6e49bf2\n",
            "  Stored in directory: /root/.cache/pip/wheels/26/7a/37/7dbcc30a6b4efd17b91ad1f0128b7bbf84813bd4e1cfb8c1e3\n",
            "  Building wheel for overrides (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for overrides: filename=overrides-3.1.0-cp37-none-any.whl size=10174 sha256=396dae7f99ad74c994ba0c9e4fdae43f0142f467743c6e9b2a408fe4be9eaf87\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/24/13/6ef8600e6f147c95e595f1289a86a3cc82ed65df57582c65a9\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-cp37-none-any.whl size=8786 sha256=3ae60dfd661f56a3e2cbecb01186e9fed59224a5e20022985a5bb870b60b9b04\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/04/79/c3b0c3a0266a3cb4376da31e5bfe8bba0c489246968a68e843\n",
            "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for subprocess32: filename=subprocess32-3.5.4-cp37-none-any.whl size=6489 sha256=93f0c4e54a20f6e28f3b036ff4a66ecee0077d1c6cdc80563d74e81d1cbdbc04\n",
            "  Stored in directory: /root/.cache/pip/wheels/68/39/1a/5e402bdfdf004af1786c8b853fd92f8c4a04f22aad179654d1\n",
            "Successfully built seqeval sacremoses jsonnet overrides pathtools subprocess32\n",
            "\u001b[31mERROR: torchvision 0.9.1+cu101 has requirement torch==1.8.1, but you'll have torch 1.7.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: torchtext 0.9.1 has requirement torch==1.8.1, but you'll have torch 1.7.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: botocore 1.20.53 has requirement urllib3<1.27,>=1.25.4, but you'll have urllib3 1.24.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: sacremoses, tokenizers, transformers, torch, jmespath, botocore, s3transfer, boto3, jsonnet, pathtools, docker-pycreds, smmap, gitdb, GitPython, shortuuid, sentry-sdk, subprocess32, configparser, wandb, sentencepiece, tensorboardX, overrides, allennlp, seqeval, pytorch-crf\n",
            "  Found existing installation: torch 1.8.1+cu101\n",
            "    Uninstalling torch-1.8.1+cu101:\n",
            "      Successfully uninstalled torch-1.8.1+cu101\n",
            "Successfully installed GitPython-3.1.14 allennlp-2.3.0 boto3-1.17.53 botocore-1.20.53 configparser-5.0.2 docker-pycreds-0.4.0 gitdb-4.0.7 jmespath-0.10.0 jsonnet-0.17.0 overrides-3.1.0 pathtools-0.1.2 pytorch-crf-0.7.2 s3transfer-0.3.7 sacremoses-0.0.44 sentencepiece-0.1.95 sentry-sdk-1.0.0 seqeval-1.2.2 shortuuid-1.0.1 smmap-4.0.0 subprocess32-3.5.4 tensorboardX-2.2 tokenizers-0.10.2 torch-1.7.1 transformers-4.3.3 wandb-0.10.26\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZSCzDWrGkvSF"
      },
      "source": [
        "###Importing packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHlIcoTU4xO9"
      },
      "source": [
        "import sys\n",
        "sys.path.append(PATH_TO_PROJECT)\n",
        "sys.path.append(PATH_TO_CONLL)\n",
        "\n",
        "from importlib import reload\n",
        "import conll as co\n",
        "\n",
        "import data_loaders as dalo\n",
        "\n",
        "from bert_config import *\n",
        "from elmo_config import *\n",
        "\n",
        "import model_utils as mu"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSczpEJZkrqr"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.optim import AdamW\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from transformers import BertForTokenClassification\n",
        "from allennlp.modules.elmo import Elmo, batch_to_ids\n",
        "\n",
        "from torchcrf import CRF\n",
        "\n",
        "from sklearn.model_selection import KFold, ParameterGrid\n",
        "\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "import matplotlib\n",
        "from matplotlib import pyplot as plt\n",
        "import json\n",
        "\n",
        "import gc\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRNrCVJDkeAx"
      },
      "source": [
        "Connect to device"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZD7U4Tz4kcx7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f48c147-7808-48ad-d0fa-61e64a223c9e"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_gpu = torch.cuda.device_count()\n",
        "\n",
        "print(torch.cuda.get_device_name(0))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqKg6gBfnHnZ"
      },
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKbM8puQnS5J"
      },
      "source": [
        "t = torch.cuda.get_device_properties(0).total_memory\n",
        "r = torch.cuda.memory_reserved(0) \n",
        "a = torch.cuda.memory_allocated(0)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RnYk4xX4k37T"
      },
      "source": [
        "### Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kG-jCX8jku-M"
      },
      "source": [
        "conll = co.CoNLL_old(PATH_TO_CONLL)\n",
        "for typ in conll.types:\n",
        "    conll.split_text_label(typ)\n",
        "conll.create_tag2idx(PATH_TO_TAG2IDX)\n",
        "conll.create_idx2tag()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IOMB_7-R5UUL"
      },
      "source": [
        "# with use it for evaluating on different tags\n",
        "conll_one_tag = co.CoNLL(PATH_TO_CONLL)\n",
        "# splitting raw data to sentences and labels\n",
        "for typ in conll_one_tag.types:\n",
        "    conll_one_tag.split_text_label(typ)\n",
        "\n",
        "# define set of all labels\n",
        "conll_one_tag.create_set_of_labels()\n",
        "\n",
        "# for multihead model\n",
        "conll_one_tag.create_tag2idx(PATH_TO_TAG2IDX)\n",
        "conll_one_tag.create_idx2tag()\n",
        "\n",
        "for typ in conll_one_tag.types:\n",
        "    # for multiple heads of CRF layer\n",
        "    conll_one_tag.create_one_labeled_data(typ)\n",
        "\n",
        "    # creating one_tag2idx dictionary\n",
        "    conll_one_tag.create_one_tag2idx(PATH_TO_ONE_TAG2IDX)\n",
        "    conll_one_tag.create_idx2one_tag()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IhhxetRPyhks",
        "outputId": "f5987d2b-46d6-4e9b-95ff-7d2515997d31"
      },
      "source": [
        "conll.idx2tag"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'PAD',\n",
              " 1: 'I-ORG',\n",
              " 2: 'O',\n",
              " 3: 'B-ORG',\n",
              " 4: 'B-PER',\n",
              " 5: 'B-MISC',\n",
              " 6: 'I-PER',\n",
              " 7: 'I-LOC',\n",
              " 8: 'B-LOC',\n",
              " 9: 'I-MISC'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXAiaxejk37V"
      },
      "source": [
        "### Tokenization with BertTokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Fig7rJPk37V"
      },
      "source": [
        "BERT (Bidirectional Encoder Representations from Transformers) is a method of pretraining language representations. These vectors (representations) are used as high-quality feature inputs to downstream models. BERT offers an advantage over models like Word2Vec, because while each word has a fixed representation under Word2Vec regardless of the context within which the word appears, BERT produces word representations that are dynamically informed by the words around them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nPqO5Tjsk37V"
      },
      "source": [
        "The Bert implementation comes with a pretrained tokenizer and a definied vocabulary. We load the one related to the smallest pre-trained model bert-base-cased. We use the cased variate since it is well suited for NER."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JyuwJkHzk37V",
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "dcba835f5daf4a259414e78325612127",
            "9804c2530f574607ba0145d11b34021a",
            "4730f7c53e934eed9746e7411aeb6f0a",
            "b85d384d3a694a63ae7ae3122a5c3c8e",
            "1d25b797f742400992fddbf4d5e20c55",
            "9c6eaaf4edeb439db234767a9693c8fe",
            "309646a6259a462e8e1301c63e37bf37",
            "6c3c3a5f945c444ebe1e28c6d765db7d"
          ]
        },
        "outputId": "d80497ed-d2e2-4216-f39f-8c8f3b45dee9"
      },
      "source": [
        "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-cased', do_lower_case=False)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dcba835f5daf4a259414e78325612127",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=213450.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIs7ltIPlbVp"
      },
      "source": [
        "### Creating dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_DTCbZHfxtN"
      },
      "source": [
        "!pip uninstall protobuf -y\n",
        "!pip uninstall google -y\n",
        "!pip install google\n",
        "!pip install protobuf\n",
        "!pip install google-cloud"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLMDhqfK44DZ"
      },
      "source": [
        "train_dataset, train_sampler, train_dataloader = dalo.create_dataloader_old(conll.sentences['train'],\n",
        "                                                                            conll.labels['train'], conll.tag2idx,\n",
        "                                                                            bert_tokenizer)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gh2_h5s8pABD",
        "outputId": "4afdf39b-4e14-4528-e1aa-06aa235074a3"
      },
      "source": [
        "# max len\n",
        "train_dataset[0][0].shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([173])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_1U6cD45Iw-"
      },
      "source": [
        "valid_dataset, valid_sampler, valid_dataloader = dalo.create_dataloader_old(conll.sentences['valid'],\n",
        "                                                            conll.labels['valid'], conll.tag2idx,\n",
        "                                                            bert_tokenizer, 'valid', desired_pad=train_dataset[0][0].shape[0])"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GtlwOjQkk37V"
      },
      "source": [
        "### BERT & ELMo setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_OFDSv-Dk37V"
      },
      "source": [
        "The transformer package provides a BertForTokenClassification class for token-level predictions. BertForTokenClassification is a fine-tuning model that wraps BertModel and adds token-level classifier on top of the BertModel."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulzg47ERB_tw"
      },
      "source": [
        "### Define the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xn_SOeVWtX_P"
      },
      "source": [
        "def freeze_bert_layers(bert, num_of_trainable=1):\n",
        "    for name, par in bert.named_parameters():\n",
        "        if sum([str(i) in name for i in range(11-num_of_trainable, 11)]) == 0:\n",
        "            par.requires_grad = False"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGZZM6n8pQ-b"
      },
      "source": [
        "class BEboC(nn.Module):\n",
        "    \"\"\"\n",
        "    BERT+Elmo+biLSTM+one CRF\n",
        "    \"\"\"\n",
        "    def __init__(self, hidden_size=128, num_labels=len(conll.tag2idx), elmo_layers=2,\n",
        "                 bert_layers=1, concat_bert=True, bilstm_layers=1, dropout=0.5):\n",
        "        \"\"\"\n",
        "        Creates model\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        hidden_size:\n",
        "        num_labels:\n",
        "        elmo_layers: int, default=2\n",
        "            Num of ELMo layers to be considered\n",
        "        bert_layers: int, default=1\n",
        "            Num of final BERT hidden layers to be used as embedding vector.\n",
        "        concat_bert: bool, default=True\n",
        "            Whether to concat (True) or sum (False) last BERT hidden layers.\n",
        "        bilstm_layers: int, default=1\n",
        "        \"\"\"\n",
        "        super(BEboC, self).__init__()\n",
        "\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_labels = num_labels\n",
        "        self.elmo_layers = elmo_layers\n",
        "        self.bert_layers = bert_layers\n",
        "        self.concat_bert = concat_bert\n",
        "        self.bilstm_layers = bilstm_layers\n",
        "        self.dropout = dropout\n",
        "        \n",
        "        self.bert = BertForTokenClassification.from_pretrained(\n",
        "                        BERT_MODEL,\n",
        "                        output_hidden_states=True)\n",
        "        \n",
        "        #for pars in self.bert.parameters():\n",
        "        #    pars.requires_grad = False\n",
        "        freeze_bert_layers(self.bert, num_of_trainable=1)\n",
        "        \n",
        "        bert_embedding_dim = self.bert.config.to_dict()['hidden_size']\n",
        "\n",
        "        self.elmo = Elmo(options_file, weight_file, self.elmo_layers, dropout=0, requires_grad=False)\n",
        "        \n",
        "        elmo_embedding_dim = 512 # it's always fixed\n",
        "\n",
        "        if self.concat_bert:\n",
        "          self.linear1 = nn.Linear(bert_embedding_dim*self.bert_layers+elmo_embedding_dim*self.elmo_layers, 1024)\n",
        "        else:\n",
        "          self.linear1 = nn.Linear(bert_embedding_dim+elmo_embedding_dim*self.elmo_layers, 1024)\n",
        "        \n",
        "        self.dp1 = nn.Dropout(dropout)\n",
        "\n",
        "        self.bilstm = nn.LSTM(1024, self.hidden_size, self.bilstm_layers, bidirectional=True)\n",
        "        \n",
        "        self.dp2 = nn.Dropout(dropout)\n",
        "\n",
        "        self.linear2 = nn.Linear(self.hidden_size*2, self.num_labels)\n",
        "\n",
        "        self.crf = CRF(num_tags=self.num_labels, batch_first=True)\n",
        "    \n",
        "    def get_model_pars_dict(self):\n",
        "        \"\"\"\n",
        "        Returns dict with described model's parameters.\n",
        "        \n",
        "        \"\"\"\n",
        "        pars = {}\n",
        "        pars['hidden_size'] = self.hidden_size\n",
        "        pars['num_labels'] = self.num_labels\n",
        "        pars['elmo_layers'] = self.elmo_layers\n",
        "        pars['bert_layers'] = self.bert_layers\n",
        "        pars['concat_bert'] = int(self.concat_bert)\n",
        "        pars['bilstm_layers'] = self.bilstm_layers\n",
        "\n",
        "        return pars\n",
        "    \n",
        "    def forward(self, bert_ids, elmo_ids, attention_mask):\n",
        "        \"\"\"\n",
        "        Forward propogate of model.\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        sequence:\n",
        "        attention_mask:\n",
        "        \n",
        "        Returns\n",
        "        -------\n",
        "        Logits\n",
        "        \n",
        "        \"\"\"\n",
        "\n",
        "        bert_hiddens = self.bert(bert_ids, attention_mask=attention_mask)[1]\n",
        "        elmo_hiddens = self.elmo(elmo_ids)\n",
        "\n",
        "        if self.concat_bert:\n",
        "            bert_embedding = torch.cat(bert_hiddens[-self.bert_layers:], dim=2)#[bert_hiddens[-i] for i in range(-1, -self.bert_layers-1, -1)], dim=0)\n",
        "        else:\n",
        "            emb_sum = 0\n",
        "            for h in bert_hiddens[-self.bert_layers:]:\n",
        "                emb_sum += h\n",
        "            bert_embedding = emb_sum\n",
        "\n",
        "        elmo_bert_embeddings = torch.clone(bert_embedding)\n",
        "\n",
        "        for el_hi in elmo_hiddens['elmo_representations']:\n",
        "            elmo_bert_embeddings = torch.cat((elmo_bert_embeddings, el_hi), dim=-1)\n",
        "\n",
        "        linear1_output = nn.functional.relu(self.linear1(elmo_bert_embeddings))\n",
        "        linear1_output = self.dp1(linear1_output)\n",
        "\n",
        "        bilstm_output, (h_n, c_n) = self.bilstm(linear1_output)\n",
        "        bilstm_output = self.dp2(bilstm_output)\n",
        "\n",
        "        linear2_output = nn.functional.relu(self.linear2(bilstm_output))\n",
        "        return linear2_output"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rc7JfSK1Hs8Q"
      },
      "source": [
        "### Model selection using grid"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVTXa0B3KaXf"
      },
      "source": [
        "Let's use small train dataset with 1000 examples (instead of 14041) in train and 250 (instead of 3250) in validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFTvZkYwKx_g"
      },
      "source": [
        "train_dataset, train_sampler, train_dataloader = dalo.create_dataloader_old(conll.sentences['train'][:1000],\n",
        "                                                                            conll.labels['train'][:1000], conll.tag2idx,\n",
        "                                                                            bert_tokenizer)\n",
        "\n",
        "valid_dataset, valid_sampler, valid_dataloader = dalo.create_dataloader_old(conll.sentences['valid'][:250],\n",
        "                                                            conll.labels['valid'][:250], conll.tag2idx,\n",
        "                                                            bert_tokenizer, 'valid', desired_pad=train_dataset[0][0].shape[0])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fC3j35AI4Wqp"
      },
      "source": [
        "N_EPOCHS = 15\n",
        "total_steps = len(train_dataloader) *  N_EPOCHS"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYCHQ6sboU8R"
      },
      "source": [
        "%time\n",
        "param_grid = {\n",
        "    'hidden_size': [512],\n",
        "    'lr': [3e-4, 5e-4, 1e-3],\n",
        "    'bert_layers': [2],\n",
        "    'bilstm_layers': [1, 2],\n",
        "    'dropout': [0, 0.25, 0.5],\n",
        "    'max_grad_norm': [None, 228]\n",
        "}\n",
        "\n",
        "\n",
        "grid = ParameterGrid(param_grid)\n",
        "\n",
        "results_dict = {}\n",
        "\n",
        "for m, ps in enumerate(grid):\n",
        "    print(f\"Model #{m} of {len(grid)}\")\n",
        "    results_dict[m] = {}\n",
        "    results_dict[m]['params'] = ps\n",
        "\n",
        "    model = BEboC(hidden_size=ps['hidden_size'], bert_layers=ps['bert_layers'],\n",
        "                  dropout=ps['dropout'])\n",
        "\n",
        "    optimizer = AdamW(params=model.parameters(),lr=ps['lr'])\n",
        "\n",
        "    scheduler = get_linear_schedule_with_warmup(\n",
        "        optimizer,\n",
        "        num_warmup_steps=0,\n",
        "        num_training_steps=total_steps\n",
        "    )\n",
        "\n",
        "    if device.type != 'cpu':\n",
        "        model.to(device)\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "    \n",
        "    results = mu.train_old(model, train_dataloader, optimizer, conll_old.idx2tag, device,\n",
        "                        scheduler, n_epoch=N_EPOCHS, max_grad_norm=ps['max_grad_norm'],\n",
        "                        validate=True, valid_dataloader=valid_dataloader, \n",
        "                        save_model=False)\n",
        "    \n",
        "\n",
        "    _, _, valid_accuracies, valid_f1_scores = results\n",
        "\n",
        "    results_dict[m]['valid_accs'] = valid_accuracies\n",
        "    results_dict[m]['valid_f1s'] = valid_f1_scores\n",
        "    \n",
        "\n",
        "with open(\"/content/drive/My Drive/Serious/Models_results/dropout_results_dict.json\", \"w\") as w:\n",
        "    json.dump(results_dict, w)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPS7K3gVw3KU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93e9d53c-a15b-4af9-f7bc-d030b4bcad5c"
      },
      "source": [
        "final_f1s = {k: v['valid_f1s'][-1] for k, v in results_dict.items()}\n",
        "print(f'The best model is the {np.argmax(list(final_f1s.values()))} one.')\n",
        "print(f'Its params: {results_dict[np.argmax(list(final_f1s.values()))][\"params\"]}')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The best model is the 15 one.\n",
            "Its params: {'bert_layers': 2, 'bilstm_layers': 1, 'dropout': 0.5, 'hidden_size': 512, 'lr': 0.0005, 'max_grad_norm': 228}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_xcMVxJlxsn"
      },
      "source": [
        "After train for 15 epochs on small dataset the best result gave the model that concatenates two last bert layers, uses just 1 bilstm layer, dropout value 0.5 and has learning rate 5e-4, so let's train such model on all train data. Also, let's use now linear scheduler."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFu_4fMKPCjv"
      },
      "source": [
        "### Model gradients analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3mgbU2Jwitf"
      },
      "source": [
        "Grid search has shown us that it's a little bit better to use clipping of gradient. Let's inpect gradient values of pretrained model to find max grad norm value more carefully. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dP96N0jBPS4-",
        "outputId": "2f192cba-54bc-45d8-ad5d-c9d1d48d2e04"
      },
      "source": [
        "checkpoint = torch.load(PATH_TO_CHECKPOINT+'dropout_beboc.pth')\n",
        "model = checkpoint['model']\n",
        "model.load_state_dict(checkpoint['state_dict'])"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePZAYm8i0ChQ"
      },
      "source": [
        "def get_grad_norm(model):\n",
        "    total_norm = 0\n",
        "    for p in model.parameters():\n",
        "        if p.requires_grad:\n",
        "            param_norm = p.grad.data.norm(2)\n",
        "            total_norm += param_norm.item() ** 2 \n",
        "    total_norm = total_norm ** (1. / 2)\n",
        "    return total_norm"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gr_-ewye0NKx"
      },
      "source": [
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNViVt_90oPA",
        "outputId": "1a564085-b724-4a6d-8c9a-ba26af795b42"
      },
      "source": [
        "model.train()\n",
        "grad_norms = []\n",
        "\n",
        "for batch in train_dataloader:\n",
        "    if device.type != 'cpu':\n",
        "            batch = tuple(t.to(device) for t in batch)\n",
        "    b_bert_ids, b_elmo_ids, b_labels, b_input_mask = batch\n",
        "    model.zero_grad()\n",
        "\n",
        "    logits = model.forward(b_bert_ids, b_elmo_ids, b_input_mask.byte())\n",
        "    loss = -1*model.crf.forward(logits, b_labels, mask=b_input_mask.byte())\n",
        "    loss.backward()\n",
        "    grad_norms.append(get_grad_norm(model))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py:435: UserWarning: Setting attributes on ParameterList is not supported.\n",
            "  warnings.warn(\"Setting attributes on ParameterList is not supported.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "WOUzVsBRK5kc",
        "outputId": "cd4b5854-866f-4167-c670-c4f4896ec7cc"
      },
      "source": [
        "_ = plt.hist(grad_norms)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kc-cYctfR5Fk",
        "outputId": "d9f07b95-0d04-4f49-dc65-80b21440be19"
      },
      "source": [
        "print(f'Mean gradient norm: {np.mean(grad_norms)}')"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean gradient norm: 443.54006613919825\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQqboO0ZSM9C"
      },
      "source": [
        "So, let's set max grad norm value to be 500 during training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBeYV1uDDOvk"
      },
      "source": [
        "### Cross-validation with the best hyperparams on 5 folds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ByjTJrC8P2K"
      },
      "source": [
        "Fix some train parameters\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AnXnYO3H8GDs"
      },
      "source": [
        "N_FOLDS = 5\n",
        "RANDOM_SEED = 42\n",
        "N_EPOCHS = 15\n",
        "BATCH_SIZE = 128"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rl13L8v75q0t"
      },
      "source": [
        "kf = KFold(n_splits=N_FOLDS, shuffle=True, random_state=RANDOM_SEED)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPt33hLBurfM"
      },
      "source": [
        "TAG_NAMES = ['ORG', 'LOC', 'PER', 'MISC']"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umh1pUqOejBX"
      },
      "source": [
        "train_dataset, train_sampler, train_dataloader = dalo.create_dataloader_old(conll.sentences['train'],\n",
        "                                                                            conll.labels['train'], conll.tag2idx,\n",
        "                                                                            bert_tokenizer)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJBtbzEvej7d"
      },
      "source": [
        "valid_dataset, valid_sampler, valid_dataloader = dalo.create_dataloader_old(conll.sentences['valid'],\n",
        "                                                            conll.labels['valid'], conll.tag2idx,\n",
        "                                                            bert_tokenizer, 'valid', desired_pad=train_dataset[0][0].shape[0])"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jv0PZ6jtmuT_"
      },
      "source": [
        "all_tag_results = []\n",
        "model_results = []\n",
        "\n",
        "for i, (train_index, valid_index) in enumerate(kf.split(train_dataset)):\n",
        "    print(f\"FOLD #{i}\\n\")\n",
        "    # train_dataset based on conll and defined above specially for multiple-head model input\n",
        "    train_fold = torch.utils.data.Subset(train_dataset, train_index)\n",
        "    valid_fold = torch.utils.data.Subset(train_dataset, valid_index)\n",
        "    \n",
        "    _train_dataloader = torch.utils.data.DataLoader(train_fold, batch_size=BATCH_SIZE)\n",
        "    _valid_dataloader = torch.utils.data.DataLoader(valid_fold, batch_size=BATCH_SIZE)\n",
        "\n",
        "    total_steps = len(train_fold) *  N_EPOCHS\n",
        "\n",
        "    model = BEboC(hidden_size=512, num_labels=len(conll.tag2idx), bert_layers=2)\n",
        "    model.to(device)\n",
        "\n",
        "    optimizer = AdamW(params=model.parameters(),lr=5e-4)\n",
        "\n",
        "    scheduler = get_linear_schedule_with_warmup(\n",
        "        optimizer,\n",
        "        num_warmup_steps=0,\n",
        "        num_training_steps=total_steps\n",
        "    )\n",
        "\n",
        "    loss_values, validation_loss_values, valid_accuracies, valid_f1_scores = mu.train_old(model, _train_dataloader, optimizer, conll.idx2tag, device, scheduler, n_epoch=N_EPOCHS,\n",
        "                                                                                          max_grad_norm=500, valid_dataloader=_valid_dataloader, save_model=False)\n",
        "    \n",
        "    # evaluating on all validation data\n",
        "    eval_loss, acc, f1 = mu.eval_old(model, _valid_dataloader, device, conll.idx2tag)\n",
        "    model_results.append({'acc': acc, 'f1': f1})\n",
        "\n",
        "    # evaluating on separate tags\n",
        "    tag_results = {}\n",
        "    for tag in TAG_NAMES:\n",
        "        # old version of create dataloader function is very suitable here\n",
        "        tag_train_dataset, _, _ = dalo.create_dataloader_old(conll_one_tag.sentences['train'],\n",
        "                                                            conll_one_tag.one_tag_dict['train'][tag], conll_one_tag.tag2idx,\n",
        "                                                            bert_tokenizer, desired_pad=train_dataset[0][0].shape[0])\n",
        "        tag_valid_fold = torch.utils.data.Subset(tag_train_dataset, valid_index)\n",
        "        tag_valid_dataloader = torch.utils.data.DataLoader(tag_valid_fold, batch_size=BATCH_SIZE)\n",
        "        eval_loss, acc, f1 = mu.eval_old(model, tag_valid_dataloader, device, conll.idx2tag)\n",
        "        \n",
        "        tag_results[tag] = {'loss': eval_loss, 'acc': acc, 'f1': f1}\n",
        "    \n",
        "    print(f\"tag_results:{tag_results}\")\n",
        "    all_tag_results.append(tag_results)\n",
        "\n",
        "    # cleaning\n",
        "    del model\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    with open(PATH_TO_CHECKPOINT+f\"beboc_5folds/BEboC-5fold_tag_results_fold{i}.json\", \"w\") as f:\n",
        "        json.dump(tag_results, f)\n",
        "\n",
        "    with open(PATH_TO_CHECKPOINT+f\"beboc_5folds/BEboC-5fold_model_results_fold{i}.json\", \"w\") as f:\n",
        "        json.dump(model_results[-1], f)\n",
        "\n",
        "#with open(PATH_TO_CHECKPOINT+\"BEboC-5fold_tag_results.json\", \"w\") as f:\n",
        "#    json.dump(all_tag_results, f)\n",
        "\n",
        "#with open(PATH_TO_CHECKPOINT+\"BEboC-5fold_model_results.json\", \"w\") as f:\n",
        "#    json.dump(model_results, f)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dB8TmGLD29DC"
      },
      "source": [
        "### Final model train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVfn5z8DMXOd"
      },
      "source": [
        "N_EPOCHS = 15"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UrTQbk8byXP_"
      },
      "source": [
        "total_steps = len(train_dataloader) *  N_EPOCHS"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r3hRyRjLMNvJ",
        "outputId": "e065a41e-56d1-46c3-85c1-fc852a8b5f56"
      },
      "source": [
        "model = BEboC(hidden_size=512, bert_layers=2, dropout=0.5)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "noc7jM-228Jf"
      },
      "source": [
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZtAb2SH5MPr_"
      },
      "source": [
        "optimizer = AdamW(params=model.parameters(), lr=5e-4)\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=total_steps\n",
        ")\n",
        "\n",
        "#if device.type != 'cpu':\n",
        "#    model.to(device)\n",
        "\n",
        "#train_losses, valid_losses, valid_accs, valid_f1s\n",
        "results = mu.train_old(model, train_dataloader, optimizer, conll_old.idx2tag, device,\n",
        "                        scheduler, n_epoch=N_EPOCHS, max_grad_norm=500,\n",
        "                        validate=True, valid_dataloader=valid_dataloader, \n",
        "                        save_path=PATH_TO_CHECKPOINT+'new_beboc.pth')\n",
        "\n",
        "with open(PATH_TO_CHECKPOINT+'new_beboc_results.json', 'w') as f:\n",
        "    json.dump(results, f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "id": "BNCH0fryUcYw",
        "outputId": "777904cb-895c-4319-ab1d-566bc163aa8b"
      },
      "source": [
        "fig = plt.figure(figsize=(10,8))\n",
        "plt.plot(results[0], label='train loss')\n",
        "plt.plot(results[1], label='valid loss')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.ylabel(\"loss\")\n",
        "plt.xlabel(\"#epoch\")\n",
        "plt.xticks(np.arange(0,15,2))\n",
        "plt.show()"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4tqWLr8kihG4"
      },
      "source": [
        "If we want to train model for more time"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_WyjXJoifw1"
      },
      "source": [
        "N_EPOCHS = 5\n",
        "total_steps = len(train_dataloader) *  N_EPOCHS\n",
        "\n",
        "optimizer = AdamW(params=model.parameters(),lr=1e-4)\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=total_steps\n",
        ")\n",
        "\n",
        "if device.type != 'cpu':\n",
        "    model.to(device)\n",
        "  \n",
        "model.train()\n",
        "\n",
        "#train_losses, valid_losses, valid_accs, valid_f1s\n",
        "results_1 = train(model, train_dataloader, optimizer, scheduler, n_epoch=N_EPOCHS,\n",
        "     validate=True, valid_dataloader=valid_dataloader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_55aneQlAzpC"
      },
      "source": [
        "If we want to evaluate the best model on the test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ts056laRSDc",
        "outputId": "5d89f247-a52f-4249-cfd1-e72a5772bd31"
      },
      "source": [
        "checkpoint = torch.load(PATH_TO_CHECKPOINT+'new_beboc.pth')\n",
        "model = checkpoint['model']\n",
        "model.load_state_dict(checkpoint['state_dict'])"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0bd-fXwgE0J"
      },
      "source": [
        "test_dataset, test_sampler, test_dataloader = dalo.create_dataloader_old(conll.sentences['test'],\n",
        "                                                            conll.labels['test'], conll.tag2idx,\n",
        "                                                            bert_tokenizer, 'test', desired_pad=train_dataset[0][0].shape[0])"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ho1fi5rCMTJN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0cf33801-bd92-4ebf-fc77-72497a2f02a6"
      },
      "source": [
        "# eval model on the test data\n",
        "mean_loss, mean_acc, mean_f1 = mu.eval_old(model, test_dataloader, device, conll_old.idx2tag)\n",
        "print(f\"test loss: {mean_loss}\")\n",
        "print(f\"test accuracy: {mean_acc}\")\n",
        "print(f\"test f1-score: {mean_f1}\")"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py:435: UserWarning: Setting attributes on ParameterList is not supported.\n",
            "  warnings.warn(\"Setting attributes on ParameterList is not supported.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "test loss: 476.7273305257161\n",
            "test accuracy: 0.9708812369434536\n",
            "test f1-score: 0.8798677443056576\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97x4ZM_bBLE9"
      },
      "source": [
        "___"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4iZbz4pAgg9"
      },
      "source": [
        "### Load the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlJ5NZwVi5iQ"
      },
      "source": [
        "model = torch.load('/content/drive/My Drive/models/BERT_biLSTM_oneCRF.pth',\n",
        "                   map_location=torch.device('cpu'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4LdgKkJXCdHU"
      },
      "source": [
        "model = torch.load('/content/drive/My Drive/models/Elmo_BERT_biLSTM_oneCRF.pth',\n",
        "                   map_location=torch.device('cpu'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l72fDasHEj_2"
      },
      "source": [
        "def load_checkpoint(tokenizer_path, checkpoint_path):\n",
        "    \"\"\"Loads both tokenizer and our pretrained model\"\"\"\n",
        "    tokenizer = tokenizer = BertTokenizer.from_pretrained(tokenizer_path)\n",
        "    checkpoint = torch.load(checkpoint_path)\n",
        "    model = checkpoint['model']\n",
        "    model.load_state_dict(checkpoint['state_dict'])\n",
        "    #for parameter in model.parameters():\n",
        "    #    parameter.requires_grad = False\n",
        "\n",
        "    model.eval()\n",
        "    return tokenizer, model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36G1_emY6nIF"
      },
      "source": [
        "tokenizer, model = load_checkpoint('/content/drive/My Drive/models/ElMo_BERT_biLSTM_oneCRF_19_tokenizer.pth',\n",
        "                                     '/content/drive/My Drive/models/ElMo_BERT_biLSTM_oneCRF_19_state_dict.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w67J1ykrSs21",
        "outputId": "b6fb6770-ae59-45f9-996a-1d52ada63e7d"
      },
      "source": [
        "tokenizer.save_pretrained(f'/content/drive/My Drive/models/ElMo_BERT_biLSTM_oneCRF_19_tokenizer.pth')\n",
        "checkpoint = {'model': BEboC(hidden_size=512, bert_layers=2),\n",
        "              'state_dict': model.state_dict(), \n",
        "              'optimizer' : optimizer.state_dict()}\n",
        "\n",
        "torch.save(checkpoint,\n",
        "            f'/content/drive/My Drive/models/ElMo_BERT_biLSTM_oneCRF_19_state_dict.pth')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "beoXMar6EssL"
      },
      "source": [
        "train_dataset, train_sampler, train_dataloader = create_dataloader(tokenizer, train_data, train_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lAhyHC69E8qd"
      },
      "source": [
        "for s in train_dataset:\n",
        "  max_seq_len = s[1].shape[0]\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3PnWw3uSEptE"
      },
      "source": [
        "test_dataset, test_sampler, test_dataloader = create_dataloader(tokenizer, test_data, test_labels,\n",
        "                                                                   datatype='test',\n",
        "                                                                   desired_pad=max_seq_len)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J3j0QLosgsvL",
        "outputId": "55ac4c06-2dd8-4031-a0dd-4c3e63f68696"
      },
      "source": [
        "model.to(device)\n",
        "model.eval()\n",
        "test_losses = []\n",
        "true_labels = []\n",
        "pred_labels = []\n",
        "for step, batch in enumerate(test_dataloader):\n",
        "    # add batch to gpu\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    b_elmo_ids, b_bert_ids, b_input_mask, b_labels = batch\n",
        "    batch_true_labels = b_labels\n",
        "    for bl in batch_true_labels.detach().cpu().tolist():\n",
        "      tag_names = [idx2tag[i] for i in bl if idx2tag[i] != 'PAD']\n",
        "      true_labels.append(tag_names)\n",
        "    \n",
        "    # Always clear any previously calculated gradients before performing a backward pass.\n",
        "    # forward pass\n",
        "    # This will return the loss (rather than the model output)\n",
        "    # because we have provided the `labels`.\n",
        "    with torch.no_grad():\n",
        "        logits = model.forward(b_elmo_ids, b_bert_ids, b_input_mask.byte())\n",
        "        loss = model.crf.forward(logits, b_labels, b_input_mask.byte())\n",
        "        test_losses.append(loss.item())\n",
        "        tags = model.crf.decode(logits, b_input_mask.byte())\n",
        "    for t in tags:\n",
        "      tag_names = [idx2tag[i] for i in t]\n",
        "      pred_labels.append(tag_names)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py:434: UserWarning: Setting attributes on ParameterList is not supported.\n",
            "  warnings.warn(\"Setting attributes on ParameterList is not supported.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wfdmdhpghyar",
        "outputId": "64c845c4-3c93-4dcc-f28f-4d1bba83deae"
      },
      "source": [
        "f1_score(true_labels, pred_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8405783838198957"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lEjtb2Ft2Yqb"
      },
      "source": [
        "### Evaluate model on tags separately"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3CK0kq62iRi"
      },
      "source": [
        "checkpoint = torch.load(PATH_TO_CHECKPOINT+'new_beboc.pth')\n",
        "model = checkpoint['model']\n",
        "model.load_state_dict(checkpoint['state_dict'])\n",
        "model.eval()\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O0Ld3OM42fCa"
      },
      "source": [
        "Evaluating on the entire validation dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOf_Fc7D2eXw"
      },
      "source": [
        "# 173 because I remember this value (max len from the training)\n",
        "valid_dataset, valid_sampler, valid_dataloader = dalo.create_dataloader(conll, bert_tokenizer, datatype='valid', desired_pad=173)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p6M6iqPU2-Cn",
        "outputId": "79f89474-bee0-49b0-ae8e-452ea227016f"
      },
      "source": [
        "mu.eval_old(model, valid_dataloader, device, conll_old.idx2tag)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py:435: UserWarning: Setting attributes on ParameterList is not supported.\n",
            "  warnings.warn(\"Setting attributes on ParameterList is not supported.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(243.1688398214487, 0.9847141629056523, 0.9289676149579532)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2OGaw-U6HL3"
      },
      "source": [
        "So, f1-score on the entire validation dataset is 0.93"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OIgCNhNR3jIq"
      },
      "source": [
        "Let's evaluate the old model on just PER entity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NbNPhjby3g8j"
      },
      "source": [
        "valid_dataset, valid_sampler, valid_dataloader = dalo.create_dataloader_old(conll_one_tag.sentences['valid'],\n",
        "                                                                            conll_one_tag.one_tag_dict['valid']['PER'], conll_one_tag.tag2idx,\n",
        "                                                                            bert_tokenizer, datatype='valid', desired_pad=173)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W7aQy_o83nHC",
        "outputId": "14c60767-03ed-4a00-9886-f43546ef7202"
      },
      "source": [
        "mu.eval_old(model, valid_dataloader, device, conll_one_tag.idx2tag)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py:435: UserWarning: Setting attributes on ParameterList is not supported.\n",
            "  warnings.warn(\"Setting attributes on ParameterList is not supported.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3763.243896484375, 0.866309370298732, 0.43730655478368524)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JprLailV6hU4"
      },
      "source": [
        "ORG"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rbh7Me7b6hi_"
      },
      "source": [
        "valid_dataset, valid_sampler, valid_dataloader = dalo.create_dataloader_old(conll_one_tag.sentences['valid'],\n",
        "                                                                            conll_one_tag.one_tag_dict['valid']['ORG'], conll_one_tag.tag2idx,\n",
        "                                                                            bert_tokenizer, datatype='valid', desired_pad=173)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jEFofmU06qIc",
        "outputId": "83a06e80-ce95-4782-c4dc-6a98e96e87ff"
      },
      "source": [
        "mu.eval_old(model, valid_dataloader, device, conll_one_tag.idx2tag)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py:435: UserWarning: Setting attributes on ParameterList is not supported.\n",
            "  warnings.warn(\"Setting attributes on ParameterList is not supported.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4901.181142953726, 0.8295320223511713, 0.355232892466935)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8sgKz1iB6syH"
      },
      "source": [
        "LOC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkzeVRz36vdD"
      },
      "source": [
        "valid_dataset, valid_sampler, valid_dataloader = dalo.create_dataloader_old(conll_one_tag.sentences['valid'],\n",
        "                                                                            conll_one_tag.one_tag_dict['valid']['LOC'], conll_one_tag.tag2idx,\n",
        "                                                                            bert_tokenizer, datatype='valid', desired_pad=173)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ozsuxnpy6y6u",
        "outputId": "e06ede32-c094-460a-9634-07717803d94d"
      },
      "source": [
        "mu.eval_old(model, valid_dataloader, device, conll_one_tag.idx2tag)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py:435: UserWarning: Setting attributes on ParameterList is not supported.\n",
            "  warnings.warn(\"Setting attributes on ParameterList is not supported.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4691.968515249399, 0.834098968407479, 0.4648029639609297)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E528jjfa61eH"
      },
      "source": [
        "The last values above are f1-scores:\n",
        "\n",
        "'PER' - 0.43730655478368524\n",
        "\n",
        "'ORG' - 0.355232892466935\n",
        "\n",
        "'LOC' - 0.4648029639609297"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ct8d_FlWwCaJ"
      },
      "source": [
        "### Train BEboC on data with three labels (without MISC)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YCFnCe9G8NFA"
      },
      "source": [
        "But CRF is still knows that there is another tag that he doesn't meet during this training (it is inpossible to add new tags to CRF)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CAg-S9STwG6w"
      },
      "source": [
        "labels_w_misc = {}\n",
        "for typ in ['train', 'valid']:\n",
        "    labels_w_misc[typ] = [[l if 'MISC' not in l else 'O' for l in sen] for sen in conll.labels[typ]]"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H1j2pSMTwRYF",
        "outputId": "71ab18c6-6f6e-421a-86d0-8e5c47fd6371"
      },
      "source": [
        "print(conll.labels['train'][0])\n",
        "print(labels_w_misc['train'][0])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['B-ORG', 'O', 'B-MISC', 'O', 'O', 'O', 'B-MISC', 'O', 'O']\n",
            "['B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvmrT2sBwTUY"
      },
      "source": [
        "train_dataset, train_sampler, train_dataloader = dalo.create_dataloader_old(conll.sentences['train'],\n",
        "                                                                            labels_w_misc['train'], conll.tag2idx,\n",
        "                                                                            bert_tokenizer)\n",
        "\n",
        "valid_dataset, valid_sampler, valid_dataloader = dalo.create_dataloader_old(conll.sentences['valid'],\n",
        "                                                            labels_w_misc['valid'], conll.tag2idx,\n",
        "                                                            bert_tokenizer, 'valid', desired_pad=train_dataset[0][0].shape[0])"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0xwW9yfxESY"
      },
      "source": [
        "N_EPOCHS = 15\n",
        "total_steps = len(train_dataloader) *  N_EPOCHS"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254,
          "referenced_widgets": [
            "f06d4f3f09e44d7281575f8ee9b8b8eb",
            "a710f50332c04a2a8b4e65c7c3d1dc30",
            "9a2e456c1e864e098a5eff059e3920ae",
            "28631b66e20046ad8dc16a9a576160fc",
            "4089fd51dead419189a1c9d0856e992f",
            "9b29bc675ea7456ba9724c44986d3b43",
            "2c71105966934923afb6d0d923884af4",
            "f7932c6432954d01b73b3a856116991c",
            "ade080fbbbfb4bb080edbf58da5ad5fe",
            "f5b9ac612c064b949099708ccd020f08",
            "7bd992fe00dd44a6a686325e71f23cad",
            "8dde2b3b744e48abb7c67df105a09e68",
            "1af0a6b1f7654da0b54ebbe8cf7ea5ce",
            "ca2c3838700b481198277fbb72a7f6c6",
            "c85299002a1941259f2c6343016bd7a6",
            "12df2642d803487fa9575e80c738012d"
          ]
        },
        "id": "Gttj5xnYw-Po",
        "outputId": "1f2e9d35-dd12-4eb6-8070-b690bfc41323"
      },
      "source": [
        "model = BEboC(hidden_size=512, bert_layers=2, dropout=0.5)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f06d4f3f09e44d7281575f8ee9b8b8eb",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ade080fbbbfb4bb080edbf58da5ad5fe",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=435779157.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "downloading: 100%|##########| 336/336 [00:00<00:00, 965926.08B/s]\n",
            "downloading: 100%|##########| 112140184/112140184 [00:02<00:00, 53843224.96B/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iLl1QJQzyvoQ",
        "outputId": "883a1cd9-c431-42c8-d8fb-7c8c0c441896"
      },
      "source": [
        "reload(mu)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'model_utils' from '/content/drive/My Drive/Serious/model_utils.py'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fAKj2Dp13Uiz"
      },
      "source": [
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Evj-hxxGxMfe"
      },
      "source": [
        "optimizer = AdamW(params=model.parameters(),lr=5e-4)\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=total_steps\n",
        ")\n",
        "\n",
        "#train_losses, valid_losses, valid_accs, valid_f1s\n",
        "results = mu.train_old(model, train_dataloader, optimizer, conll.idx2tag, device,\n",
        "                       scheduler, n_epoch=N_EPOCHS, max_grad_norm=500,\n",
        "                       validate=True, valid_dataloader=valid_dataloader, \n",
        "                       save_path=PATH_TO_CHECKPOINT+'Beboc_without_misc.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJ5MGmRy4wIP"
      },
      "source": [
        "### Continue to train BEboC on data with MISC"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GbVjUiF845tG"
      },
      "source": [
        "Now let's try to keep 85% of examples with one or more tags MISC and 15% without it. So, we would simulate the real case of receiving new data with new tag."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8kOBURT5pstG",
        "outputId": "5c124992-c2d4-4eef-a296-c9d604539f91"
      },
      "source": [
        "checkpoint = torch.load(PATH_TO_CHECKPOINT+'Beboc_without_misc.pth')\n",
        "model = checkpoint['model']\n",
        "model.load_state_dict(checkpoint['state_dict'])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Pg5P8i41HIb"
      },
      "source": [
        "indexes_with_misc = [i for i, s in enumerate(conll.labels['train']) if 'B-MISC' in s]\n",
        "indexes_without_misc = [i for i in range(len(conll.labels['train'])) if i not in indexes_with_misc]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJfUQ_oE5bR3",
        "outputId": "cdad9705-597b-4972-fc6e-ff16166d716e"
      },
      "source": [
        "print(f\"# sentences with MISC: {len(indexes_with_misc)}\")\n",
        "print(f\"# sentences without MISC: {len(indexes_without_misc)}\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# sentences with MISC: 2698\n",
            "# sentences without MISC: 11343\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UNNVZGw25g_G"
      },
      "source": [
        "Also, let's consider multiple \"random\" cases."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxedMhtGBFF1"
      },
      "source": [
        "BATCH_SIZE=32\n",
        "RANDOM_SEED=42\n",
        "N_EPOCHS = 15"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3yBCGSa65des"
      },
      "source": [
        "results_dict = {}\n",
        "for seed in [1234, 12345]:\n",
        "    print(f\"SEED:{seed}\")\n",
        "    np.random.seed(seed)\n",
        "    results_dict[seed] = {}\n",
        "\n",
        "    for n_train_samples in range(100, 351, 50):\n",
        "        print(f\"NUMBER OF TRAIN SAMPLES: {n_train_samples}\")\n",
        "        \n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "        model = checkpoint['model']\n",
        "        model.load_state_dict(checkpoint['state_dict'])\n",
        "        \n",
        "        model.train()\n",
        "        \n",
        "        # I just remember that max sequence length in train is 173\n",
        "        all_valid_dataset, all_valid_sampler, all_valid_dataloader = dalo.create_dataloader_old(conll.sentences['valid'],\n",
        "                                                                              conll.labels['valid'], conll.tag2idx,\n",
        "                                                                              bert_tokenizer, 'valid', desired_pad=173)\n",
        "        \n",
        "        # train indexes\n",
        "        n_train_with_misc = int(n_train_samples*0.85)\n",
        "        train_misk_indexes = np.random.choice(indexes_with_misc, n_train_with_misc)\n",
        "        train_nmisk_indexes = np.random.choice(indexes_without_misc, n_train_samples-n_train_with_misc)\n",
        "        train_indexes = np.append(train_misk_indexes, train_nmisk_indexes)\n",
        "\n",
        "        # let's create small validation data with the same proportion of MISC samples from the train data\n",
        "        n_valid_samples = int(n_train_samples/4)\n",
        "        _idxes_with_misc = [i for i in indexes_with_misc if i not in train_misk_indexes]\n",
        "        _idxes_without_misc = [i for i in indexes_without_misc if i not in train_nmisk_indexes]\n",
        "\n",
        "        # validation indexes\n",
        "        n_valid_with_misc = int(n_valid_samples*0.85)\n",
        "        valid_misk_indexes = np.random.choice(_idxes_with_misc, n_valid_with_misc)\n",
        "        valid_nmisk_indexes = np.random.choice(_idxes_without_misc, n_valid_samples-n_valid_with_misc)\n",
        "        valid_indexes = np.append(valid_misk_indexes, valid_nmisk_indexes)\n",
        "\n",
        "        train_dataset, train_sampler, train_dataloader = dalo.create_dataloader(conll, bert_tokenizer,\n",
        "                                                                      desired_pad=173, batch_size=BATCH_SIZE,\n",
        "                                                                      indexes=train_indexes)\n",
        "        \n",
        "        valid_dataset, valid_sampler, valid_dataloader = dalo.create_dataloader(conll, bert_tokenizer,\n",
        "                                                                            desired_pad=173, batch_size=BATCH_SIZE,\n",
        "                                                                            indexes=valid_indexes)\n",
        "        \n",
        "        total_steps = len(train_dataloader) *  N_EPOCHS\n",
        "\n",
        "        optimizer = AdamW(params=model.parameters(),lr=5e-4)\n",
        "\n",
        "        scheduler = get_linear_schedule_with_warmup(\n",
        "            optimizer,\n",
        "            num_warmup_steps=0,\n",
        "            num_training_steps=total_steps\n",
        "        )\n",
        "\n",
        "        if device.type != 'cpu':\n",
        "            model.to(device)\n",
        "\n",
        "        results = mu.train_old(model, train_dataloader, optimizer, conll.idx2tag, device,\n",
        "                        scheduler, n_epoch=N_EPOCHS, max_grad_norm=500,\n",
        "                        validate=True, valid_dataloader=valid_dataloader, \n",
        "                        save_model=False)\n",
        "        \n",
        "        _, _, valid_accuracies, valid_f1_scores = results\n",
        "\n",
        "        results_dict[seed][n_train_samples] = {}\n",
        "        results_dict[seed][n_train_samples]['small_valid_accs'] = valid_accuracies\n",
        "        results_dict[seed][n_train_samples]['small_valid_f1s'] = valid_f1_scores\n",
        "\n",
        "        # eval model on the all validation data\n",
        "        mean_loss, mean_acc, mean_f1 = mu.eval_old(model, all_valid_dataloader, device, conll.idx2tag)\n",
        "        print(f\"validation loss: {mean_loss}\")\n",
        "        print(f\"validation accuracy: {mean_acc}\")\n",
        "        print(f\"validation f1-score: {mean_f1}\")\n",
        "\n",
        "        results_dict[seed][n_train_samples][\"all_valid_loss\"] = mean_loss\n",
        "        results_dict[seed][n_train_samples][\"all_valid_acc\"] = mean_acc\n",
        "        results_dict[seed][n_train_samples][\"all_valid_f1\"] = mean_f1\n",
        "\n",
        "        # eval model on every tag separately\n",
        "        results_dict[seed][n_train_samples]['tags_results'] = {}\n",
        "        for tag in ['LOC', 'PER', 'ORG', 'MISC']:\n",
        "            tag_dataset, tag_sampler, tag_dataloader = dalo.create_dataloader_old(conll_one_tag.sentences['valid'],\n",
        "                                                                              conll_one_tag.one_tag_dict['valid']['ORG'], conll.tag2idx,\n",
        "                                                                              bert_tokenizer, datatype='valid', desired_pad=173)\n",
        "            loss, acc, f1 = mu.eval_old(model, tag_dataloader, device, conll.idx2tag)\n",
        "            results_dict[seed][n_train_samples]['tags_results'][tag] = {'loss': loss, 'acc': acc, 'f1': f1}\n",
        "\n",
        "    with open(PATH_TO_CHECKPOINT+f\"misc_finetune/results_seed{seed}.json\", \"w\") as f:\n",
        "        json.dump(results_dict[seed], f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYUzfpE8DH-F"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}