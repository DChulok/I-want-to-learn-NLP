{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NEWEXPER.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "zNBmPWcXheAq"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "fc5411ddb8894a7a86237731d94aa793": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4276ba32ff8a445382a22d7bbca602df",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_01f50663d93742a5ae72b19622a98245",
              "IPY_MODEL_6a08ae8e94b04ec193c55f3f6539565a"
            ]
          }
        },
        "4276ba32ff8a445382a22d7bbca602df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "01f50663d93742a5ae72b19622a98245": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4b70128434634478b4b6c2b28af15a42",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 213450,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 213450,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ae65a66d3ac64b3e95917bf7efdf5ae1"
          }
        },
        "6a08ae8e94b04ec193c55f3f6539565a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_465e2f8a5a8545e5b8794cd60dc0e942",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 213k/213k [00:00&lt;00:00, 283kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7bb861d351494b62876bf0e15a4bd6ec"
          }
        },
        "4b70128434634478b4b6c2b28af15a42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ae65a66d3ac64b3e95917bf7efdf5ae1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "465e2f8a5a8545e5b8794cd60dc0e942": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7bb861d351494b62876bf0e15a4bd6ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "97c85b6ec1894241be12e449603bd271": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_85fd70bc5c664442899cf1870a9b14dc",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d569e2b8a3534c0ab6d52d253105359c",
              "IPY_MODEL_6f0816fad65f4f4fb535445471ef8a87"
            ]
          }
        },
        "85fd70bc5c664442899cf1870a9b14dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d569e2b8a3534c0ab6d52d253105359c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ee151660aa4743929fe1f07d75e39d77",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f6f985f8dffb49879355a5c7cd2c27a7"
          }
        },
        "6f0816fad65f4f4fb535445471ef8a87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0f94f60f19a443a3a36afa0abaad3b94",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:41&lt;00:00, 10.5B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_55a85e306f4c4555ad8ecb6f6d5a2514"
          }
        },
        "ee151660aa4743929fe1f07d75e39d77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f6f985f8dffb49879355a5c7cd2c27a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0f94f60f19a443a3a36afa0abaad3b94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "55a85e306f4c4555ad8ecb6f6d5a2514": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dec096bf6d444252a635b6810fa798d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d606cc26898e461f8a9a321f9dd5df50",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_18c465dcd0a04347a25f75022681f251",
              "IPY_MODEL_cf62d06acbc547fab9f00f263a482996"
            ]
          }
        },
        "d606cc26898e461f8a9a321f9dd5df50": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "18c465dcd0a04347a25f75022681f251": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a7665da59dbb40029a47fc28164f19d4",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 435779157,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 435779157,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_02dbce26d7584e1c9e4f4eb0695029e4"
          }
        },
        "cf62d06acbc547fab9f00f263a482996": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_77433f1a868e46d9bcf86d5bf2af30db",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 436M/436M [00:12&lt;00:00, 36.0MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b086959745ed412599b3ff6f81d6c23f"
          }
        },
        "a7665da59dbb40029a47fc28164f19d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "02dbce26d7584e1c9e4f4eb0695029e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "77433f1a868e46d9bcf86d5bf2af30db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b086959745ed412599b3ff6f81d6c23f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UxdpJX4wYsFD",
        "outputId": "59800c24-d87b-4043-b8f4-d0ff1b3546c1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ect9MxMggsIR"
      },
      "source": [
        "PATH_TO_PROJECT = '/content/drive/My Drive/Serious/'\n",
        "# path to conll class as well as to conll data\n",
        "PATH_TO_CONLL = PATH_TO_PROJECT + 'coNLL/'\n",
        "PATH_TO_TAG2IDX = PATH_TO_CONLL + 'tag2idx.json'\n",
        "PATH_TO_ONE_TAG2IDX = PATH_TO_CONLL + 'one_tag2idx.json'\n",
        "PATH_TO_CHECKPOINT = '/content/drive/My Drive/models/'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNBmPWcXheAq"
      },
      "source": [
        "### Intall requirements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ePx2hWb5gopz",
        "outputId": "ce3d55ed-09ca-4323-a6ad-f85352dd83b9"
      },
      "source": [
        "!pip install -r '/content/drive/My Drive/Serious/requirements.txt'"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting botocore<1.21.0,>=1.20.19\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c9/84/3f9f99ff67e7f146fb8b785db0920365eb10ba477db5b25a3d8e04b6d8d9/botocore-1.20.19-py2.py3-none-any.whl (7.3MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7.3MB 33.4MB/s \n",
            "\u001b[?25hCollecting s3transfer<0.4.0,>=0.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ea/43/4b4a1b26eb03a429a4c37ca7fdf369d938bd60018fc194e94b8379b0c77c/s3transfer-0.3.4-py2.py3-none-any.whl (69kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 71kB 7.9MB/s \n",
            "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1,>=2.1.0->allennlp~=2.0->-r /content/drive/My Drive/Serious/requirements.txt (line 2)) (0.8.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.1,>=2.1.0->allennlp~=2.0->-r /content/drive/My Drive/Serious/requirements.txt (line 2)) (54.0.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1,>=2.1.0->allennlp~=2.0->-r /content/drive/My Drive/Serious/requirements.txt (line 2)) (1.0.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1,>=2.1.0->allennlp~=2.0->-r /content/drive/My Drive/Serious/requirements.txt (line 2)) (1.1.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1,>=2.1.0->allennlp~=2.0->-r /content/drive/My Drive/Serious/requirements.txt (line 2)) (3.0.5)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1,>=2.1.0->allennlp~=2.0->-r /content/drive/My Drive/Serious/requirements.txt (line 2)) (0.4.1)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1,>=2.1.0->allennlp~=2.0->-r /content/drive/My Drive/Serious/requirements.txt (line 2)) (7.4.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1,>=2.1.0->allennlp~=2.0->-r /content/drive/My Drive/Serious/requirements.txt (line 2)) (1.0.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1,>=2.1.0->allennlp~=2.0->-r /content/drive/My Drive/Serious/requirements.txt (line 2)) (2.0.5)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1,>=2.1.0->allennlp~=2.0->-r /content/drive/My Drive/Serious/requirements.txt (line 2)) (1.0.5)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp~=2.0->-r /content/drive/My Drive/Serious/requirements.txt (line 2)) (0.7.1)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp~=2.0->-r /content/drive/My Drive/Serious/requirements.txt (line 2)) (20.3.0)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp~=2.0->-r /content/drive/My Drive/Serious/requirements.txt (line 2)) (1.4.0)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp~=2.0->-r /content/drive/My Drive/Serious/requirements.txt (line 2)) (1.10.0)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.21.0,>=1.20.19->boto3<2.0,>=1.14->allennlp~=2.0->-r /content/drive/My Drive/Serious/requirements.txt (line 2)) (2.8.1)\n",
            "Building wheels for collected packages: seqeval, sacremoses, jsonnet, overrides\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-cp37-none-any.whl size=16172 sha256=326dd8a7dd7df1f6c774e380f5d035c6c9bccc763aabe853e3756ff6a0bbec5e\n",
            "  Stored in directory: /root/.cache/pip/wheels/52/df/1b/45d75646c37428f7e626214704a0e35bd3cfc32eda37e59e5f\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp37-none-any.whl size=893262 sha256=1c968cf7f70c7bef0b996eb73308e5b973f7204de2b078be15095146ca409958\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "  Building wheel for jsonnet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jsonnet: filename=jsonnet-0.17.0-cp37-cp37m-linux_x86_64.whl size=3388755 sha256=1fbbf50d1c712849580d7da87bdfbfa104decadb4dc575b45a7facd93047158a\n",
            "  Stored in directory: /root/.cache/pip/wheels/26/7a/37/7dbcc30a6b4efd17b91ad1f0128b7bbf84813bd4e1cfb8c1e3\n",
            "  Building wheel for overrides (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for overrides: filename=overrides-3.1.0-cp37-none-any.whl size=10174 sha256=267d9289741bad58530ae24663f603e8fe31461fa2f7138cdceec063dfdf2c42\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/24/13/6ef8600e6f147c95e595f1289a86a3cc82ed65df57582c65a9\n",
            "Successfully built seqeval sacremoses jsonnet overrides\n",
            "\u001b[31mERROR: botocore 1.20.19 has requirement urllib3<1.27,>=1.25.4, but you'll have urllib3 1.24.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: sacremoses, tokenizers, transformers, jsonpickle, tensorboardX, jsonnet, jmespath, botocore, s3transfer, boto3, overrides, sentencepiece, allennlp, seqeval, pytorch-crf\n",
            "Successfully installed allennlp-2.1.0 boto3-1.17.19 botocore-1.20.19 jmespath-0.10.0 jsonnet-0.17.0 jsonpickle-2.0.0 overrides-3.1.0 pytorch-crf-0.7.2 s3transfer-0.3.4 sacremoses-0.0.43 sentencepiece-0.1.95 seqeval-1.2.2 tensorboardX-2.1 tokenizers-0.10.1 transformers-4.3.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ig5ZPACeZfR0"
      },
      "source": [
        "### Loading coNLL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMQq-F5Y-9pO"
      },
      "source": [
        "import sys\n",
        "sys.path.append(PATH_TO_PROJECT)\n",
        "sys.path.append(PATH_TO_CONLL)\n",
        "\n",
        "from importlib import reload\n",
        "import conll as co"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVoDyuLrZUZW"
      },
      "source": [
        "conll = co.CoNLL(PATH_TO_CONLL)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDaiJBYeZz22"
      },
      "source": [
        "# splitting raw data to sentences and labels\n",
        "for typ in conll.types:\n",
        "    conll.split_text_label(typ)\n",
        "\n",
        "# define set of all labels\n",
        "conll.create_set_of_labels()\n",
        "\n",
        "for typ in conll.types:\n",
        "    # for multiple heads of CRF layer\n",
        "    conll.create_one_labeled_data(typ)\n",
        "\n",
        "    # creating one_tag2idx dictionary\n",
        "    conll.create_one_tag2idx(PATH_TO_ONE_TAG2IDX)\n",
        "    conll.create_idx2one_tag()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLenRElisZ7u",
        "outputId": "1afab785-9e29-4bc1-d7f7-fb301853aa17"
      },
      "source": [
        "# dict of tag2idx mapping for each CRF-head (one head responsible for 'LOC' etc.)\n",
        "conll.one_tag2idx"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'LOC': {'B-LOC': 0, 'I-LOC': 3, 'O': 2, 'PAD': 1},\n",
              " 'MISC': {'B-MISC': 0, 'I-MISC': 3, 'O': 2, 'PAD': 1},\n",
              " 'ORG': {'B-ORG': 2, 'I-ORG': 3, 'O': 1, 'PAD': 0},\n",
              " 'PER': {'B-PER': 2, 'I-PER': 0, 'O': 3, 'PAD': 1}}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r31Vd_X7aFYq",
        "outputId": "9e3acf69-48d7-43b4-e348-6d56ae2d8e7d"
      },
      "source": [
        "print(f\"sen example: {conll.sentences['train'][0]}\")\n",
        "print(f\"tags example: {conll.labels['train'][0]}\")\n",
        "print(f\"tags example with only 'ORG' tag: {conll.one_tag_dict['train']['ORG'][0]}\")\n",
        "print(f\"tags for CRF tags has labels: {conll.one_tag_dict['train'].keys()}\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sen example: ['EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'lamb', '.']\n",
            "tags example: ['B-ORG', 'O', 'B-MISC', 'O', 'O', 'O', 'B-MISC', 'O', 'O']\n",
            "tags example with only 'ORG' tag: ['B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "tags for CRF tags has labels: dict_keys(['ORG', 'MISC', 'LOC', 'PER'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0QAfxs-oksA8"
      },
      "source": [
        "### Importing packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRTdZDZhaswg"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.optim import AdamW\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from transformers import BertForTokenClassification\n",
        "from allennlp.modules.elmo import Elmo, batch_to_ids\n",
        "\n",
        "from torchcrf import CRF\n",
        "\n",
        "from sklearn.model_selection import KFold, ParameterGrid\n",
        "\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "import matplotlib\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Wbv4ooQlF-L"
      },
      "source": [
        "### Creating dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWa5WR6-Hq1-"
      },
      "source": [
        "import data_loaders as dalo"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0-SYtcug_EN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "fc5411ddb8894a7a86237731d94aa793",
            "4276ba32ff8a445382a22d7bbca602df",
            "01f50663d93742a5ae72b19622a98245",
            "6a08ae8e94b04ec193c55f3f6539565a",
            "4b70128434634478b4b6c2b28af15a42",
            "ae65a66d3ac64b3e95917bf7efdf5ae1",
            "465e2f8a5a8545e5b8794cd60dc0e942",
            "7bb861d351494b62876bf0e15a4bd6ec"
          ]
        },
        "outputId": "b01ffdc1-6758-479f-969d-949e8e4fce30"
      },
      "source": [
        "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-cased', do_lower_case=False)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fc5411ddb8894a7a86237731d94aa793",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=213450.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxXzWE70ZqHt"
      },
      "source": [
        "TAG_NAMES = ['ORG', 'LOC']\n",
        "NUM_OF_HEADS = len(TAG_NAMES)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GfEU-vEzg1cC",
        "outputId": "2732172b-cb79-40b1-cb01-10264d78ad6e"
      },
      "source": [
        "# in the second argument we pass list of tag names for every head of the model\n",
        "train_dataset, train_sampler, train_dataloader = dalo.create_dataloader(conll, bert_tokenizer, TAG_NAMES)\n",
        "\n",
        "# sanity check for output sizes\n",
        "assert train_dataset[0][0].shape[0] == train_dataset[0][1].shape[0]\n",
        "if NUM_OF_HEADS > 1:\n",
        "  assert train_dataset[0][2].shape[0] == NUM_OF_HEADS\n",
        "  assert train_dataset[0][2].shape[1] == train_dataset[0][0].shape[0]\n",
        "else:\n",
        "  assert len(train_dataset[0][2].shape) == NUM_OF_HEADS # == 1\n",
        "  assert train_dataset[0][2].shape[0] == train_dataset[0][0].shape[0]\n",
        "assert train_dataset[0][3].shape[0] == train_dataset[0][0].shape[0]\n",
        "\n",
        "print(f\"bert sentence shape: {train_dataset[0][0].shape}\")\n",
        "print(f\"elmo sentence shape: {train_dataset[0][1].shape}\")\n",
        "print(f\"number of heads: {train_dataset[0][2].shape[0] if NUM_OF_HEADS > 1 else 1}\")\n",
        "print(f\"tokens len: {train_dataset[0][2].shape[1] if NUM_OF_HEADS > 1 else train_dataset[0][2].shape[0]}\")\n",
        "print(f\"mask shape: {train_dataset[0][3].shape}\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bert sentence shape: torch.Size([173])\n",
            "elmo sentence shape: torch.Size([173, 50])\n",
            "number of heads: 2\n",
            "tokens len: 173\n",
            "mask shape: torch.Size([173])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYwcH-OXOlEK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79b7afb8-5a55-459b-d423-fa7d0e3b3148"
      },
      "source": [
        "valid_dataset, valid_sampler, valid_dataloader = dalo.create_dataloader(conll, bert_tokenizer, TAG_NAMES,\n",
        "                                                                        'valid', desired_pad=train_dataset[0][0].shape[0])\n",
        "\n",
        "# sanity check for output sizes\n",
        "assert valid_dataset[0][0].shape[0] == train_dataset[0][1].shape[0]\n",
        "if NUM_OF_HEADS > 1:\n",
        "  assert valid_dataset[0][2].shape[0] == NUM_OF_HEADS\n",
        "  assert valid_dataset[0][2].shape[1] == train_dataset[0][0].shape[0]\n",
        "else:\n",
        "  assert len(valid_dataset[0][2].shape) == NUM_OF_HEADS # == 1\n",
        "  assert valid_dataset[0][2].shape[0] == train_dataset[0][0].shape[0]\n",
        "assert valid_dataset[0][3].shape[0] == train_dataset[0][0].shape[0]\n",
        "\n",
        "print(f\"bert sentence shape: {valid_dataset[0][0].shape}\")\n",
        "print(f\"elmo sentence shape: {valid_dataset[0][1].shape}\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bert sentence shape: torch.Size([173])\n",
            "elmo sentence shape: torch.Size([173, 50])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HIZt3E_7T7wL"
      },
      "source": [
        "### Creating model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLKRCesGaQge"
      },
      "source": [
        "from bert_config import *\n",
        "from elmo_config import *"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4E_iWY0bTiuL"
      },
      "source": [
        "class BEbiC(nn.Module):\n",
        "    \"\"\"\n",
        "    BERT+Elmo+biLSTM+CRFs\n",
        "    \"\"\"\n",
        "    def __init__(self, hidden_size=128, num_labels=4, tag_names=TAG_NAMES,\n",
        "                 elmo_layers=2, bert_layers=1, concat_bert=True,\n",
        "                 bilstm_layers=1, bilstm_dropout=0):\n",
        "        \"\"\"\n",
        "        Creates model\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        hidden_size: int, default=128\n",
        "          LSTM parameter\n",
        "        num_labels: int, defualt=4\n",
        "          The number of each CRF labels (ex: B-LABEL, I-LABEL, O, PAD for multiple heads case)\n",
        "        tag_names: list of str\n",
        "          List of tag names for models heads\n",
        "        elmo_layers: int, default=2\n",
        "          Num of ELMo layers to be considered\n",
        "        bert_layers: int, default=1\n",
        "          Num of final BERT hidden layers to be used as embedding vector.\n",
        "        concat_bert: bool, default=True\n",
        "          Whether to concat (True) or sum (False) last BERT hidden layers.\n",
        "        bilstm_layers: int, default=1\n",
        "          Number of layers in biLSTM\n",
        "        bilstm_dropout: int, default=0\n",
        "          Dropout value in bilstm layes\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        super(BEbiC, self).__init__()\n",
        "\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_labels = num_labels\n",
        "        self.tag_names = tag_names\n",
        "        self.num_heads = len(self.tag_names)\n",
        "        self.elmo_layers = elmo_layers\n",
        "        self.bert_layers = bert_layers\n",
        "        self.concat_bert = concat_bert\n",
        "        self.bilstm_layers = bilstm_layers\n",
        "        self.bilstm_dropout = bilstm_dropout\n",
        "        \n",
        "        self.bert = BertForTokenClassification.from_pretrained(\n",
        "                        BERT_MODEL,\n",
        "                        output_hidden_states=True)\n",
        "        \n",
        "        for pars in self.bert.parameters():\n",
        "            pars.requires_grad = False\n",
        "        \n",
        "        bert_embedding_dim = self.bert.config.to_dict()['hidden_size']\n",
        "\n",
        "        self.elmo = Elmo(options_file, weight_file, self.elmo_layers, dropout=0, requires_grad=False)\n",
        "        \n",
        "        elmo_embedding_dim = 512 # it's always fixed\n",
        "\n",
        "        \n",
        "        if self.concat_bert:\n",
        "          self.linear1 = nn.Linear(bert_embedding_dim*self.bert_layers+elmo_embedding_dim*self.elmo_layers, 1024)\n",
        "        else:\n",
        "          self.linear1 = nn.Linear(bert_embedding_dim+elmo_embedding_dim*self.elmo_layers, 1024)\n",
        "        \n",
        "        self.bilstm = nn.LSTM(1024, self.hidden_size, self.bilstm_layers, \n",
        "                              bidirectional=True, dropout=self.bilstm_dropout)\n",
        "        self.active_body = True\n",
        "\n",
        "        self.heads = {}\n",
        "        for i, tag in enumerate(self.tag_names):\n",
        "            lin_crf = nn.ModuleDict({'linear': nn.Linear(self.hidden_size*2, self.num_labels),\n",
        "                                     'crf': CRF(num_tags=self.num_labels, batch_first=True)})\n",
        "            self.heads[tag] = lin_crf\n",
        "\n",
        "        self.heads = nn.ModuleDict(self.heads)\n",
        "        self.active_heads = {head: True for head in self.heads.keys()}\n",
        "\n",
        "    def get_model_pars_dict(self):\n",
        "        \"\"\"\n",
        "        Returns dict with described model's parameters.\n",
        "        \n",
        "        \"\"\"\n",
        "        pars = {}\n",
        "        pars['hidden_size'] = self.hidden_size\n",
        "        pars['num_labels'] = self.num_labels\n",
        "        pars['tag_names'] = self.tag_names\n",
        "        pars['elmo_layers'] = self.elmo_layers\n",
        "        pars['bert_layers'] = self.bert_layers\n",
        "        pars['concat_bert'] = int(self.concat_bert)\n",
        "        pars['bilstm_layers'] = self.bilstm_layers\n",
        "        pars['bilstm_dropout'] = self.bilstm_dropout\n",
        "\n",
        "        return pars\n",
        "\n",
        "    def add_head(self, tag_name):\n",
        "        \"\"\"\n",
        "        Adds new head to the model\n",
        "\n",
        "        \"\"\"\n",
        "        self.tag_names.append(tag_name)\n",
        "        self.num_heads += 1\n",
        "        lin_crf = nn.ModuleDict({'linear': nn.Linear(self.hidden_size*2, self.num_labels),\n",
        "                                     'crf': CRF(num_tags=self.num_labels, batch_first=True)})\n",
        "        self.heads.update({tag_name: lin_crf})\n",
        "\n",
        "\n",
        "    def shared_forward(self, bert_ids, elmo_ids, attention_mask):\n",
        "        \"\"\"\n",
        "        Forward propogate of model shared layers.\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        bert_ids:\n",
        "        elmo_ids:\n",
        "        attention_mask:\n",
        "        \n",
        "        Returns\n",
        "        -------\n",
        "        Bilstm logits with shape (seq_len, batch, 2*self.hidden_size)\n",
        "        \n",
        "        \"\"\"\n",
        "\n",
        "        mask = attention_mask.byte()\n",
        "        bert_hiddens = self.bert(bert_ids, attention_mask=mask)[1]\n",
        "        elmo_hiddens = self.elmo(elmo_ids)\n",
        "\n",
        "        if self.concat_bert:\n",
        "            bert_embedding = torch.cat(bert_hiddens[-self.bert_layers:], dim=2)\n",
        "        else:\n",
        "            emb_sum = 0\n",
        "            for h in bert_hiddens[-self.bert_layers:]:\n",
        "                emb_sum += h\n",
        "            bert_embedding = emb_sum\n",
        "\n",
        "        elmo_bert_embeddings = torch.clone(bert_embedding)\n",
        "        for el_hi in elmo_hiddens['elmo_representations']:\n",
        "            elmo_bert_embeddings = torch.cat((elmo_bert_embeddings, el_hi), dim=-1)\n",
        "\n",
        "        linear1_output = nn.functional.relu(self.linear1(elmo_bert_embeddings))\n",
        "\n",
        "        bilstm_output, (h_n, c_n) = self.bilstm(linear1_output)\n",
        "\n",
        "        return bilstm_output\n",
        "    \n",
        "    def get_one_head_loss(self, bilstm_logits, head_labels, attention_mask, head_tag):\n",
        "        \"\"\"\n",
        "        Returns negative log-likelihood for one head.\n",
        "        You should run it after shared forward.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        bilstm_logits:\n",
        "        head_labels:\n",
        "        attention_mask:\n",
        "        head_tag: str\n",
        "          Key of self.heads dictionary.\n",
        "        \n",
        "        Returns\n",
        "        -------\n",
        "        Loss\n",
        "\n",
        "        \"\"\"\n",
        "        lin_out = nn.functional.relu(self.heads[head_tag]['linear'](bilstm_logits))\n",
        "        loss = -1*self.heads[head_tag]['crf'].forward(lin_out, head_labels, mask=attention_mask.byte())\n",
        "        return loss\n",
        "    \n",
        "    def get_one_head_seq(self, bilstm_logits, attention_mask, head_tag):\n",
        "        \"\"\"\n",
        "        Returns the most likely sequence of labels for the given head.\n",
        "        You should run it after shared forward.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        bilstm_logits:\n",
        "        attention_mask:\n",
        "        head_tag: str\n",
        "          Key of self.heads dictionary.\n",
        "        \n",
        "        Returns\n",
        "        -------\n",
        "        List\n",
        "        \"\"\"\n",
        "      \n",
        "        lin_out = nn.functional.relu(self.heads[head_tag]['linear'](bilstm_logits))\n",
        "        seq = self.heads[head_tag]['crf'].decode(lin_out, mask=attention_mask.byte())\n",
        "        return seq\n",
        "    \n",
        "    def forward(self, bert_ids, elmo_ids, head_labels, attention_mask):\n",
        "        \"\"\"\n",
        "        Forward model pass.\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        bert_ids:\n",
        "        elmo_ids:\n",
        "        head_labels:\n",
        "        attention_mask:\n",
        "        \n",
        "        Returns\n",
        "        -------\n",
        "        Total loss for all heads.\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        mask = attention_mask.byte()\n",
        "        bilstm_logits = self.shared_forward(bert_ids, elmo_ids, mask)\n",
        "        head_loss = 0\n",
        "        for i, tag in enumerate(self.heads.keys()):\n",
        "          _one_head_labels = head_labels[:,i,:] if len(self.heads.keys()) > 1 else head_labels\n",
        "          head_loss += self.get_one_head_loss(bilstm_logits, _one_head_labels, mask, tag)\n",
        "        return head_loss\n",
        "    \n",
        "    def freeze_head(self, head_tag):\n",
        "        \"\"\"\n",
        "        Freezes model's head parameters.\n",
        "\n",
        "        \"\"\"\n",
        "        if head_tag not in self.heads.keys():\n",
        "            raise ValueError(f\"Unknown head tag. Please, give one of {self.heads.keys()}\")\n",
        "        \n",
        "        for parameter in self.heads[head_tag].parameters():\n",
        "            parameter.requires_grad = False\n",
        "        \n",
        "        self.active_heads[head_tag] = False\n",
        "    \n",
        "    def unfreeze_head(self, head_tag):\n",
        "        \"\"\"\n",
        "        Unfreezes model's head parameters.\n",
        "\n",
        "        \"\"\"\n",
        "        if head_tag not in self.heads.keys():\n",
        "            raise ValueError(f\"Unknown head tag. Please, give one of {self.heads.keys()}\")\n",
        "        \n",
        "        for parameter in self.heads[head_tag].parameters():\n",
        "            parameter.requires_grad = True\n",
        "        \n",
        "        self.active_heads[head_tag] = True\n",
        "      \n",
        "    def freeze_body(self):\n",
        "        \"\"\"\n",
        "        Freezes model's body parameters.\n",
        "\n",
        "        \"\"\"\n",
        "        for parameter in self.body.parameters():\n",
        "            parameter.requires_grad = False\n",
        "        \n",
        "        self.active_body = False\n",
        "    \n",
        "    def unfreeze_body(self):\n",
        "        \"\"\"\n",
        "        Freezes model's body parameters.\n",
        "\n",
        "        \"\"\"\n",
        "        for parameter in self.body.parameters():\n",
        "            parameter.requires_grad = True\n",
        "        \n",
        "        self.active_body = True\n",
        "    "
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254,
          "referenced_widgets": [
            "97c85b6ec1894241be12e449603bd271",
            "85fd70bc5c664442899cf1870a9b14dc",
            "d569e2b8a3534c0ab6d52d253105359c",
            "6f0816fad65f4f4fb535445471ef8a87",
            "ee151660aa4743929fe1f07d75e39d77",
            "f6f985f8dffb49879355a5c7cd2c27a7",
            "0f94f60f19a443a3a36afa0abaad3b94",
            "55a85e306f4c4555ad8ecb6f6d5a2514",
            "dec096bf6d444252a635b6810fa798d7",
            "d606cc26898e461f8a9a321f9dd5df50",
            "18c465dcd0a04347a25f75022681f251",
            "cf62d06acbc547fab9f00f263a482996",
            "a7665da59dbb40029a47fc28164f19d4",
            "02dbce26d7584e1c9e4f4eb0695029e4",
            "77433f1a868e46d9bcf86d5bf2af30db",
            "b086959745ed412599b3ff6f81d6c23f"
          ]
        },
        "id": "RRrAN94jZ3aO",
        "outputId": "bc75c631-6fb8-417c-ecfe-ee66ea190618"
      },
      "source": [
        "model = BEbiC(hidden_size=512, bert_layers=2, bilstm_layers=2, bilstm_dropout=0.3)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "97c85b6ec1894241be12e449603bd271",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dec096bf6d444252a635b6810fa798d7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=435779157.0, style=ProgressStyle(descriâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "downloading: 100%|##########| 336/336 [00:00<00:00, 796656.95B/s]\n",
            "downloading: 100%|##########| 112140184/112140184 [00:09<00:00, 11844806.03B/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9E6afKGZGZT"
      },
      "source": [
        "N_EPOCHS = 10\n",
        "total_steps = len(train_dataloader) *  N_EPOCHS"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPWdYLAD7fgU"
      },
      "source": [
        "import model_utils as mu"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pd9OMA00PCNX"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_gpu = torch.cuda.device_count()\n",
        "\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hht0bf98-D2"
      },
      "source": [
        "Two head experiment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPu6JHCJ9CIr"
      },
      "source": [
        "model.tag_names"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezSoQeCuPGAL"
      },
      "source": [
        "optimizer = AdamW(params=model.parameters(),lr=5e-4)\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=total_steps\n",
        ")\n",
        "\n",
        "if device.type != 'cpu':\n",
        "    model.to(device)\n",
        "\n",
        "loss_value, head_results = mu.train(model, train_dataloader, optimizer, device, conll, scheduler, n_epoch=N_EPOCHS,\n",
        "                                valid_dataloader=valid_dataloader, path_to_save=PATH_TO_CHECKPOINT)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtNisogew8-P"
      },
      "source": [
        "mu.eval_model(model, valid_dataloader, device, conll)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5H727E05BTw"
      },
      "source": [
        "### Loading pretrained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0pP0yRmB6_L-"
      },
      "source": [
        "from models import *"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "laN65dnu63he"
      },
      "source": [
        "bert_tokenizer, model, opt_state, model_pars = mu.load_checkpoint(PATH_TO_CHECKPOINT+'BEbic_9_state_dict.pth',\n",
        "                                                                  PATH_TO_CHECKPOINT+'BEbic_9_tokenizer.pth')"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4-ilZod9opg",
        "outputId": "acbaa12c-df18-4bde-ca4d-fd711715bc21"
      },
      "source": [
        "model.heads"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ModuleDict(\n",
              "  (ORG): ModuleDict(\n",
              "    (linear): Linear(in_features=1024, out_features=4, bias=True)\n",
              "    (crf): CRF(num_tags=4)\n",
              "  )\n",
              "  (LOC): ModuleDict(\n",
              "    (linear): Linear(in_features=1024, out_features=4, bias=True)\n",
              "    (crf): CRF(num_tags=4)\n",
              "  )\n",
              "  (PER): ModuleDict(\n",
              "    (linear): Linear(in_features=1024, out_features=4, bias=True)\n",
              "    (crf): CRF(num_tags=4)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypJGtiItZUTu",
        "outputId": "db661fa5-983e-421d-f743-9695660f16e0"
      },
      "source": [
        "model_pars"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'bert_layers': 2,\n",
              " 'bilstm_layers': 1,\n",
              " 'concat_bert': 1,\n",
              " 'elmo_layers': 2,\n",
              " 'hidden_size': 512,\n",
              " 'num_labels': 4,\n",
              " 'tag_names': ['ORG', 'LOC', 'PER']}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_nKjJ-dEWfx"
      },
      "source": [
        "optimizer = AdamW(params=model.parameters(),lr=3e-4)\n",
        "optimizer.load_state_dict(opt_state)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8QEc1Bs8AiR"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_gpu = torch.cuda.device_count()\n",
        "\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0M4ByPSW88Mr"
      },
      "source": [
        "valid_dataset, valid_sampler, valid_dataloader = dalo.create_dataloader(conll, bert_tokenizer, \n",
        "                                                                        model_pars['tag_names'], \n",
        "                                                                        'valid', desired_pad=173)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQe_CGEz9DLX"
      },
      "source": [
        "head_result, mean_loss, mean_acc, mean_f1 = mu.eval_model(model, valid_dataloader, device, conll)"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OMwI3yEHDm1Q",
        "outputId": "62c4e7c1-d665-4bee-d059-276f609b2893"
      },
      "source": [
        "head_result"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'LOC': {'acc': 0.9913228024930153, 'f1': 0.9035911602209944},\n",
              " 'ORG': {'acc': 0.9772458628841607, 'f1': 0.634631886047709},\n",
              " 'PER': {'acc': 0.9769100580270793, 'f1': 0.3787528868360277}}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKF7rRyJ9ooK"
      },
      "source": [
        "#### Continue to train pretrained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDIeShD--TQs"
      },
      "source": [
        "TAG_NAMES = ['ORG', 'LOC', 'PER']\n",
        "NUM_OF_HEADS = len(TAG_NAMES)\n",
        "\n",
        "# in the second argument we pass list of tag names for every head of the model\n",
        "train_dataset, train_sampler, train_dataloader = dalo.create_dataloader(conll, TAG_NAMES, bert_tokenizer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_dgr1559Fpy"
      },
      "source": [
        "N_EPOCHS = 5\n",
        "total_steps = len(train_dataloader) *  N_EPOCHS"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wORAtulk9-ue"
      },
      "source": [
        "optimizer = AdamW(params=model.parameters(),lr=1e-4)\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=total_steps\n",
        ")\n",
        "\n",
        "if device.type != 'cpu':\n",
        "    model.to(device)\n",
        "\n",
        "loss_value, head_results = mu.train(model, train_dataloader, optimizer, device, conll, scheduler, n_epoch=N_EPOCHS,\n",
        "                                valid_dataloader=valid_dataloader, path_to_save=PATH_TO_CHECKPOINT)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZDF-YLzZsWU"
      },
      "source": [
        "### Load one-head model to compare with multi-head one"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QqwJJL9Lz66M"
      },
      "source": [
        "conll_old = co.CoNLL_old(PATH_TO_CONLL)\n",
        "for typ in conll_old.types:\n",
        "  conll_old.split_text_label(typ)\n",
        "conll_old.create_tag2idx(PATH_TO_TAG2IDX)\n",
        "conll_old.create_idx2tag()"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQzQbs4JcEZh"
      },
      "source": [
        "# importing BEboC model class\n",
        "from models import *"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jobcoyu_cVz8",
        "outputId": "b1f06ed2-f230-489f-cd80-2a21386fc8d9"
      },
      "source": [
        "bert_tokenizer, old_model, opt_state, model_pars = mu.load_checkpoint(PATH_TO_CHECKPOINT+'ElMo_BERT_biLSTM_oneCRF_19_state_dict.pth',\n",
        "                                                          PATH_TO_CHECKPOINT+'ElMo_BERT_biLSTM_oneCRF_19_tokenizer.pth')"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py:435: UserWarning: Setting attributes on ParameterList is not supported.\n",
            "  warnings.warn(\"Setting attributes on ParameterList is not supported.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VePYY0AXswjd"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_gpu = torch.cuda.device_count()\n",
        "\n",
        "old_model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gh7WnZK9Z3mp"
      },
      "source": [
        "Evaluating on the entire validation dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWS87LaoZ8az"
      },
      "source": [
        "# 173 because I remember this value, it's temporary\n",
        "valid_dataset, valid_sampler, valid_dataloader = dalo.create_dataloader(conll_old, bert_tokenizer, datatype='valid', desired_pad=173)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_Ym-QJpalzu",
        "outputId": "9cec24d4-10c2-4f58-d0e5-093675bf742d"
      },
      "source": [
        "mu.eval_old(old_model, valid_dataloader, device, conll_old.idx2tag)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py:435: UserWarning: Setting attributes on ParameterList is not supported.\n",
            "  warnings.warn(\"Setting attributes on ParameterList is not supported.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(277.77915220994214, 0.9769234902213626, 0.8913024125344965)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zbzPmUC7cZUa"
      },
      "source": [
        "So it's f1-score is 0.89"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-XNTKvo7CBA"
      },
      "source": [
        "Let's evaluate the old model on just PER entity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e___e9zazzUb"
      },
      "source": [
        "valid_dataset, valid_sampler, valid_dataloader = dalo.create_dataloader_old(conll.sentences['valid'],\n",
        "                                                                            conll.one_tag_dict['valid']['PER'], conll_old.tag2idx,\n",
        "                                                                            bert_tokenizer, datatype='valid', desired_pad=173)"
      ],
      "execution_count": 195,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rr2ZBFJ8mki1",
        "outputId": "72bbee10-e127-4565-c66c-08a16d397b88"
      },
      "source": [
        "mu.eval_old(old_model, valid_dataloader, device, conll_old.idx2tag)"
      ],
      "execution_count": 197,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py:435: UserWarning: Setting attributes on ParameterList is not supported.\n",
            "  warnings.warn(\"Setting attributes on ParameterList is not supported.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2879.9386127178486, 0.8668600902643456, 0.4219006007646095)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 197
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pg47RHnf7G8N"
      },
      "source": [
        "ORG"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RIWApeiF7ERC"
      },
      "source": [
        "valid_dataset, valid_sampler, valid_dataloader = dalo.create_dataloader_old(conll.sentences['valid'],\n",
        "                                                                            conll.one_tag_dict['valid']['ORG'], conll_old.tag2idx,\n",
        "                                                                            bert_tokenizer, datatype='valid', desired_pad=173)"
      ],
      "execution_count": 198,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AmzEKqGO6HiW",
        "outputId": "0c82c70b-d424-4d9d-e0f7-7803309ad03e"
      },
      "source": [
        "mu.eval_old(old_model, valid_dataloader, device, conll_old.idx2tag)"
      ],
      "execution_count": 199,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py:435: UserWarning: Setting attributes on ParameterList is not supported.\n",
            "  warnings.warn(\"Setting attributes on ParameterList is not supported.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4071.6029616135816, 0.8300827423167849, 0.3436274160188289)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 199
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzz7AXK37d7h"
      },
      "source": [
        "LOC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FhUsB3vS7LXR"
      },
      "source": [
        "valid_dataset, valid_sampler, valid_dataloader = dalo.create_dataloader_old(conll.sentences['valid'],\n",
        "                                                                            conll.one_tag_dict['valid']['LOC'], conll_old.tag2idx,\n",
        "                                                                            bert_tokenizer, datatype='valid', desired_pad=173)"
      ],
      "execution_count": 200,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfmeB_Xa7hA9",
        "outputId": "0bb38b0a-e945-462b-f6a0-6db5c46a0051"
      },
      "source": [
        "mu.eval_old(old_model, valid_dataloader, device, conll_old.idx2tag)"
      ],
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py:435: UserWarning: Setting attributes on ParameterList is not supported.\n",
            "  warnings.warn(\"Setting attributes on ParameterList is not supported.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4093.646503155048, 0.8329706640876854, 0.44121974053764873)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 201
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-RRhpGeU7oPB"
      },
      "source": [
        "The last values above are f1-scores.\n",
        "\n",
        "In the case of multiple-head fitting of this 3 heads at the same time we got:\n",
        "\n",
        "'PER' - 0.3787528868360277 (vs 0.4219006007646095)\n",
        "\n",
        "'ORG' - 0.6343975283213182 (vs 0.3436274160188289)\n",
        "\n",
        "'LOC' - 0.9035911602209944 (vs 0.44121974053764873)\n",
        "\n",
        "So, results of multiple heads look better!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihuzR6kMikKm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}