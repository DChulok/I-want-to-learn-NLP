{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MULTIPLE-v2.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "zNBmPWcXheAq",
        "U5H727E05BTw",
        "dKF7rRyJ9ooK",
        "iKFEtgArImqL",
        "jVKrbJRDWF2H",
        "r6OWQ2XsVzwK",
        "Qdz9TOt4yhYf",
        "VNprUw27Ohim",
        "VBRyBAiSxZyF"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "89df23966a6e494d9d8b479a3ba45df0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9eaf1561d5134791ba7a147396998832",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_fe7b9dfed3bc4d45886f057ca6458c6f",
              "IPY_MODEL_4c2bbe8cc471421aa70523d8e53d15e6"
            ]
          }
        },
        "9eaf1561d5134791ba7a147396998832": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fe7b9dfed3bc4d45886f057ca6458c6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f153f73183d446459e277077e2a4660d",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 213450,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 213450,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_da00c5fe8fc442a2a5e37e3e62b75e8a"
          }
        },
        "4c2bbe8cc471421aa70523d8e53d15e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_67c433f30c704f4787a937a4171f3787",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 213k/213k [00:00&lt;00:00, 2.87MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_72177b76b319437d8d6a3ab9afb5764b"
          }
        },
        "f153f73183d446459e277077e2a4660d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "da00c5fe8fc442a2a5e37e3e62b75e8a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "67c433f30c704f4787a937a4171f3787": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "72177b76b319437d8d6a3ab9afb5764b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "52187f2e41b84a38921aca08a9273288": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_533008fb1deb40a2b356123f5e115bee",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_cb1a1daa49b84a1a8104704553ca2fca",
              "IPY_MODEL_c27bdb21d5c74eb4ba893600bba3b13c"
            ]
          }
        },
        "533008fb1deb40a2b356123f5e115bee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cb1a1daa49b84a1a8104704553ca2fca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0794b38fed4d46e997a6234c0150ace6",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 570,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 570,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f5a906bd709a40e08cb1ebeaed4b5473"
          }
        },
        "c27bdb21d5c74eb4ba893600bba3b13c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ad3acc3587a9497a848179aee11783d2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 570/570 [00:00&lt;00:00, 843B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_33c130e14948460884b2fe730d805492"
          }
        },
        "0794b38fed4d46e997a6234c0150ace6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f5a906bd709a40e08cb1ebeaed4b5473": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ad3acc3587a9497a848179aee11783d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "33c130e14948460884b2fe730d805492": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7b9ccc39844f4a3a90e66e3592220189": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_80104aa86a6c4b549364ba8a5dfe0c66",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_45d9be3605ec4c29b918b6b3f7928466",
              "IPY_MODEL_985776de692e44b2b72b88b18478d43b"
            ]
          }
        },
        "80104aa86a6c4b549364ba8a5dfe0c66": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "45d9be3605ec4c29b918b6b3f7928466": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f61b11f529c741519fb9e55217c45703",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 435779157,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 435779157,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6a497f8fddcd4529a120c406c966c4ba"
          }
        },
        "985776de692e44b2b72b88b18478d43b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4eb651b10fe44de99238edab6df466eb",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 436M/436M [42:20&lt;00:00, 172kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_97ddea3da307453d9c491efe9a3e5081"
          }
        },
        "f61b11f529c741519fb9e55217c45703": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6a497f8fddcd4529a120c406c966c4ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4eb651b10fe44de99238edab6df466eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "97ddea3da307453d9c491efe9a3e5081": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UxdpJX4wYsFD",
        "outputId": "41508778-f887-45ed-ec2e-322e36e957ff"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ect9MxMggsIR"
      },
      "source": [
        "PATH_TO_PROJECT = '/content/drive/My Drive/Serious/'\n",
        "# path to conll class as well as to conll data\n",
        "PATH_TO_CONLL = PATH_TO_PROJECT + 'coNLL/'\n",
        "PATH_TO_TAG2IDX = PATH_TO_CONLL + 'tag2idx.json'\n",
        "PATH_TO_ONE_TAG2IDX = PATH_TO_CONLL + 'one_tag2idx.json'\n",
        "PATH_TO_CHECKPOINT = '/content/drive/My Drive/models/'\n",
        "PATH_TO_NEW_CHECKPOINT = PATH_TO_CHECKPOINT+'New_results/'"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNBmPWcXheAq"
      },
      "source": [
        "### Intall requirements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ePx2hWb5gopz",
        "outputId": "5229789e-ce11-4356-f58a-35cef9a44676"
      },
      "source": [
        "!pip install -r '/content/drive/My Drive/Serious/requirements.txt'"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers==4.3.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f9/54/5ca07ec9569d2f232f3166de5457b63943882f7950ddfcc887732fc7fb23/transformers-4.3.3-py3-none-any.whl (1.9MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.9MB 18.4MB/s \n",
            "\u001b[?25hCollecting allennlp~=2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ed/eb/0c7ce6af0dfbc9c168a263a534e258447eff707c76df26356d4080900dd0/allennlp-2.4.0-py3-none-any.whl (625kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 634kB 41.5MB/s \n",
            "\u001b[?25hCollecting seqeval~=1.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9d/2d/233c79d5b4e5ab1dbf111242299153f3caddddbb691219f363ad55ce783d/seqeval-1.2.2.tar.gz (43kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 51kB 8.4MB/s \n",
            "\u001b[?25hCollecting pytorch-crf~=0.7\n",
            "  Downloading https://files.pythonhosted.org/packages/96/7d/4c4688e26ea015fc118a0327e5726e6596836abce9182d3738be8ec2e32a/pytorch_crf-0.7.2-py3-none-any.whl\n",
            "Collecting torch~=1.7.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/90/5d/095ddddc91c8a769a68c791c019c5793f9c4456a688ddd235d6670924ecb/torch-1.7.1-cp37-cp37m-manylinux1_x86_64.whl (776.8MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 776.8MB 23kB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.3->-r /content/drive/My Drive/Serious/requirements.txt (line 1)) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.3->-r /content/drive/My Drive/Serious/requirements.txt (line 1)) (4.41.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.3->-r /content/drive/My Drive/Serious/requirements.txt (line 1)) (1.19.5)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/04/5b870f26a858552025a62f1649c20d29d2672c02ff3c3fb4c688ca46467a/tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.3MB 49.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.3->-r /content/drive/My Drive/Serious/requirements.txt (line 1)) (2019.12.20)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.3->-r /content/drive/My Drive/Serious/requirements.txt (line 1)) (3.10.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.3->-r /content/drive/My Drive/Serious/requirements.txt (line 1)) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.3->-r /content/drive/My Drive/Serious/requirements.txt (line 1)) (20.9)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 901kB 40.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from allennlp~=2.0->-r /content/drive/My Drive/Serious/requirements.txt (line 2)) (2.10.0)\n",
            "Collecting wandb<0.11.0,>=0.10.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f6/28/4aefc543967839bdb4e139831b82004279f1c435cede2a9557ccf8369875/wandb-0.10.27-py2.py3-none-any.whl (2.1MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.1MB 48.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: lmdb in /usr/local/lib/python3.7/dist-packages (from allennlp~=2.0->-r /content/drive/My Drive/Serious/requirements.txt (line 2)) (0.99)\n",
            "Collecting jsonnet>=0.10.0; sys_platform != \"win32\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/42/40/6f16e5ac994b16fa71c24310f97174ce07d3a97b433275589265c6b94d2b/jsonnet-0.17.0.tar.gz (259kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 266kB 61.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: torchvision<0.10.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from allennlp~=2.0->-r /content/drive/My Drive/Serious/requirements.txt (line 2)) (0.9.1+cu101)\n",
            "Collecting huggingface-hub>=0.0.8\n",
            "  Downloading https://files.pythonhosted.org/packages/a1/88/7b1e45720ecf59c6c6737ff332f41c955963090a18e72acbcbeac6b25e86/huggingface_hub-0.0.8-py3-none-any.whl\n",
            "Collecting tensorboardX>=1.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/84/46421bd3e0e89a92682b1a38b40efc22dafb6d8e3d947e4ceefd4a5fabc7/tensorboardX-2.2-py2.py3-none-any.whl (120kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 122kB 58.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytest in /usr/local/lib/python3.7/dist-packages (from allennlp~=2.0->-r /content/drive/My Drive/Serious/requirements.txt (line 2)) (3.6.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from allennlp~=2.0->-r /content/drive/My Drive/Serious/requirements.txt (line 2)) (1.4.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.7/dist-packages (from allennlp~=2.0->-r /content/drive/My Drive/Serious/requirements.txt (line 2)) (8.7.0)\n",
            "Requirement already satisfied: spacy<3.1,>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from allennlp~=2.0->-r /content/drive/My Drive/Serious/requirements.txt (line 2)) (2.2.4)\n",
            "Collecting boto3<2.0,>=1.14\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4b/a3/388f78a63b0545f30daf13e6542b0d850f621ff51ef721cf431eef609c87/boto3-1.17.59-py2.py3-none-any.whl (131kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 133kB 60.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from allennlp~=2.0->-r /content/drive/My Drive/Serious/requirements.txt (line 2)) (0.22.2.post1)\n",
            "Collecting overrides==3.1.0\n",
            "  Downloading https://files.pythonhosted.org/packages/ff/b1/10f69c00947518e6676bbd43e739733048de64b8dd998e9c2d5a71f44c5d/overrides-3.1.0.tar.gz\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from allennlp~=2.0->-r /content/drive/My Drive/Serious/requirements.txt (line 2)) (3.2.5)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.2MB 46.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch~=1.7.1->-r /content/drive/My Drive/Serious/requirements.txt (line 5)) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers==4.3.3->-r /content/drive/My Drive/Serious/requirements.txt (line 1)) (3.4.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.3.3->-r /content/drive/My Drive/Serious/requirements.txt (line 1)) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.3.3->-r /content/drive/My Drive/Serious/requirements.txt (line 1)) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.3.3->-r /content/drive/My Drive/Serious/requirements.txt (line 1)) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.3.3->-r /content/drive/My Drive/Serious/requirements.txt (line 1)) (1.24.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.3.3->-r /content/drive/My Drive/Serious/requirements.txt (line 1)) (2.4.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.3.3->-r /content/drive/My Drive/Serious/requirements.txt (line 1)) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.3.3->-r /content/drive/My Drive/Serious/requirements.txt (line 1)) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.3.3->-r /content/drive/My Drive/Serious/requirements.txt (line 1)) (1.15.0)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading https://files.pythonhosted.org/packages/f5/e8/f6bd1eee09314e7e6dee49cbe2c5e22314ccdb38db16c9fc72d2fa80d054/docker_pycreds-0.4.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb<0.11.0,>=0.10.0->allennlp~=2.0->-r /content/drive/My Drive/Serious/requirements.txt (line 2)) (3.13)\n",
            "Collecting sentry-sdk>=0.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f3/92/5a33be64990ba815364a8f2dd9e6f51de60d23dfddafb4f1fc5577d4dc64/sentry_sdk-1.0.0-py2.py3-none-any.whl (131kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 133kB 59.1MB/s \n",
            "\u001b[?25hCollecting pathtools\n",
            "  Downloading https://files.pythonhosted.org/packages/e7/7f/470d6fcdf23f9f3518f6b0b76be9df16dcc8630ad409947f8be2eb0ed13a/pathtools-0.1.2.tar.gz\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb<0.11.0,>=0.10.0->allennlp~=2.0->-r /content/drive/My Drive/Serious/requirements.txt (line 2)) (5.4.8)\n",
            "Collecting GitPython>=1.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/99/98019716955ba243657daedd1de8f3a88ca1f5b75057c38e959db22fb87b/GitPython-3.1.14-py3-none-any.whl (159kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163kB 52.0MB/s \n",
            "\u001b[?25hCollecting configparser>=3.8.1\n",
            "  Downloading https://files.pythonhosted.org/packages/fd/01/ff260a18caaf4457eb028c96eeb405c4a230ca06c8ec9c1379f813caa52e/configparser-5.0.2-py3-none-any.whl\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb<0.11.0,>=0.10.0->allennlp~=2.0->-r /content/drive/My Drive/Serious/requirements.txt (line 2)) (2.8.1)\n",
            "Collecting shortuuid>=0.5.0\n",
            "  Downloading https://files.pythonhosted.org/packages/25/a6/2ecc1daa6a304e7f1b216f0896b26156b78e7c38e1211e9b798b4716c53d/shortuuid-1.0.1-py3-none-any.whl\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb<0.11.0,>=0.10.0->allennlp~=2.0->-r /content/drive/My Drive/Serious/requirements.txt (line 2)) (2.3)\n",
            "Collecting subprocess32>=3.5.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/c8/564be4d12629b912ea431f1a50eb8b3b9d00f1a0b1ceff17f266be190007/subprocess32-3.5.4.tar.gz (97kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102kB 15.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb<0.11.0,>=0.10.0->allennlp~=2.0->-r /content/drive/My Drive/Serious/requirements.txt (line 2)) (3.12.4)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision<0.10.0,>=0.8.1->allennlp~=2.0->-r /content/drive/My Drive/Serious/requirements.txt (line 2)) (7.1.2)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp~=2.0->-r /content/drive/My Drive/Serious/requirements.txt (line 2)) (1.10.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp~=2.0->-r /content/drive/My Drive/Serious/requirements.txt (line 2)) (0.7.1)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp~=2.0->-r /content/drive/My Drive/Serious/requirements.txt (line 2)) (1.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp~=2.0->-r /content/drive/My Drive/Serious/requirements.txt (line 2)) (56.0.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp~=2.0->-r /content/drive/My Drive/Serious/requirements.txt (line 2)) (20.3.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1,>=2.1.0->allennlp~=2.0->-r /content/drive/My Drive/Serious/requirements.txt (line 2)) (7.4.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1,>=2.1.0->allennlp~=2.0->-r /content/drive/My Drive/Serious/requirements.txt (line 2)) (3.0.5)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1,>=2.1.0->allennlp~=2.0->-r /content/drive/My Drive/Serious/requirements.txt (line 2)) (0.4.1)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1,>=2.1.0->allennlp~=2.0->-r /content/drive/My Drive/Serious/requirements.txt (line 2)) (1.1.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1,>=2.1.0->allennlp~=2.0->-r /content/drive/My Drive/Serious/requirements.txt (line 2)) (1.0.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1,>=2.1.0->allennlp~=2.0->-r /content/drive/My Drive/Serious/requirements.txt (line 2)) (0.8.2)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1,>=2.1.0->allennlp~=2.0->-r /content/drive/My Drive/Serious/requirements.txt (line 2)) (1.0.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1,>=2.1.0->allennlp~=2.0->-r /content/drive/My Drive/Serious/requirements.txt (line 2)) (1.0.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1,>=2.1.0->allennlp~=2.0->-r /content/drive/My Drive/Serious/requirements.txt (line 2)) (2.0.5)\n",
            "Collecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n",
            "Collecting s3transfer<0.5.0,>=0.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/63/d0/693477c688348654ddc21dcdce0817653a294aa43f41771084c25e7ff9c7/s3transfer-0.4.2-py2.py3-none-any.whl (79kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81kB 12.5MB/s \n",
            "\u001b[?25hCollecting botocore<1.21.0,>=1.20.59\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/25/68/e91883d8f68183216fac7cfa855cd0d1b3336c3d4b82cd4b99591118bcc7/botocore-1.20.59-py2.py3-none-any.whl (7.4MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7.4MB 41.2MB/s \n",
            "\u001b[?25hCollecting gitdb<5,>=4.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ea/e8/f414d1a4f0bbc668ed441f74f44c116d9816833a48bf81d22b697090dba8/gitdb-4.0.7-py3-none-any.whl (63kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 71kB 11.2MB/s \n",
            "\u001b[?25hCollecting smmap<5,>=3.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/68/ee/d540eb5e5996eb81c26ceffac6ee49041d473bc5125f2aa995cf51ec1cf1/smmap-4.0.0-py2.py3-none-any.whl\n",
            "Building wheels for collected packages: seqeval, jsonnet, overrides, pathtools, subprocess32\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-cp37-none-any.whl size=16172 sha256=8eef9a25b2d666d9c326d67321b2d52c20a9333957465c8886f3452395aabfb5\n",
            "  Stored in directory: /root/.cache/pip/wheels/52/df/1b/45d75646c37428f7e626214704a0e35bd3cfc32eda37e59e5f\n",
            "  Building wheel for jsonnet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jsonnet: filename=jsonnet-0.17.0-cp37-cp37m-linux_x86_64.whl size=3388777 sha256=7de8dd7396159e5088b1701e301647665241de9d0a24201afc063b5be64d537d\n",
            "  Stored in directory: /root/.cache/pip/wheels/26/7a/37/7dbcc30a6b4efd17b91ad1f0128b7bbf84813bd4e1cfb8c1e3\n",
            "  Building wheel for overrides (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for overrides: filename=overrides-3.1.0-cp37-none-any.whl size=10174 sha256=6fb64f5c258e9c71cfc59360701270b3aa51d8ee14de52c297a4700700dd2452\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/24/13/6ef8600e6f147c95e595f1289a86a3cc82ed65df57582c65a9\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-cp37-none-any.whl size=8786 sha256=bcccb1cdbdbccfded61c916933e107449717d2ded5931d6dc599ae1a5ed5a2d7\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/04/79/c3b0c3a0266a3cb4376da31e5bfe8bba0c489246968a68e843\n",
            "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for subprocess32: filename=subprocess32-3.5.4-cp37-none-any.whl size=6489 sha256=3a6996c98bae698a2accf526c61e7449fcd62abebae48ea8940d8a31ed6f8da3\n",
            "  Stored in directory: /root/.cache/pip/wheels/68/39/1a/5e402bdfdf004af1786c8b853fd92f8c4a04f22aad179654d1\n",
            "Successfully built seqeval jsonnet overrides pathtools subprocess32\n",
            "\u001b[31mERROR: torchvision 0.9.1+cu101 has requirement torch==1.8.1, but you'll have torch 1.7.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: torchtext 0.9.1 has requirement torch==1.8.1, but you'll have torch 1.7.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: botocore 1.20.59 has requirement urllib3<1.27,>=1.25.4, but you'll have urllib3 1.24.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tokenizers, sacremoses, transformers, torch, docker-pycreds, sentry-sdk, pathtools, smmap, gitdb, GitPython, configparser, shortuuid, subprocess32, wandb, jsonnet, huggingface-hub, tensorboardX, jmespath, botocore, s3transfer, boto3, overrides, sentencepiece, allennlp, seqeval, pytorch-crf\n",
            "  Found existing installation: torch 1.8.1+cu101\n",
            "    Uninstalling torch-1.8.1+cu101:\n",
            "      Successfully uninstalled torch-1.8.1+cu101\n",
            "Successfully installed GitPython-3.1.14 allennlp-2.4.0 boto3-1.17.59 botocore-1.20.59 configparser-5.0.2 docker-pycreds-0.4.0 gitdb-4.0.7 huggingface-hub-0.0.8 jmespath-0.10.0 jsonnet-0.17.0 overrides-3.1.0 pathtools-0.1.2 pytorch-crf-0.7.2 s3transfer-0.4.2 sacremoses-0.0.45 sentencepiece-0.1.95 sentry-sdk-1.0.0 seqeval-1.2.2 shortuuid-1.0.1 smmap-4.0.0 subprocess32-3.5.4 tensorboardX-2.2 tokenizers-0.10.2 torch-1.7.1 transformers-4.3.3 wandb-0.10.27\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ig5ZPACeZfR0"
      },
      "source": [
        "### Loading coNLL and my modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMQq-F5Y-9pO"
      },
      "source": [
        "import sys\n",
        "sys.path.append(PATH_TO_PROJECT)\n",
        "sys.path.append(PATH_TO_CONLL)\n",
        "\n",
        "from importlib import reload\n",
        "import conll as co\n",
        "\n",
        "import data_loaders as dalo\n",
        "import model_utils as mu\n",
        "\n",
        "from bert_config import *\n",
        "from elmo_config import *"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVoDyuLrZUZW"
      },
      "source": [
        "conll = co.CoNLL(PATH_TO_CONLL)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDaiJBYeZz22"
      },
      "source": [
        "# splitting raw data to sentences and labels\n",
        "for typ in conll.types:\n",
        "    conll.split_text_label(typ)\n",
        "\n",
        "# define set of all labels\n",
        "conll.create_set_of_labels()\n",
        "\n",
        "for typ in conll.types:\n",
        "    # for multiple heads of CRF layer\n",
        "    conll.create_one_labeled_data(typ)\n",
        "\n",
        "    # creating one_tag2idx dictionary\n",
        "    conll.create_one_tag2idx(PATH_TO_ONE_TAG2IDX)\n",
        "    conll.create_idx2one_tag()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLenRElisZ7u",
        "outputId": "1c45995d-a2e3-4aeb-a5d0-f24d05d2fda3"
      },
      "source": [
        "# dict of tag2idx mapping for each CRF-head (one head responsible for 'LOC' etc.)\n",
        "conll.one_tag2idx"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'LOC': {'B-LOC': 0, 'I-LOC': 3, 'O': 2, 'PAD': 1},\n",
              " 'MISC': {'B-MISC': 0, 'I-MISC': 3, 'O': 2, 'PAD': 1},\n",
              " 'ORG': {'B-ORG': 2, 'I-ORG': 3, 'O': 1, 'PAD': 0},\n",
              " 'PER': {'B-PER': 2, 'I-PER': 0, 'O': 3, 'PAD': 1}}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r31Vd_X7aFYq",
        "outputId": "2b4ada41-e135-4fd5-88d0-4701326656b6"
      },
      "source": [
        "print(f\"sen example: {conll.sentences['train'][0]}\")\n",
        "print(f\"tags example: {conll.labels['train'][0]}\")\n",
        "print(f\"tags example with only 'ORG' tag: {conll.one_tag_dict['train']['ORG'][0]}\")\n",
        "print(f\"tags for CRF tags has labels: {conll.one_tag_dict['train'].keys()}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sen example: ['EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'lamb', '.']\n",
            "tags example: ['B-ORG', 'O', 'B-MISC', 'O', 'O', 'O', 'B-MISC', 'O', 'O']\n",
            "tags example with only 'ORG' tag: ['B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "tags for CRF tags has labels: dict_keys(['MISC', 'LOC', 'PER', 'ORG'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0QAfxs-oksA8"
      },
      "source": [
        "### Importing external packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRTdZDZhaswg"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.optim import AdamW\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from transformers import BertForTokenClassification\n",
        "from allennlp.modules.elmo import Elmo, batch_to_ids\n",
        "\n",
        "from torchcrf import CRF\n",
        "\n",
        "from sklearn.model_selection import KFold, ParameterGrid\n",
        "\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "import matplotlib\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "import json\n",
        "import gc"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZDfG9yZ_T8M",
        "outputId": "5768e4b4-afe3-4f6a-f810-f9b34e416039"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_gpu = torch.cuda.device_count()\n",
        "print(torch.cuda.get_device_name())\n",
        "\n",
        "#model.to(device)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Wbv4ooQlF-L"
      },
      "source": [
        "### Creating dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0-SYtcug_EN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "89df23966a6e494d9d8b479a3ba45df0",
            "9eaf1561d5134791ba7a147396998832",
            "fe7b9dfed3bc4d45886f057ca6458c6f",
            "4c2bbe8cc471421aa70523d8e53d15e6",
            "f153f73183d446459e277077e2a4660d",
            "da00c5fe8fc442a2a5e37e3e62b75e8a",
            "67c433f30c704f4787a937a4171f3787",
            "72177b76b319437d8d6a3ab9afb5764b"
          ]
        },
        "outputId": "6e9de02a-d48c-4047-9c58-fae7fd498828"
      },
      "source": [
        "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-cased', do_lower_case=False)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "89df23966a6e494d9d8b479a3ba45df0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=213450.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxXzWE70ZqHt"
      },
      "source": [
        "TAG_NAMES = ['ORG', 'LOC', 'PER']\n",
        "NUM_OF_HEADS = len(TAG_NAMES)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GfEU-vEzg1cC",
        "outputId": "01dd27ac-c8ba-427c-8ae7-e763e8cdb2d9"
      },
      "source": [
        "# in the second argument we pass list of tag names for every head of the model\n",
        "train_dataset, train_sampler, train_dataloader = dalo.create_dataloader(conll, bert_tokenizer, TAG_NAMES)\n",
        "\n",
        "# sanity check for output sizes\n",
        "assert train_dataset[0][0].shape[0] == train_dataset[0][1].shape[0]\n",
        "if NUM_OF_HEADS > 1:\n",
        "  assert train_dataset[0][2].shape[0] == NUM_OF_HEADS\n",
        "  assert train_dataset[0][2].shape[1] == train_dataset[0][0].shape[0]\n",
        "else:\n",
        "  assert len(train_dataset[0][2].shape) == NUM_OF_HEADS # == 1\n",
        "  assert train_dataset[0][2].shape[0] == train_dataset[0][0].shape[0]\n",
        "assert train_dataset[0][3].shape[0] == train_dataset[0][0].shape[0]\n",
        "\n",
        "print(f\"bert sentence shape: {train_dataset[0][0].shape}\")\n",
        "print(f\"elmo sentence shape: {train_dataset[0][1].shape}\")\n",
        "print(f\"number of heads: {train_dataset[0][2].shape[0] if NUM_OF_HEADS > 1 else 1}\")\n",
        "print(f\"tokens len: {train_dataset[0][2].shape[1] if NUM_OF_HEADS > 1 else train_dataset[0][2].shape[0]}\")\n",
        "print(f\"mask shape: {train_dataset[0][3].shape}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bert sentence shape: torch.Size([173])\n",
            "elmo sentence shape: torch.Size([173, 50])\n",
            "number of heads: 3\n",
            "tokens len: 173\n",
            "mask shape: torch.Size([173])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYwcH-OXOlEK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08380815-c727-45fe-c2a6-a235e6d5742e"
      },
      "source": [
        "valid_dataset, valid_sampler, valid_dataloader = dalo.create_dataloader(conll, bert_tokenizer, TAG_NAMES,\n",
        "                                                                        'valid', desired_pad=train_dataset[0][0].shape[0])\n",
        "\n",
        "# sanity check for output sizes\n",
        "assert valid_dataset[0][0].shape[0] == train_dataset[0][1].shape[0]\n",
        "if NUM_OF_HEADS > 1:\n",
        "  assert valid_dataset[0][2].shape[0] == NUM_OF_HEADS\n",
        "  assert valid_dataset[0][2].shape[1] == train_dataset[0][0].shape[0]\n",
        "else:\n",
        "  assert len(valid_dataset[0][2].shape) == NUM_OF_HEADS # == 1\n",
        "  assert valid_dataset[0][2].shape[0] == train_dataset[0][0].shape[0]\n",
        "assert valid_dataset[0][3].shape[0] == train_dataset[0][0].shape[0]\n",
        "\n",
        "print(f\"bert sentence shape: {valid_dataset[0][0].shape}\")\n",
        "print(f\"elmo sentence shape: {valid_dataset[0][1].shape}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bert sentence shape: torch.Size([173])\n",
            "elmo sentence shape: torch.Size([173, 50])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HIZt3E_7T7wL"
      },
      "source": [
        "### Creating model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9crDVcjDFO_"
      },
      "source": [
        "def freeze_bert_layers(bert, num_of_trainable=1):\n",
        "    for name, par in bert.named_parameters():\n",
        "        if sum([str(i) in name for i in range(12-num_of_trainable, 12)]) == 0:\n",
        "            par.requires_grad = False\n",
        "\n",
        "def unfreeze_bert_layers(bert, num_of_trainable=1):\n",
        "    for name, par in bert.named_parameters():\n",
        "        if sum([str(i) in name for i in range(12-num_of_trainable, 12)]) != 0:\n",
        "            par.requires_grad = True"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4E_iWY0bTiuL"
      },
      "source": [
        "class BEbiC(nn.Module):\n",
        "    \"\"\"\n",
        "    BERT+Elmo+biLSTM+CRFs\n",
        "    \"\"\"\n",
        "    def __init__(self, tag_names, hidden_size=128, num_labels=4, elmo_layers=2, \n",
        "                 bert_layers=1, concat_bert=True, num_of_trainable_bert_layers=0, \n",
        "                 bilstm_layers=1, dropout=0):\n",
        "        \"\"\"\n",
        "        Creates model\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        hidden_size: int, default=128\n",
        "          LSTM parameter\n",
        "        num_labels: int, defualt=4\n",
        "          The number of each CRF labels (ex: B-LABEL, I-LABEL, O, PAD for multiple heads case)\n",
        "        tag_names: list of str\n",
        "          List of tag names for models heads\n",
        "        elmo_layers: int, default=2\n",
        "          Num of ELMo layers to be considered\n",
        "        bert_layers: int, default=1\n",
        "          Num of final BERT hidden layers to be used as embedding vector.\n",
        "        concat_bert: bool, default=True\n",
        "          Whether to concat (True) or sum (False) last BERT hidden layers.\n",
        "        num_of_trainable_bert_layers: int, default=0\n",
        "          Num of trainable bert layers.\n",
        "        bilstm_layers: int, default=1\n",
        "          Number of layers in biLSTM\n",
        "        dropout: float, default=0\n",
        "          Dropout value\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        super(BEbiC, self).__init__()\n",
        "\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_labels = num_labels\n",
        "        self.tag_names = tag_names\n",
        "        self.num_heads = len(self.tag_names)\n",
        "        self.elmo_layers = elmo_layers\n",
        "        self.bert_layers = bert_layers\n",
        "        self.concat_bert = concat_bert\n",
        "        self.num_of_trainable_bert_layers = num_of_trainable_bert_layers\n",
        "        self.bilstm_layers = bilstm_layers\n",
        "        self.dropout = dropout\n",
        "        \n",
        "        self.bert = BertForTokenClassification.from_pretrained(\n",
        "                        BERT_MODEL,\n",
        "                        output_hidden_states=True)\n",
        "        \n",
        "        #for pars in self.bert.parameters():\n",
        "        #    pars.requires_grad = False\n",
        "        freeze_bert_layers(self.bert, num_of_trainable=self.num_of_trainable_bert_layers)\n",
        "        \n",
        "        bert_embedding_dim = self.bert.config.to_dict()['hidden_size']\n",
        "\n",
        "        self.elmo = Elmo(options_file, weight_file, self.elmo_layers, dropout=0, requires_grad=False)\n",
        "        \n",
        "        elmo_embedding_dim = 512 # it's always fixed\n",
        "\n",
        "        \n",
        "        if self.concat_bert:\n",
        "          self.linear1 = nn.Linear(bert_embedding_dim*self.bert_layers+elmo_embedding_dim*self.elmo_layers, 1024)\n",
        "        else:\n",
        "          self.linear1 = nn.Linear(bert_embedding_dim+elmo_embedding_dim*self.elmo_layers, 1024)\n",
        "\n",
        "        self.dp1 = nn.Dropout(self.dropout)\n",
        "        \n",
        "        self.bilstm = nn.LSTM(1024, self.hidden_size, self.bilstm_layers, \n",
        "                              bidirectional=True, dropout=self.dropout)\n",
        "        self.active_body = True\n",
        "\n",
        "        self.dp2 = nn.Dropout(self.dropout)\n",
        "\n",
        "        self.heads = {}\n",
        "        for i, tag in enumerate(self.tag_names):\n",
        "            lin_crf = nn.ModuleDict({'linear': nn.Linear(self.hidden_size*2, self.num_labels),\n",
        "                                     'crf': CRF(num_tags=self.num_labels, batch_first=True)})\n",
        "            self.heads[tag] = lin_crf\n",
        "\n",
        "        self.heads = nn.ModuleDict(self.heads)\n",
        "        self.active_heads = {head: True for head in self.heads.keys()}\n",
        "\n",
        "    def get_model_pars_dict(self):\n",
        "        \"\"\"\n",
        "        Returns dict with described model's parameters.\n",
        "        \n",
        "        \"\"\"\n",
        "        pars = {}\n",
        "        pars['hidden_size'] = self.hidden_size\n",
        "        pars['num_labels'] = self.num_labels\n",
        "        pars['tag_names'] = self.tag_names\n",
        "        pars['elmo_layers'] = self.elmo_layers\n",
        "        pars['bert_layers'] = self.bert_layers\n",
        "        pars['concat_bert'] = int(self.concat_bert)\n",
        "        pars['bilstm_layers'] = self.bilstm_layers\n",
        "        pars['dropout'] = self.dropout\n",
        "\n",
        "        return pars\n",
        "\n",
        "    def add_head(self, tag_name):\n",
        "        \"\"\"\n",
        "        Adds new head to the model\n",
        "\n",
        "        \"\"\"\n",
        "        self.tag_names.append(tag_name)\n",
        "        self.num_heads += 1\n",
        "        lin_crf = nn.ModuleDict({'linear': nn.Linear(self.hidden_size*2, self.num_labels),\n",
        "                                     'crf': CRF(num_tags=self.num_labels, batch_first=True)})\n",
        "        self.heads.update({tag_name: lin_crf})\n",
        "        self.active_heads[tag_name] = True\n",
        "\n",
        "\n",
        "    def shared_forward(self, bert_ids, elmo_ids, attention_mask):\n",
        "        \"\"\"\n",
        "        Forward propogate of model shared layers.\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        bert_ids:\n",
        "        elmo_ids:\n",
        "        attention_mask:\n",
        "        \n",
        "        Returns\n",
        "        -------\n",
        "        Bilstm logits with shape (seq_len, batch, 2*self.hidden_size)\n",
        "        \n",
        "        \"\"\"\n",
        "\n",
        "        mask = attention_mask.byte()\n",
        "        bert_hiddens = self.bert(bert_ids, attention_mask=mask)[1]\n",
        "        elmo_hiddens = self.elmo(elmo_ids)\n",
        "\n",
        "        if self.concat_bert:\n",
        "            bert_embedding = torch.cat(bert_hiddens[-self.bert_layers:], dim=2)\n",
        "        else:\n",
        "            emb_sum = 0\n",
        "            for h in bert_hiddens[-self.bert_layers:]:\n",
        "                emb_sum += h\n",
        "            bert_embedding = emb_sum\n",
        "\n",
        "        elmo_bert_embeddings = torch.clone(bert_embedding)\n",
        "        for el_hi in elmo_hiddens['elmo_representations']:\n",
        "            elmo_bert_embeddings = torch.cat((elmo_bert_embeddings, el_hi), dim=-1)\n",
        "\n",
        "        linear1_output = nn.functional.relu(self.linear1(elmo_bert_embeddings))\n",
        "        linear1_output = self.dp1(linear1_output)\n",
        "\n",
        "        bilstm_output, (h_n, c_n) = self.bilstm(linear1_output)\n",
        "        bilstm_output = self.dp2(bilstm_output)\n",
        "\n",
        "        return bilstm_output\n",
        "    \n",
        "    def get_one_head_loss(self, bilstm_logits, head_labels, attention_mask, head_tag):\n",
        "        \"\"\"\n",
        "        Returns negative log-likelihood for one head.\n",
        "        You should run it after shared forward.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        bilstm_logits:\n",
        "        head_labels:\n",
        "        attention_mask:\n",
        "        head_tag: str\n",
        "          Key of self.heads dictionary.\n",
        "        \n",
        "        Returns\n",
        "        -------\n",
        "        Loss\n",
        "\n",
        "        \"\"\"\n",
        "        lin_out = nn.functional.relu(self.heads[head_tag]['linear'](bilstm_logits))\n",
        "        loss = -1*self.heads[head_tag]['crf'].forward(lin_out, head_labels, mask=attention_mask.byte())\n",
        "        return loss\n",
        "    \n",
        "    def get_one_head_seq(self, bilstm_logits, attention_mask, head_tag):\n",
        "        \"\"\"\n",
        "        Returns the most likely sequence of labels for the given head.\n",
        "        You should run it after shared forward.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        bilstm_logits:\n",
        "        attention_mask:\n",
        "        head_tag: str\n",
        "          Key of self.heads dictionary.\n",
        "        \n",
        "        Returns\n",
        "        -------\n",
        "        List\n",
        "        \"\"\"\n",
        "      \n",
        "        lin_out = nn.functional.relu(self.heads[head_tag]['linear'](bilstm_logits))\n",
        "        seq = self.heads[head_tag]['crf'].decode(lin_out, mask=attention_mask.byte())\n",
        "        return seq\n",
        "    \n",
        "    def forward(self, bert_ids, elmo_ids, head_labels, attention_mask):\n",
        "        \"\"\"\n",
        "        Forward model pass.\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        bert_ids:\n",
        "        elmo_ids:\n",
        "        head_labels:\n",
        "        attention_mask:\n",
        "        \n",
        "        Returns\n",
        "        -------\n",
        "        Total loss for all heads.\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        mask = attention_mask.byte()\n",
        "        bilstm_logits = self.shared_forward(bert_ids, elmo_ids, mask)\n",
        "        head_loss = 0\n",
        "\n",
        "        for i, tag in enumerate(self.heads.keys()):\n",
        "          # if head is not active - we don't calculate loss from it\n",
        "          #if not self.active_heads[tag]:\n",
        "          #    continue\n",
        "          _one_head_labels = head_labels[:,i,:] if len(self.heads.keys()) > 1 else head_labels\n",
        "          head_loss += self.get_one_head_loss(bilstm_logits, _one_head_labels, mask, tag)\n",
        "        return head_loss\n",
        "    \n",
        "    def freeze_head(self, head_tag):\n",
        "        \"\"\"\n",
        "        Freezes model's head parameters.\n",
        "\n",
        "        \"\"\"\n",
        "        if head_tag not in self.heads.keys():\n",
        "            raise ValueError(f\"Unknown head tag. Please, give one of {self.heads.keys()}\")\n",
        "        \n",
        "        for parameter in self.heads[head_tag].parameters():\n",
        "            parameter.requires_grad = False\n",
        "        \n",
        "        self.active_heads[head_tag] = False\n",
        "    \n",
        "    def unfreeze_head(self, head_tag):\n",
        "        \"\"\"\n",
        "        Unfreezes model's head parameters.\n",
        "\n",
        "        \"\"\"\n",
        "        if head_tag not in self.heads.keys():\n",
        "            raise ValueError(f\"Unknown head tag. Please, give one of {self.heads.keys()}\")\n",
        "        \n",
        "        for parameter in self.heads[head_tag].parameters():\n",
        "            parameter.requires_grad = True\n",
        "        \n",
        "        self.active_heads[head_tag] = True\n",
        "      \n",
        "    def freeze_body(self):\n",
        "        \"\"\"\n",
        "        Freezes model's body parameters.\n",
        "\n",
        "        \"\"\"\n",
        "        freeze_bert_layers(self.bert, num_of_trainable=0)\n",
        "\n",
        "        for parameter in self.linear1.parameters():\n",
        "            parameter.requires_grad = False\n",
        "        for parameter in self.bilstm.parameters():\n",
        "            parameter.requires_grad = False\n",
        "        \n",
        "        self.active_body = False\n",
        "    \n",
        "    def unfreeze_body(self):\n",
        "        \"\"\"\n",
        "        Freezes model's body parameters.\n",
        "\n",
        "        \"\"\"\n",
        "        unfreeze_bert_layers(self.bert, num_of_trainable=self.num_of_trainable_bert_layers)\n",
        "\n",
        "        for parameter in self.linear1.parameters():\n",
        "            parameter.requires_grad = True\n",
        "        for parameter in self.bilstm.parameters():\n",
        "            parameter.requires_grad = True\n",
        "        \n",
        "        self.active_body = True\n",
        "    \n",
        "    def init_weights(self):\n",
        "        \"\"\"\n",
        "        Initializes models trainable weights (in bilstm and linear layers) \n",
        "        according to Xavier uniform distribution.\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        for name, param in model.named_parameters():\n",
        "            if ('linear' in name or 'bilstm' in name) and \\\n",
        "            ('weight' in name) and \\\n",
        "            ('bert' not in name and 'elmo' not in name) and \\\n",
        "            param.requires_grad:\n",
        "                torch.nn.init.xavier_uniform_(param)\n",
        "    "
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRrAN94jZ3aO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88ca8319-3283-40c1-9053-3cb998bb33ae"
      },
      "source": [
        "model = BEbiC(tag_names=TAG_NAMES, hidden_size=512, bert_layers=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9E6afKGZGZT"
      },
      "source": [
        "N_EPOCHS = 10\n",
        "total_steps = len(train_dataloader) *  N_EPOCHS"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPu6JHCJ9CIr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0dc2cd40-c80e-45ef-bcb6-bb9b98cb62d6"
      },
      "source": [
        "model.tag_names"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ORG', 'LOC', 'PER', 'MISC']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezSoQeCuPGAL"
      },
      "source": [
        "optimizer = AdamW(params=model.parameters(),lr=5e-4)\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=total_steps\n",
        ")\n",
        "\n",
        "if device.type != 'cpu':\n",
        "    model.to(device)\n",
        "\n",
        "loss_value, head_results = mu.train(model, train_dataloader, optimizer, device, conll, scheduler, n_epoch=N_EPOCHS,\n",
        "                                valid_dataloader=valid_dataloader, path_to_save=PATH_TO_CHECKPOINT+'bebic_with_dp_4_tags.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtNisogew8-P"
      },
      "source": [
        "mu.eval_model(model, valid_dataloader, device, conll)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5H727E05BTw"
      },
      "source": [
        "### Loading pretrained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0pP0yRmB6_L-"
      },
      "source": [
        "from models import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "laN65dnu63he"
      },
      "source": [
        "bert_tokenizer, model, opt_state, model_pars = mu.load_checkpoint(PATH_TO_CHECKPOINT+'BEbic_9_state_dict.pth',\n",
        "                                                                  PATH_TO_CHECKPOINT+'BEbic_9_tokenizer.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4-ilZod9opg",
        "outputId": "acbaa12c-df18-4bde-ca4d-fd711715bc21"
      },
      "source": [
        "model.heads"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ModuleDict(\n",
              "  (ORG): ModuleDict(\n",
              "    (linear): Linear(in_features=1024, out_features=4, bias=True)\n",
              "    (crf): CRF(num_tags=4)\n",
              "  )\n",
              "  (LOC): ModuleDict(\n",
              "    (linear): Linear(in_features=1024, out_features=4, bias=True)\n",
              "    (crf): CRF(num_tags=4)\n",
              "  )\n",
              "  (PER): ModuleDict(\n",
              "    (linear): Linear(in_features=1024, out_features=4, bias=True)\n",
              "    (crf): CRF(num_tags=4)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypJGtiItZUTu",
        "outputId": "db661fa5-983e-421d-f743-9695660f16e0"
      },
      "source": [
        "model_pars"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'bert_layers': 2,\n",
              " 'bilstm_layers': 1,\n",
              " 'concat_bert': 1,\n",
              " 'elmo_layers': 2,\n",
              " 'hidden_size': 512,\n",
              " 'num_labels': 4,\n",
              " 'tag_names': ['ORG', 'LOC', 'PER']}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_nKjJ-dEWfx"
      },
      "source": [
        "optimizer = AdamW(params=model.parameters(),lr=3e-4)\n",
        "optimizer.load_state_dict(opt_state)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8QEc1Bs8AiR"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_gpu = torch.cuda.device_count()\n",
        "\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0M4ByPSW88Mr"
      },
      "source": [
        "valid_dataset, valid_sampler, valid_dataloader = dalo.create_dataloader(conll, bert_tokenizer, \n",
        "                                                                        model_pars['tag_names'], \n",
        "                                                                        'valid', desired_pad=173)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQe_CGEz9DLX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f74d761-e746-4a35-cc85-56d4356f9653"
      },
      "source": [
        "head_result, mean_loss, mean_acc, mean_f1 = mu.eval_model(model, valid_dataloader, device, conll)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py:435: UserWarning: Setting attributes on ParameterList is not supported.\n",
            "  warnings.warn(\"Setting attributes on ParameterList is not supported.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OMwI3yEHDm1Q",
        "outputId": "62c4e7c1-d665-4bee-d059-276f609b2893"
      },
      "source": [
        "head_result"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'LOC': {'acc': 0.9913228024930153, 'f1': 0.9035911602209944},\n",
              " 'ORG': {'acc': 0.9772458628841607, 'f1': 0.634631886047709},\n",
              " 'PER': {'acc': 0.9769100580270793, 'f1': 0.3787528868360277}}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKF7rRyJ9ooK"
      },
      "source": [
        "#### Continue to train pretrained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDIeShD--TQs"
      },
      "source": [
        "TAG_NAMES = ['ORG', 'LOC', 'PER']\n",
        "NUM_OF_HEADS = len(TAG_NAMES)\n",
        "\n",
        "# in the second argument we pass list of tag names for every head of the model\n",
        "train_dataset, train_sampler, train_dataloader = dalo.create_dataloader(conll, bert_tokenizer, TAG_NAMES)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_dgr1559Fpy"
      },
      "source": [
        "N_EPOCHS = 5\n",
        "total_steps = len(train_dataloader) *  N_EPOCHS"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wORAtulk9-ue"
      },
      "source": [
        "optimizer = AdamW(params=model.parameters(),lr=1e-4)\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=total_steps\n",
        ")\n",
        "\n",
        "if device.type != 'cpu':\n",
        "    model.to(device)\n",
        "\n",
        "loss_value, head_results = mu.train(model, train_dataloader, optimizer, device, conll, scheduler, n_epoch=N_EPOCHS,\n",
        "                                valid_dataloader=valid_dataloader, path_to_save=PATH_TO_CHECKPOINT)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKFEtgArImqL"
      },
      "source": [
        "### Select params with grid search"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-9UdgeFU6yJ"
      },
      "source": [
        "Let's try to select the best params for our model 'at the start' (when we have not all tags)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rY5NRRKxRcPX"
      },
      "source": [
        "TAG_NAMES = ['ORG', 'LOC', 'PER']\n",
        "NUM_OF_HEADS = len(TAG_NAMES)\n",
        "\n",
        "# in the second argument we pass list of tag names for every head of the model\n",
        "train_dataset, train_sampler, train_dataloader = dalo.create_dataloader(conll, bert_tokenizer, TAG_NAMES, indexes=np.arange(1000))\n",
        "\n",
        "\n",
        "valid_dataset, valid_sampler, valid_dataloader = dalo.create_dataloader(conll, bert_tokenizer, TAG_NAMES,\n",
        "                                                                        'valid', desired_pad=train_dataset[0][0].shape[0],\n",
        "                                                                        indexes=np.arange(250))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZdS_PxMVlnS"
      },
      "source": [
        "N_EPOCHS = 15\n",
        "total_steps = len(train_dataloader) *  N_EPOCHS"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRqDsGAFIhSz"
      },
      "source": [
        "param_grid = {\n",
        "    'hidden_size': [512],\n",
        "    'lr': [3e-4, 5e-4, 1e-3],\n",
        "    'bert_layers': [2],\n",
        "    'bilstm_layers': [1, 2],\n",
        "    'dropout': [0, 0.25, 0.5],\n",
        "    'max_grad_norm': [None, 228]\n",
        "}\n",
        "\n",
        "\n",
        "grid = ParameterGrid(param_grid)\n",
        "\n",
        "results_dict = {}\n",
        "\n",
        "for m, ps in enumerate(grid):\n",
        "    print(f\"Model #{m} of {len(grid)}\")\n",
        "    results_dict[m] = {}\n",
        "    results_dict[m]['params'] = ps\n",
        "\n",
        "    model = BEbiC(tag_names=TAG_NAMES,\n",
        "                  hidden_size=ps['hidden_size'], bert_layers=ps['bert_layers'],\n",
        "                  dropout=ps['dropout'])\n",
        "\n",
        "    optimizer = AdamW(params=model.parameters(),lr=ps['lr'])\n",
        "\n",
        "    scheduler = get_linear_schedule_with_warmup(\n",
        "        optimizer,\n",
        "        num_warmup_steps=0,\n",
        "        num_training_steps=total_steps\n",
        "    )\n",
        "\n",
        "    if device.type != 'cpu':\n",
        "        model.to(device)\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "    \n",
        "    loss_value, head_results = mu.train(model, train_dataloader, optimizer, device, conll, scheduler, n_epoch=N_EPOCHS,\n",
        "                                max_grad_norm=ps['max_grad_norm'],\n",
        "                                valid_dataloader=valid_dataloader, save_model=False)\n",
        "    \n",
        "\n",
        "    results_dict[m]['head_results'] = head_results\n",
        "    \n",
        "\n",
        "with open(PATH_TO_CHECKPOINT+'bebic_gridsearch_results.json', \"w\") as w:\n",
        "    json.dump(results_dict, w)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9lq0VtZ5H_C",
        "outputId": "8fd43438-f502-4d2a-c472-be89fb97757f"
      },
      "source": [
        "mean_f1s = {k: np.mean([v['head_results'][tag]['f1'][-1] for tag in v['head_results'].keys()]) for k, v in results_dict.items()}\n",
        "print(mean_f1s)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{0: 0.2679059168734685, 1: 0.39203286847293395, 2: 0.09669211195928752, 3: 0.7876130135949433, 4: 0.2900665330819922, 5: 0.3667632850241546, 6: 0.6000593071898404, 7: 0.6425540825402759, 8: 0.583669454008854, 9: 0.5754897484011977, 10: 0.3450359839307026, 11: 0.1635864564325707, 12: 0.7935277492329728, 13: 0.5383463409116617, 14: 0.6157668582823776, 15: 0.8107453740345906, 16: 0.3359081779329673, 17: 0.828276269248082, 18: 0.3207379775496432, 19: 0.279613254899059, 20: 0.0, 21: 0.4092689278410004, 22: 0.1368759374330405, 23: 0.21609195402298853, 24: 0.2979867202967546, 25: 0.6543898994403518, 26: 0.8237526576548474, 27: 0.3745669656698656, 28: 0.3605909827210749, 29: 0.6484876889086819, 30: 0.7749038774845225, 31: 0.8242677147839608, 32: 0.77657496109267, 33: 0.5574397985857636, 34: 0.3175805675805676, 35: 0.3956337496949393}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OOBkkKiX5xJn",
        "outputId": "459caa4f-80d9-47e5-f9b0-794060d74ede"
      },
      "source": [
        "print(f\"best results: {results_dict[np.argmax(list(mean_f1s.values()))]['params']}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "best results: {'bert_layers': 2, 'bilstm_layers': 1, 'dropout': 0.5, 'hidden_size': 512, 'lr': 0.001, 'max_grad_norm': 228}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4xZJXbgM6jsa",
        "outputId": "9887c760-6191-4c7e-b8f7-733e68f8043c"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "#print(f'The model has {count_parameters(model)} trainable parameters')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 23110236 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w7eaJWjv6Rw9"
      },
      "source": [
        "So, we have the same almost results as we had in multilabel model case."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jVKrbJRDWF2H"
      },
      "source": [
        "### Model gradients analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "At23y5BZolMq"
      },
      "source": [
        "Let's take trained model to inspect its gradients norms. We need trained model because gradients of raw parameters are too huge."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pfg99hNKbR7a",
        "outputId": "93c19700-20ee-4e53-8d4b-3a90363b65b3"
      },
      "source": [
        "checkpoint = torch.load(PATH_TO_CHECKPOINT+'bebic_with_dp_4_tags.pth')\n",
        "model = checkpoint['model']\n",
        "model.load_state_dict(checkpoint['state_dict'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdY1ylCcb5n4"
      },
      "source": [
        "def get_grad_norm(model, many_heads=False):\n",
        "    total_norm = 0\n",
        "    if many_heads:\n",
        "        body_norm = 0\n",
        "        heads_norms = {head: 0 for head in model.heads.keys()}\n",
        "    \n",
        "    for name, p in model.named_parameters():\n",
        "        if p.requires_grad:\n",
        "            param_norm = p.grad.data.norm(2)\n",
        "            total_norm += param_norm.item() ** 2\n",
        "            if many_heads:\n",
        "                if 'heads' not in name:\n",
        "                    body_norm += param_norm\n",
        "                else:\n",
        "                    for k in heads_norms.keys():\n",
        "                        if k in name:\n",
        "                            heads_norms[k] += param_norm\n",
        "    total_norm = total_norm ** (1. / 2)\n",
        "    if many_heads:\n",
        "        return total_norm, body_norm, heads_norms\n",
        "    return total_norm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIK3UabieFiL"
      },
      "source": [
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04_ZB1yOeNU5",
        "outputId": "650e35f3-51f2-42b2-e687-dfc5155ddd41"
      },
      "source": [
        "model.train()\n",
        "total_grad_norms = []\n",
        "body_grad_norms = []\n",
        "heads_grad_norms = {head: [] for head in model.heads.keys()}\n",
        "\n",
        "for batch in train_dataloader:\n",
        "    if device.type != 'cpu':\n",
        "          batch = tuple(t.to(device) for t in batch)\n",
        "    b_bert_ids, b_elmo_ids, b_labels, b_input_mask = batch\n",
        "    model.zero_grad()\n",
        "\n",
        "    loss = model(b_bert_ids, b_elmo_ids, b_labels, b_input_mask.byte())\n",
        "    loss.backward()\n",
        "\n",
        "    total_norm, body_norm, heads_norms = get_grad_norm(model, many_heads=True)\n",
        "    total_grad_norms.append(total_norm)\n",
        "    body_grad_norms.append(body_norm.item())\n",
        "    for head in heads_grad_norms.keys():\n",
        "        heads_grad_norms[head].append(heads_norms[head].item())\n",
        "    \n",
        "    del batch, loss, b_bert_ids, b_elmo_ids, b_labels, b_input_mask\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py:435: UserWarning: Setting attributes on ParameterList is not supported.\n",
            "  warnings.warn(\"Setting attributes on ParameterList is not supported.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdyNCH_0lkSH"
      },
      "source": [
        "body_grad_norms = [x.item() for x in body_grad_norms]\n",
        "for head in heads_grad_norms.keys():\n",
        "    heads_grad_norms[head] = [x.item() for x in heads_grad_norms[head]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 499
        },
        "id": "nxVnCXLEfZvE",
        "outputId": "1765845b-e306-45e2-f76b-fc3b81de927e"
      },
      "source": [
        "fig, axes = plt.subplots(2, 3, figsize=(12, 8))\n",
        "_ = axes[0][0].hist(total_grad_norms)\n",
        "axes[0][0].set_title('total norm')\n",
        "_ = axes[0][1].hist(body_grad_norms)\n",
        "axes[0][1].set_title('body norms')\n",
        "for i, head in enumerate(heads_grad_norms.keys()):\n",
        "    j = i+2\n",
        "    _ = axes[j//3][j%3].hist(heads_grad_norms[head])\n",
        "    axes[j//3][j%3].set_title(f'{head} norms')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x576 with 6 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7GbxezDe1KZ"
      },
      "source": [
        "Body's norms are mainly greater than total ones and it's ok because gradients may take negative values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FcO05KnMnJWA",
        "outputId": "816b081a-cc95-4f86-aa2e-ca5f661e1c58"
      },
      "source": [
        "print(f'Mean total gradient norm: {np.mean(total_grad_norms)}')\n",
        "print(f'Mean body gradient norm: {np.mean(body_grad_norms)}')\n",
        "for head in heads_grad_norms.keys():\n",
        "    print(f'Mean {head} gradient norm: {np.mean(heads_grad_norms[head])}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean total gradient norm: 479.1625377599561\n",
            "Mean body gradient norm: 1493.7607202703302\n",
            "Mean ORG gradient norm: 100.52260801141912\n",
            "Mean LOC gradient norm: 61.176813992587\n",
            "Mean PER gradient norm: 113.64938697814941\n",
            "Mean MISC gradient norm: 69.2078110261397\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPserxYOoFHP"
      },
      "source": [
        "So, let's restrict the overall model grandients size to the norm of 500."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6OWQ2XsVzwK"
      },
      "source": [
        "### K-fold for multihead model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TN1Qe5CAXcBR"
      },
      "source": [
        "N_FOLDS = 5\n",
        "RANDOM_SEED = 42\n",
        "N_EPOCHS = 10\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "TAG_NAMES = ['ORG', 'LOC', 'PER']\n",
        "NUM_OF_HEADS = len(TAG_NAMES)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IezQc2CaYnDY"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_gpu = torch.cuda.device_count()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CpH5sly8V-KC"
      },
      "source": [
        "kf = KFold(n_splits=N_FOLDS, shuffle=True, random_state=RANDOM_SEED)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WK9Cl7phXVp4"
      },
      "source": [
        "all_loss_values = []\n",
        "all_head_results = []\n",
        "\n",
        "for i, (train_index, valid_index) in enumerate(kf.split(train_dataset)):\n",
        "    print(f\"FOLD #{i}\\n\")\n",
        "    # train_dataset based on conll and defined above specially for multiple-head model input\n",
        "    train_fold = torch.utils.data.Subset(train_dataset, train_index)\n",
        "    valid_fold = torch.utils.data.Subset(train_dataset, valid_index)\n",
        "    \n",
        "    _train_dataloader = torch.utils.data.DataLoader(train_fold, batch_size=BATCH_SIZE)\n",
        "    _valid_dataloader = torch.utils.data.DataLoader(valid_fold, batch_size=BATCH_SIZE)\n",
        "\n",
        "    total_steps = len(train_fold) *  N_EPOCHS\n",
        "\n",
        "    model = BEbiC(tag_names=TAG_NAMES, hidden_size=512, bert_layers=2, dropout=0.5)\n",
        "    model.to(device)\n",
        "\n",
        "    optimizer = AdamW(params=model.parameters(),lr=1e-3)\n",
        "\n",
        "    scheduler = get_linear_schedule_with_warmup(\n",
        "        optimizer,\n",
        "        num_warmup_steps=0,\n",
        "        num_training_steps=total_steps\n",
        "    )\n",
        "\n",
        "    loss_value, head_results = mu.train(model, _train_dataloader, optimizer, device, conll, scheduler, n_epoch=N_EPOCHS,\n",
        "                                max_grad_norm=500, valid_dataloader=_valid_dataloader, save_model=False)\n",
        "    \n",
        "    print(f\"Head_results:\\n{head_results}\")\n",
        "    all_loss_values.append(loss_value)\n",
        "    all_head_results.append(head_results)\n",
        "\n",
        "    # cleaning\n",
        "    del model\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    with open(PATH_TO_CHECKPOINT+f\"New_results/bebic_5folds/Bebic-5fold_head_results_fold{i}.json\", \"w\") as f:\n",
        "        json.dump(head_results, f)\n",
        "\n",
        "    with open(PATH_TO_CHECKPOINT+f\"New_results/bebic_5folds/Bebic-5fold_loss_values_fold{i}.json\", \"w\") as f:\n",
        "        json.dump(loss_value, f)\n",
        "\n",
        "\n",
        "#with open(PATH_TO_CHECKPOINT+\"BEbic-5fold_head_results.json\", \"w\") as f:\n",
        "#    json.dump(all_head_results, f)\n",
        "\n",
        "#with open(PATH_TO_CHECKPOINT+\"BEbic-5fold_loss_values.json\", \"w\") as f:\n",
        "#    json.dump(all_loss_values, f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qdz9TOt4yhYf"
      },
      "source": [
        "## Train model with 3 heads and best params"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acRXGVPDzbGX"
      },
      "source": [
        "TAG_NAMES = ['ORG', 'LOC', 'PER']\n",
        "NUM_OF_HEADS = len(TAG_NAMES)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1TEpQq5UzfJu"
      },
      "source": [
        "train_dataset, train_sampler, train_dataloader = dalo.create_dataloader(conll, bert_tokenizer, TAG_NAMES, batch_size=64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4-veyuyziVM"
      },
      "source": [
        "valid_dataset, valid_sampler, valid_dataloader = dalo.create_dataloader(conll, bert_tokenizer, TAG_NAMES,\n",
        "                                                                        'valid', desired_pad=train_dataset[0][0].shape[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GeBsrqhrypjZ",
        "outputId": "d7922ba9-3309-40e6-ba8e-4a2395287cb3"
      },
      "source": [
        "model = BEbiC(tag_names=TAG_NAMES, hidden_size=512, bert_layers=2, dropout=0.5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:61: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSzkfYxszQnh"
      },
      "source": [
        "N_EPOCHS = 12\n",
        "total_steps = len(train_dataloader) *  N_EPOCHS"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KI_rbWfezRqt"
      },
      "source": [
        "optimizer = AdamW(params=model.parameters(),lr=1e-3)\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=total_steps\n",
        ")\n",
        "\n",
        "if device.type != 'cpu':\n",
        "    model.to(device)\n",
        "\n",
        "loss_value, head_results = mu.train(model, train_dataloader, optimizer, device, conll, scheduler, n_epoch=N_EPOCHS, max_grad_norm=500,\n",
        "                                valid_dataloader=valid_dataloader, path_to_save=PATH_TO_NEW_CHECKPOINT+'best_bebic_3_tags.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KGXhMCuR02Q9",
        "outputId": "d088cef4-551f-42ee-d409-b30d1729bc85"
      },
      "source": [
        "mu.eval_model(model, valid_dataloader, device, conll)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py:435: UserWarning: Setting attributes on ParameterList is not supported.\n",
            "  warnings.warn(\"Setting attributes on ParameterList is not supported.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'LOC': {'acc': 0.9939689447668171, 'f1': 0.9363243695137244},\n",
              "  'ORG': {'acc': 0.9802681065978939, 'f1': 0.6515723270440251},\n",
              "  'PER': {'acc': 0.9961718246292715, 'f1': 0.9532004830917874}},\n",
              " 219.55645321798156,\n",
              " 0.9901362919979941,\n",
              " 0.8470323932165122)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4m182danZnwl"
      },
      "source": [
        "We have very good quality on all labels."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNprUw27Ohim"
      },
      "source": [
        "## The fourth head trained on old data with new tag"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCDi3_UWaQ66",
        "outputId": "69e3d6eb-3ed3-45cc-afb5-d5f5a56b7780"
      },
      "source": [
        "checkpoint = torch.load(PATH_TO_NEW_CHECKPOINT+'best_bebic_3_tags.pth')\n",
        "model = checkpoint['model']\n",
        "model.load_state_dict(checkpoint['state_dict'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z2vcIxGwOzdX",
        "outputId": "3199fd8d-4ebf-4d78-f5f3-a4ae54e15a8b"
      },
      "source": [
        "model.heads"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ModuleDict(\n",
              "  (ORG): ModuleDict(\n",
              "    (linear): Linear(in_features=1024, out_features=4, bias=True)\n",
              "    (crf): CRF(num_tags=4)\n",
              "  )\n",
              "  (LOC): ModuleDict(\n",
              "    (linear): Linear(in_features=1024, out_features=4, bias=True)\n",
              "    (crf): CRF(num_tags=4)\n",
              "  )\n",
              "  (PER): ModuleDict(\n",
              "    (linear): Linear(in_features=1024, out_features=4, bias=True)\n",
              "    (crf): CRF(num_tags=4)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDbigW2tPe_b"
      },
      "source": [
        "model.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfOmk8AgPvZ5"
      },
      "source": [
        "model.add_head('MISC')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEIQgvobQSkK"
      },
      "source": [
        "for head in ['LOC', 'ORG', 'PER']:\n",
        "    model.freeze_head(head)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "INOzDJpIQvy_",
        "outputId": "041bf618-be94-4618-f2fa-0fca0164b488"
      },
      "source": [
        "model.active_heads"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'LOC': False, 'MISC': True, 'ORG': False, 'PER': False}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mVlblf7kR0Rv"
      },
      "source": [
        "Now let's try to keep 85% of examples with one or more tags MISC and 15% without it. So, we would simulate the real case of receiving new data with new tag."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XfNuDfo-wDL"
      },
      "source": [
        "TAG_NAMES = ['ORG', 'LOC', 'PER', 'MISC']#list(model.heads.keys())\n",
        "NUM_OF_HEADS = len(TAG_NAMES)\n",
        "BATCH_SIZE=32\n",
        "RANDOM_SEED=42\n",
        "N_EPOCHS = 15"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yGpD5GhEmcJC",
        "outputId": "7b4a340f-f175-4da4-c52b-1b48a195b502"
      },
      "source": [
        "TAG_NAMES"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ORG', 'LOC', 'PER', 'MISC']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGtuTb_USrcA"
      },
      "source": [
        "indexes_with_misc = [i for i, s in enumerate(conll.labels['train']) if 'B-MISC' in s]\n",
        "indexes_without_misc = [i for i in range(len(conll.labels['train'])) if i not in indexes_with_misc]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zlhg585w-Z7t",
        "outputId": "185f9e4f-f772-41d7-e690-932ca4fd0e8b"
      },
      "source": [
        "print(f\"# sentences with MISC: {len(indexes_with_misc)}\")\n",
        "print(f\"# sentences without MISC: {len(indexes_without_misc)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# sentences with MISC: 2698\n",
            "# sentences without MISC: 11343\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0rTsWs7b-DP"
      },
      "source": [
        "Also, let's consider multiple \"random\" cases."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWpGmrO7dFd4"
      },
      "source": [
        "results_dict = {}\n",
        "for freezed_epochs in range(3,4):\n",
        "  print(f\"FREEZED_EPOCHS:{freezed_epochs}\")\n",
        "  seed_results_dict = {}\n",
        "  for seed in [1, 12, 123, 1234, 12345]:\n",
        "    print(f\"SEED:{seed}\")\n",
        "    np.random.seed(seed)\n",
        "    seed_results_dict[seed] = {}\n",
        "\n",
        "    for n_train_samples in range(100, 351, 50):\n",
        "        print(f\"NUMBER OF TRAIN SAMPLES: {n_train_samples}\")\n",
        "        \n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "        checkpoint = torch.load(PATH_TO_NEW_CHECKPOINT+'best_bebic_3_tags.pth')\n",
        "        model = checkpoint['model']\n",
        "        model.load_state_dict(checkpoint['state_dict'])\n",
        "        model.train()\n",
        "        model.add_head('MISC')\n",
        "\n",
        "        for head in ['LOC', 'ORG', 'PER']:\n",
        "            model.freeze_head(head)\n",
        "        \n",
        "        # I just remember that max sequence length in train is 173\n",
        "        all_valid_dataset, all_valid_sampler, all_valid_dataloader = dalo.create_dataloader(conll, bert_tokenizer, TAG_NAMES,\n",
        "                                                                            'valid', desired_pad=173,\n",
        "                                                                            batch_size=128)\n",
        "\n",
        "        # train indexes\n",
        "        n_train_with_misc = int(n_train_samples*0.85)\n",
        "        train_misk_indexes = np.random.choice(indexes_with_misc, n_train_with_misc)\n",
        "        train_nmisk_indexes = np.random.choice(indexes_without_misc, n_train_samples-n_train_with_misc)\n",
        "        train_indexes = np.append(train_misk_indexes, train_nmisk_indexes)\n",
        "\n",
        "        # let's create small validation data with the same proportion of MISC samples from the train data\n",
        "        n_valid_samples = int(n_train_samples/4)\n",
        "        _idxes_with_misc = [i for i in indexes_with_misc if i not in train_misk_indexes]\n",
        "        _idxes_without_misc = [i for i in indexes_without_misc if i not in train_nmisk_indexes]\n",
        "\n",
        "        # validation indexes\n",
        "        n_valid_with_misc = int(n_valid_samples*0.85)\n",
        "        valid_misk_indexes = np.random.choice(_idxes_with_misc, n_valid_with_misc)\n",
        "        valid_nmisk_indexes = np.random.choice(_idxes_without_misc, n_valid_samples-n_valid_with_misc)\n",
        "        valid_indexes = np.append(valid_misk_indexes, valid_nmisk_indexes)\n",
        "\n",
        "        train_dataset, train_sampler, train_dataloader = dalo.create_dataloader(conll, bert_tokenizer, TAG_NAMES, \n",
        "                                                                      desired_pad=173, batch_size=BATCH_SIZE,\n",
        "                                                                      indexes=train_indexes)\n",
        "        \n",
        "        valid_dataset, valid_sampler, valid_dataloader = dalo.create_dataloader(conll, bert_tokenizer, TAG_NAMES,\n",
        "                                                                            desired_pad=173, batch_size=BATCH_SIZE,\n",
        "                                                                            indexes=valid_indexes)\n",
        "        \n",
        "        total_steps = len(train_dataloader) *  N_EPOCHS\n",
        "\n",
        "        optimizer = AdamW(params=model.parameters(),lr=1e-3)\n",
        "\n",
        "        scheduler = get_linear_schedule_with_warmup(\n",
        "            optimizer,\n",
        "            num_warmup_steps=0,\n",
        "            num_training_steps=total_steps\n",
        "        )\n",
        "\n",
        "        if device.type != 'cpu':\n",
        "            model.to(device)\n",
        "\n",
        "        model.freeze_body()\n",
        "\n",
        "        loss_value, head_results = mu.train(model, train_dataloader, optimizer, \n",
        "                                            device, conll, scheduler, \n",
        "                                            n_epoch=freezed_epochs, \n",
        "                                            max_grad_norm=500,\n",
        "                                            valid_dataloader=valid_dataloader,\n",
        "                                            save_model=False)\n",
        "        \n",
        "        seed_results_dict[seed][n_train_samples] = {}\n",
        "        seed_results_dict[seed][n_train_samples]['freezed_loss_values'] = loss_value\n",
        "        seed_results_dict[seed][n_train_samples]['freezed_head_results'] = head_results\n",
        "        \n",
        "        model.unfreeze_body()\n",
        "\n",
        "        loss_value, head_results = mu.train(model, train_dataloader, optimizer, \n",
        "                                            device, conll, scheduler, \n",
        "                                            n_epoch=N_EPOCHS-freezed_epochs,\n",
        "                                            max_grad_norm=500,\n",
        "                                            valid_dataloader=valid_dataloader,\n",
        "                                            save_model=False)\n",
        "\n",
        "        seed_results_dict[seed][n_train_samples]['loss_values'] = loss_value\n",
        "        seed_results_dict[seed][n_train_samples]['head_results'] = head_results\n",
        "\n",
        "        # eval model on the all validation data\n",
        "        head_results_all, mean_loss, mean_acc, mean_f1 = mu.eval_model(model, all_valid_dataloader, device, conll)\n",
        "        print(f\"mean validation loss: {mean_loss}\")\n",
        "        print(f\"mean validation accuracy: {mean_acc}\")\n",
        "        print(f\"mean validation f1-score: {mean_f1}\")\n",
        "\n",
        "        seed_results_dict[seed][n_train_samples][\"head_results_all\"] = head_results_all\n",
        "        seed_results_dict[seed][n_train_samples][\"mean_loss\"] = mean_loss\n",
        "        seed_results_dict[seed][n_train_samples][\"mean_acc\"] = mean_acc\n",
        "        seed_results_dict[seed][n_train_samples][\"mean_f1\"] = mean_f1\n",
        "  \n",
        "  results_dict[f\"{freezed_epochs}_freezed_epochs\"] = seed_results_dict\n",
        "\n",
        "  with open(PATH_TO_NEW_CHECKPOINT+f\"4th_head/results_dict_freezed{freezed_epochs}.json\", \"w\") as f:\n",
        "      json.dump(seed_results_dict, f)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBRyBAiSxZyF"
      },
      "source": [
        "## The 4th head trained on completely new data from the test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOgPqi1GznBa"
      },
      "source": [
        "TAG_NAMES = ['ORG', 'LOC', 'PER', 'MISC']#list(model.heads.keys())\n",
        "NUM_OF_HEADS = len(TAG_NAMES)\n",
        "BATCH_SIZE=32\n",
        "RANDOM_SEED=42\n",
        "N_EPOCHS = 15"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGO7YLvJz09N"
      },
      "source": [
        "Let's try to keep 85% of examples with one or more tags MISC and 15% without it. But now, let's use data from test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ek6fTN3z0IU"
      },
      "source": [
        "indexes_with_misc = [i for i, s in enumerate(conll.labels['test']) if 'B-MISC' in s]\n",
        "indexes_without_misc = [i for i in range(len(conll.labels['test'])) if i not in indexes_with_misc]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sgNbqgK-zoTW",
        "outputId": "cb58a49f-8034-43b5-f808-dd7d59487e84"
      },
      "source": [
        "print(f\"# sentences with MISC: {len(indexes_with_misc)}\")\n",
        "print(f\"# sentences without MISC: {len(indexes_without_misc)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# sentences with MISC: 563\n",
            "# sentences without MISC: 2890\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "in0Vtm1v3Ysn"
      },
      "source": [
        "Let's \"cut\" test set to divide it on 'new data for the 4th head' / 'small test set'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4cGjDmo63v5H"
      },
      "source": [
        "indexes_with_misc = indexes_with_misc[:300]\n",
        "indexes_without_misc = indexes_without_misc[:200]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99NhPXVb0oDV"
      },
      "source": [
        "results_dict = {}\n",
        "for freezed_epochs in range(0,1):\n",
        "  print(f\"FREEZED_EPOCHS:{freezed_epochs}\")\n",
        "  seed_results_dict = {}\n",
        "  for seed in [1, 12, 123, 1234, 12345]:\n",
        "    print(f\"SEED:{seed}\")\n",
        "    np.random.seed(seed)\n",
        "    seed_results_dict[seed] = {}\n",
        "\n",
        "    for n_train_samples in range(100, 351, 50):\n",
        "        print(f\"NUMBER OF TRAIN SAMPLES: {n_train_samples}\")\n",
        "        \n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "        checkpoint = torch.load(PATH_TO_NEW_CHECKPOINT+'best_bebic_3_tags.pth')\n",
        "        model = checkpoint['model']\n",
        "        model.load_state_dict(checkpoint['state_dict'])\n",
        "        model.train()\n",
        "        model.add_head('MISC')\n",
        "\n",
        "        for head in ['LOC', 'ORG', 'PER']:\n",
        "            model.freeze_head(head)\n",
        "        \n",
        "        # I just remember that max sequence length in train is 173\n",
        "        all_valid_dataset, all_valid_sampler, all_valid_dataloader = dalo.create_dataloader(conll, bert_tokenizer, TAG_NAMES,\n",
        "                                                                            'valid', desired_pad=173,\n",
        "                                                                            batch_size=128)\n",
        "\n",
        "        # train indexes\n",
        "        n_train_with_misc = int(n_train_samples*0.85)\n",
        "        train_misk_indexes = np.random.choice(indexes_with_misc, n_train_with_misc)\n",
        "        train_nmisk_indexes = np.random.choice(indexes_without_misc, n_train_samples-n_train_with_misc)\n",
        "        train_indexes = np.append(train_misk_indexes, train_nmisk_indexes)\n",
        "\n",
        "        train_dataset, train_sampler, train_dataloader = dalo.create_dataloader(conll, bert_tokenizer, TAG_NAMES, \n",
        "                                                                      'test', desired_pad=173, batch_size=BATCH_SIZE,\n",
        "                                                                      indexes=train_indexes)\n",
        "        # now we don't create small validation dataset in order to have not too small residual test set\n",
        "        # but we still would validate on all validation data\n",
        "        \n",
        "        total_steps = len(train_dataloader) *  N_EPOCHS\n",
        "\n",
        "        optimizer = AdamW(params=model.parameters(),lr=1e-3)\n",
        "\n",
        "        scheduler = get_linear_schedule_with_warmup(\n",
        "            optimizer,\n",
        "            num_warmup_steps=0,\n",
        "            num_training_steps=total_steps\n",
        "        )\n",
        "\n",
        "        if device.type != 'cpu':\n",
        "            model.to(device)\n",
        "\n",
        "        model.freeze_body()\n",
        "\n",
        "        loss_value = mu.train(model, train_dataloader, optimizer, \n",
        "                                            device, conll, scheduler, \n",
        "                                            n_epoch=freezed_epochs, \n",
        "                                            max_grad_norm=500,\n",
        "                                            save_model=False)\n",
        "        \n",
        "        seed_results_dict[seed][n_train_samples] = {}\n",
        "        seed_results_dict[seed][n_train_samples]['freezed_loss_values'] = loss_value\n",
        "        #seed_results_dict[seed][n_train_samples]['freezed_head_results'] = head_results\n",
        "        \n",
        "        model.unfreeze_body()\n",
        "\n",
        "        loss_value = mu.train(model, train_dataloader, optimizer, \n",
        "                                            device, conll, scheduler, \n",
        "                                            n_epoch=N_EPOCHS-freezed_epochs,\n",
        "                                            max_grad_norm=500,\n",
        "                                            save_model=False)\n",
        "\n",
        "        seed_results_dict[seed][n_train_samples]['loss_values'] = loss_value\n",
        "        #seed_results_dict[seed][n_train_samples]['head_results'] = head_results\n",
        "\n",
        "        # eval model on the all validation data\n",
        "        head_results_all, mean_loss, mean_acc, mean_f1 = mu.eval_model(model, all_valid_dataloader, device, conll)\n",
        "        print(f\"mean validation loss: {mean_loss}\")\n",
        "        print(f\"mean validation accuracy: {mean_acc}\")\n",
        "        print(f\"mean validation f1-score: {mean_f1}\")\n",
        "\n",
        "        seed_results_dict[seed][n_train_samples][\"head_results_all\"] = head_results_all\n",
        "        seed_results_dict[seed][n_train_samples][\"mean_loss\"] = mean_loss\n",
        "        seed_results_dict[seed][n_train_samples][\"mean_acc\"] = mean_acc\n",
        "        seed_results_dict[seed][n_train_samples][\"mean_f1\"] = mean_f1\n",
        "  \n",
        "  results_dict[f\"{freezed_epochs}_freezed_epochs\"] = seed_results_dict\n",
        "\n",
        "  with open(PATH_TO_NEW_CHECKPOINT+f\"4th_head_new_data/results_dict_freezed{freezed_epochs}.json\", \"w\") as f:\n",
        "      json.dump(seed_results_dict, f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7hJDI1cGxbEy",
        "outputId": "6595e31a-c909-4e8d-b413-a4c71af0dbce"
      },
      "source": [
        "checkpoint = torch.load(PATH_TO_NEW_CHECKPOINT+'best_bebic_3_tags_v1.pth')\n",
        "model = checkpoint['model']\n",
        "model.load_state_dict(checkpoint['state_dict'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irbMNXpW1f_A"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7D8C716YUMgT"
      },
      "source": [
        "# Train Bebic on a half of train set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "et4v1myqUpou"
      },
      "source": [
        "TAG_NAMES = ['ORG', 'LOC', 'PER']\n",
        "NUM_OF_HEADS = len(TAG_NAMES)\n",
        "PAD_LEN = 173 #I use the old value "
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KGpYowTUQfB"
      },
      "source": [
        "first_train_indexes = np.arange(int(len(conll.sentences['train'])/2))\n",
        "second_train_indexes = np.arange(len(first_train_indexes), len(conll.sentences['train']))\n",
        "\n",
        "# in the second argument we pass list of tag names for every head of the model\n",
        "train_dataset, train_sampler, train_dataloader = dalo.create_dataloader(conll, bert_tokenizer, TAG_NAMES, indexes=second_train_indexes)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQBbGbQ9WLsd"
      },
      "source": [
        "## K-fold for multihead model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Nc3dQt9V_ZC"
      },
      "source": [
        "N_FOLDS = 5\n",
        "RANDOM_SEED = 42\n",
        "N_EPOCHS = 40\n",
        "BATCH_SIZE = 128"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCbKjlxEWbDq"
      },
      "source": [
        "kf = KFold(n_splits=N_FOLDS, shuffle=True, random_state=RANDOM_SEED)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "52187f2e41b84a38921aca08a9273288",
            "533008fb1deb40a2b356123f5e115bee",
            "cb1a1daa49b84a1a8104704553ca2fca",
            "c27bdb21d5c74eb4ba893600bba3b13c",
            "0794b38fed4d46e997a6234c0150ace6",
            "f5a906bd709a40e08cb1ebeaed4b5473",
            "ad3acc3587a9497a848179aee11783d2",
            "33c130e14948460884b2fe730d805492",
            "7b9ccc39844f4a3a90e66e3592220189",
            "80104aa86a6c4b549364ba8a5dfe0c66",
            "45d9be3605ec4c29b918b6b3f7928466",
            "985776de692e44b2b72b88b18478d43b",
            "f61b11f529c741519fb9e55217c45703",
            "6a497f8fddcd4529a120c406c966c4ba",
            "4eb651b10fe44de99238edab6df466eb",
            "97ddea3da307453d9c491efe9a3e5081"
          ]
        },
        "id": "Wxo5oslfWdwU",
        "outputId": "f7f3b157-5a41-46cc-90f4-d5b0157a5b75"
      },
      "source": [
        "all_loss_values = []\n",
        "all_head_results = []\n",
        "\n",
        "for i, (train_index, valid_index) in enumerate(kf.split(train_dataset)):\n",
        "    if i < 1:\n",
        "        continue\n",
        "    print(f\"FOLD #{i}\\n\")\n",
        "    # train_dataset based on conll and defined above specially for multiple-head model input\n",
        "    train_fold = torch.utils.data.Subset(train_dataset, train_index)\n",
        "    valid_fold = torch.utils.data.Subset(train_dataset, valid_index)\n",
        "    \n",
        "    _train_dataloader = torch.utils.data.DataLoader(train_fold, batch_size=BATCH_SIZE)\n",
        "    _valid_dataloader = torch.utils.data.DataLoader(valid_fold, batch_size=BATCH_SIZE)\n",
        "\n",
        "    total_steps = len(train_fold) *  N_EPOCHS\n",
        "\n",
        "    model = BEbiC(tag_names=TAG_NAMES, hidden_size=512, bert_layers=2, \n",
        "                  num_of_trainable_bert_layers=1, dropout=0.5)\n",
        "    model.init_weights()\n",
        "    model.to(device)\n",
        "\n",
        "    optimizer = AdamW(params=model.parameters(),lr=1e-3)\n",
        "\n",
        "    scheduler = get_linear_schedule_with_warmup(\n",
        "        optimizer,\n",
        "        num_warmup_steps=0,\n",
        "        num_training_steps=total_steps\n",
        "    )\n",
        "\n",
        "    loss_value, head_results = mu.train(model, _train_dataloader, optimizer, \n",
        "                                        device, conll, scheduler, n_epoch=N_EPOCHS,\n",
        "                                        max_grad_norm=500, early_stopping_steps=10,\n",
        "                                        valid_dataloader=_valid_dataloader, save_model=False)\n",
        "    \n",
        "    print(f\"Head_results:\\n{head_results}\")\n",
        "    all_loss_values.append(loss_value)\n",
        "    all_head_results.append(head_results)\n",
        "\n",
        "    # cleaning\n",
        "    del model\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    with open(PATH_TO_NEW_CHECKPOINT+f\"bebic_5folds_half_train_second/Bebic-5fold_head_results_fold{i}.json\", \"w\") as f:\n",
        "        json.dump(head_results, f)\n",
        "\n",
        "    with open(PATH_TO_NEW_CHECKPOINT+f\"bebic_5folds_half_train_second/Bebic-5fold_loss_values_fold{i}.json\", \"w\") as f:\n",
        "        json.dump(loss_value, f)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FOLD #1\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "52187f2e41b84a38921aca08a9273288",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=570.0, style=ProgressStyle(description_â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7b9ccc39844f4a3a90e66e3592220189",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=435779157.0, style=ProgressStyle(descriâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "downloading: 100%|##########| 336/336 [00:00<00:00, 1100145.31B/s]\n",
            "downloading: 100%|##########| 112140184/112140184 [00:04<00:00, 25525126.32B/s]\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:61: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py:435: UserWarning: Setting attributes on ParameterList is not supported.\n",
            "  warnings.warn(\"Setting attributes on ParameterList is not supported.\")\n",
            "  0%|          | 0/44 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch #0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 23%|â–ˆâ–ˆâ–Ž       | 10/44 [00:33<01:55,  3.40s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "9: avg loss per batch: 1288.7032335069443\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 20/44 [01:09<01:25,  3.55s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "19: avg loss per batch: 851.9986079701206\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 30/44 [01:46<00:52,  3.77s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "29: avg loss per batch: 724.1775596881735\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 40/44 [02:23<00:14,  3.74s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "39: avg loss per batch: 635.8219009790665\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 44/44 [02:37<00:00,  3.59s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Average train loss: 588.4878914572976\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/44 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mean validation loss: 1201.514075657156\n",
            "Mean validation accuracy: 0.953509535095351\n",
            "Mean validation F1-score: 0.37671929856228736\n",
            "\n",
            "\n",
            "Epoch #1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 23%|â–ˆâ–ˆâ–Ž       | 10/44 [00:37<02:06,  3.71s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "9: avg loss per batch: 377.52630502206307\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 20/44 [01:13<01:28,  3.68s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "19: avg loss per batch: 333.4481977496231\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 30/44 [01:51<00:52,  3.73s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "29: avg loss per batch: 330.1412188650548\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 40/44 [02:28<00:15,  3.76s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "39: avg loss per batch: 313.8600925543369\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 44/44 [02:42<00:00,  3.70s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Average train loss: 295.7867186575225\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/44 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mean validation loss: 879.4072309790222\n",
            "Mean validation accuracy: 0.9764997649976499\n",
            "Mean validation F1-score: 0.6565202189323558\n",
            "\n",
            "\n",
            "Epoch #2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 23%|â–ˆâ–ˆâ–Ž       | 10/44 [00:36<02:06,  3.71s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "9: avg loss per batch: 270.05711873372394\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 20/44 [01:13<01:28,  3.70s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "19: avg loss per batch: 253.58659443102385\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 30/44 [01:51<00:51,  3.71s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "29: avg loss per batch: 253.34393450857579\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 40/44 [02:28<00:15,  3.77s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "39: avg loss per batch: 237.85626038119324\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 44/44 [02:43<00:00,  3.71s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Average train loss: 225.4258154666785\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/44 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mean validation loss: 598.501442914348\n",
            "Mean validation accuracy: 0.981029810298103\n",
            "Mean validation F1-score: 0.7257258570153016\n",
            "\n",
            "\n",
            "Epoch #3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 23%|â–ˆâ–ˆâ–Ž       | 10/44 [00:36<02:06,  3.71s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "9: avg loss per batch: 177.87436873824507\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 20/44 [01:13<01:28,  3.69s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "19: avg loss per batch: 173.34461332622328\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 30/44 [01:51<00:51,  3.71s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "29: avg loss per batch: 175.0297141239561\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 40/44 [02:28<00:15,  3.76s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "39: avg loss per batch: 168.86170933389255\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 44/44 [02:42<00:00,  3.70s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Average train loss: 160.8775626673843\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/44 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mean validation loss: 548.1484845810338\n",
            "Mean validation accuracy: 0.9829798297982979\n",
            "Mean validation F1-score: 0.7594459373191991\n",
            "\n",
            "\n",
            "Epoch #4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 23%|â–ˆâ–ˆâ–Ž       | 10/44 [00:36<02:05,  3.70s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "9: avg loss per batch: 152.22729435673466\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 20/44 [01:13<01:28,  3.70s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "19: avg loss per batch: 144.96079321074905\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 30/44 [01:51<00:51,  3.71s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "29: avg loss per batch: 151.07820620481996\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 40/44 [02:28<00:14,  3.75s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "39: avg loss per batch: 146.53420720548712\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 44/44 [02:42<00:00,  3.70s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Average train loss: 140.9443570917303\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/44 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mean validation loss: 524.6195041480255\n",
            "Mean validation accuracy: 0.9839898398983988\n",
            "Mean validation F1-score: 0.7781555667039564\n",
            "\n",
            "\n",
            "Epoch #5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 23%|â–ˆâ–ˆâ–Ž       | 10/44 [00:36<02:06,  3.71s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "9: avg loss per batch: 139.30412575050636\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 20/44 [01:13<01:28,  3.69s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "19: avg loss per batch: 132.0790003726357\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 30/44 [01:51<00:51,  3.71s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "29: avg loss per batch: 131.61908555304868\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 40/44 [02:28<00:15,  3.77s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "39: avg loss per batch: 130.7376698551015\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 44/44 [02:42<00:00,  3.70s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Average train loss: 125.20531937570284\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/44 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mean validation loss: 524.3822755337018\n",
            "Mean validation accuracy: 0.983349833498335\n",
            "Mean validation F1-score: 0.7485577444142826\n",
            "\n",
            "\n",
            "Epoch #6\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 23%|â–ˆâ–ˆâ–Ž       | 10/44 [00:36<02:05,  3.70s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "9: avg loss per batch: 122.94942333080151\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 20/44 [01:13<01:28,  3.68s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "19: avg loss per batch: 119.13539150304962\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 30/44 [01:50<00:51,  3.70s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "29: avg loss per batch: 120.15476112804194\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 40/44 [02:28<00:15,  3.78s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "39: avg loss per batch: 116.88248241457165\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 44/44 [02:42<00:00,  3.70s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Average train loss: 112.21115054506244\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/44 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mean validation loss: 464.7012050223763\n",
            "Mean validation accuracy: 0.985589855898559\n",
            "Mean validation F1-score: 0.8041747801578447\n",
            "\n",
            "\n",
            "Epoch #7\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 23%|â–ˆâ–ˆâ–Ž       | 10/44 [00:37<02:06,  3.71s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "9: avg loss per batch: 107.32389266402633\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 20/44 [01:13<01:28,  3.68s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "19: avg loss per batch: 100.31412947805305\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 30/44 [01:50<00:51,  3.69s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "29: avg loss per batch: 102.6394384976091\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 40/44 [02:28<00:15,  3.75s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "39: avg loss per batch: 102.60564507378473\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 44/44 [02:42<00:00,  3.70s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Average train loss: 98.45723215738933\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/44 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mean validation loss: 466.9596308633056\n",
            "Mean validation accuracy: 0.9847998479984799\n",
            "Mean validation F1-score: 0.8000951077584441\n",
            "\n",
            "\n",
            "Epoch #8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 23%|â–ˆâ–ˆâ–Ž       | 10/44 [00:36<02:06,  3.71s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "9: avg loss per batch: 97.125653302228\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 20/44 [01:13<01:28,  3.67s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "19: avg loss per batch: 93.79576860394394\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 30/44 [01:50<00:51,  3.70s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "29: avg loss per batch: 99.31383610867906\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 40/44 [02:28<00:15,  3.75s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "39: avg loss per batch: 96.30185666858641\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 44/44 [02:42<00:00,  3.69s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Average train loss: 92.82887117790453\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/44 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mean validation loss: 441.45177717435615\n",
            "Mean validation accuracy: 0.986279862798628\n",
            "Mean validation F1-score: 0.8033002751770357\n",
            "\n",
            "\n",
            "Epoch #9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 23%|â–ˆâ–ˆâ–Ž       | 10/44 [00:36<02:05,  3.70s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "9: avg loss per batch: 93.64961299189815\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 20/44 [01:13<01:28,  3.67s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "19: avg loss per batch: 87.27925752338611\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 30/44 [01:50<00:51,  3.69s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "29: avg loss per batch: 90.2328126403107\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 40/44 [02:28<00:15,  3.76s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "39: avg loss per batch: 92.38572888496594\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 44/44 [02:42<00:00,  3.69s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Average train loss: 88.17790950428356\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/44 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mean validation loss: 410.76515503608255\n",
            "Mean validation accuracy: 0.986269862698627\n",
            "Mean validation F1-score: 0.8147209671358155\n",
            "\n",
            "\n",
            "Epoch #10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 23%|â–ˆâ–ˆâ–Ž       | 10/44 [00:36<02:05,  3.70s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "9: avg loss per batch: 88.64940897623698\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 20/44 [01:13<01:28,  3.69s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "19: avg loss per batch: 83.81635859974644\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 30/44 [01:50<00:51,  3.70s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "29: avg loss per batch: 87.17241010994746\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 40/44 [02:28<00:15,  3.76s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "39: avg loss per batch: 84.35427660819812\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 44/44 [02:42<00:00,  3.69s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Average train loss: 81.44709731593277\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/44 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mean validation loss: 425.1303553451573\n",
            "Mean validation accuracy: 0.988479884798848\n",
            "Mean validation F1-score: 0.8288826107235323\n",
            "\n",
            "\n",
            "Epoch #11\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 23%|â–ˆâ–ˆâ–Ž       | 10/44 [00:36<02:06,  3.71s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "9: avg loss per batch: 86.82095110857928\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 20/44 [01:13<01:28,  3.69s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "19: avg loss per batch: 81.18831728215804\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 30/44 [01:50<00:51,  3.69s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "29: avg loss per batch: 81.37559824976428\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 40/44 [02:28<00:15,  3.76s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "39: avg loss per batch: 80.61819966634114\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 44/44 [02:42<00:00,  3.70s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Average train loss: 76.62957174127753\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/44 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mean validation loss: 387.885201503449\n",
            "Mean validation accuracy: 0.989719897198972\n",
            "Mean validation F1-score: 0.85241144629286\n",
            "\n",
            "\n",
            "Epoch #12\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 23%|â–ˆâ–ˆâ–Ž       | 10/44 [00:36<02:05,  3.69s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "9: avg loss per batch: 75.19517262776692\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 20/44 [01:13<01:28,  3.70s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "19: avg loss per batch: 68.30363290351734\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 30/44 [01:51<00:51,  3.71s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "29: avg loss per batch: 69.88303533093682\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 40/44 [02:28<00:15,  3.76s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "39: avg loss per batch: 69.09584938766609\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 44/44 [02:42<00:00,  3.70s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Average train loss: 66.94839841669257\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/44 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mean validation loss: 412.10863290027277\n",
            "Mean validation accuracy: 0.989349893498935\n",
            "Mean validation F1-score: 0.84763343597099\n",
            "\n",
            "\n",
            "Epoch #13\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 23%|â–ˆâ–ˆâ–Ž       | 10/44 [00:37<02:06,  3.71s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "9: avg loss per batch: 71.31859334309895\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 20/44 [01:14<01:28,  3.69s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "19: avg loss per batch: 66.55669710928933\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 30/44 [01:51<00:52,  3.72s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "29: avg loss per batch: 68.53925490105289\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 32/44 [01:58<00:44,  3.70s/it]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-ssJBtYpXss"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}